use std::collections::{HashMap, HashSet};
use std::fs;
use std::path::{Path, PathBuf};

use sha2::{Digest, Sha256};

use crate::database::Database;
use crate::error::{AppError, Result};
use crate::models::{AdapterType, Conflict, Rule, Scope, SyncError, SyncResult};

fn get_home_dir() -> Result<PathBuf> {
    dirs::home_dir().ok_or_else(|| AppError::Path("Could not determine home directory".to_string()))
}

fn validate_target_path(base_path: &str) -> Result<PathBuf> {
    let path = PathBuf::from(base_path);

    if path.is_relative() {
        return Err(AppError::InvalidInput {
            message: "Target path must be absolute".to_string(),
        });
    }

    // First canonicalize to resolve any path traversal sequences and normalize Unicode
    let canonical_path = std::fs::canonicalize(&path).map_err(|e| AppError::InvalidInput {
        message: format!("Invalid path: {}", e),
    })?;

    // Check for traversal by comparing against home directory after canonicalization
    let home_dir = get_home_dir()?;
    let canonical_home = std::fs::canonicalize(&home_dir).unwrap_or(home_dir);

    if !canonical_path.starts_with(&canonical_home) {
        return Err(AppError::InvalidInput {
            message: "Target path must be within user's home directory".to_string(),
        });
    }

    Ok(canonical_path)
}

pub trait SyncAdapter: Send + Sync {
    fn id(&self) -> AdapterType;
    fn name(&self) -> &str;
    fn file_name(&self) -> &str;
    #[allow(dead_code)]
    fn description(&self) -> &str;
    fn global_path(&self) -> Result<PathBuf>;

    fn format_content(&self, rules: &[Rule], enabled_rules_only: bool) -> String;
    fn format_rule(&self, rule: &Rule) -> String;
}

pub struct AntigravityAdapter;

impl SyncAdapter for AntigravityAdapter {
    fn id(&self) -> AdapterType {
        AdapterType::Antigravity
    }

    fn name(&self) -> &str {
        "Antigravity"
    }

    fn file_name(&self) -> &str {
        "ANTIGRAVITY.md"
    }

    fn description(&self) -> &str {
        "Antigravity AI coding assistant"
    }

    fn global_path(&self) -> Result<PathBuf> {
        Ok(get_home_dir()?.join(".antigravity").join("ANTIGRAVITY.md"))
    }

    fn format_content(&self, rules: &[Rule], _enabled_rules_only: bool) -> String {
        let timestamp = rules
            .iter()
            .filter(|r| r.enabled)
            .map(|r| r.updated_at)
            .max()
            .map(|ts| ts.format("%Y-%m-%dT%H:%M:%SZ").to_string())
            .unwrap_or_else(|| chrono::Utc::now().format("%Y-%m-%dT%H:%M:%SZ").to_string());
        let rule_names: Vec<&str> = rules
            .iter()
            .filter(|r| r.enabled)
            .map(|r| r.name.as_str())
            .collect();

        let mut content = format!(
            "<!-- Generated by RuleWeaver - Do not edit manually -->\n\
             <!-- Last synced: {} -->\n\
             <!-- Rules: {} -->\n\n",
            timestamp,
            rule_names.join(", ")
        );

        for rule in rules.iter().filter(|r| r.enabled) {
            content.push_str(&self.format_rule(rule));
            content.push_str("\n\n");
        }

        content
    }

    fn format_rule(&self, rule: &Rule) -> String {
        format!("<!-- Rule: {} -->\n{}", rule.name, rule.content)
    }
}

pub struct GeminiAdapter;

impl SyncAdapter for GeminiAdapter {
    fn id(&self) -> AdapterType {
        AdapterType::Gemini
    }

    fn name(&self) -> &str {
        "Gemini CLI"
    }

    fn file_name(&self) -> &str {
        "GEMINI.md"
    }

    fn description(&self) -> &str {
        "Google's Gemini AI coding assistant"
    }

    fn global_path(&self) -> Result<PathBuf> {
        Ok(get_home_dir()?.join(".gemini").join("GEMINI.md"))
    }

    fn format_content(&self, rules: &[Rule], _enabled_rules_only: bool) -> String {
        let timestamp = rules
            .iter()
            .filter(|r| r.enabled)
            .map(|r| r.updated_at)
            .max()
            .map(|ts| ts.format("%Y-%m-%dT%H:%M:%SZ").to_string())
            .unwrap_or_else(|| chrono::Utc::now().format("%Y-%m-%dT%H:%M:%SZ").to_string());
        let rule_names: Vec<&str> = rules
            .iter()
            .filter(|r| r.enabled)
            .map(|r| r.name.as_str())
            .collect();

        let mut content = format!(
            "<!-- Generated by RuleWeaver - Do not edit manually -->\n\
             <!-- Last synced: {} -->\n\
             <!-- Rules: {} -->\n\n",
            timestamp,
            rule_names.join(", ")
        );

        for rule in rules.iter().filter(|r| r.enabled) {
            content.push_str(&self.format_rule(rule));
            content.push_str("\n\n");
        }

        content
    }

    fn format_rule(&self, rule: &Rule) -> String {
        format!("<!-- Rule: {} -->\n{}", rule.name, rule.content)
    }
}

pub struct OpenCodeAdapter;

impl SyncAdapter for OpenCodeAdapter {
    fn id(&self) -> AdapterType {
        AdapterType::OpenCode
    }

    fn name(&self) -> &str {
        "OpenCode"
    }

    fn file_name(&self) -> &str {
        "AGENTS.md"
    }

    fn description(&self) -> &str {
        "OpenCode AI coding assistant"
    }

    fn global_path(&self) -> Result<PathBuf> {
        Ok(get_home_dir()?.join(".opencode").join("AGENTS.md"))
    }

    fn format_content(&self, rules: &[Rule], _enabled_rules_only: bool) -> String {
        let timestamp = rules
            .iter()
            .filter(|r| r.enabled)
            .map(|r| r.updated_at)
            .max()
            .map(|ts| ts.format("%Y-%m-%dT%H:%M:%SZ").to_string())
            .unwrap_or_else(|| chrono::Utc::now().format("%Y-%m-%dT%H:%M:%SZ").to_string());
        let rule_names: Vec<&str> = rules
            .iter()
            .filter(|r| r.enabled)
            .map(|r| r.name.as_str())
            .collect();

        let mut content = format!(
            "<!-- Generated by RuleWeaver - Do not edit manually -->\n\
             <!-- Last synced: {} -->\n\
             <!-- Rules: {} -->\n\n",
            timestamp,
            rule_names.join(", ")
        );

        for rule in rules.iter().filter(|r| r.enabled) {
            content.push_str(&self.format_rule(rule));
            content.push_str("\n\n");
        }

        content
    }

    fn format_rule(&self, rule: &Rule) -> String {
        format!("## {}\n{}", rule.name, rule.content)
    }
}

pub struct ClineAdapter;

impl SyncAdapter for ClineAdapter {
    fn id(&self) -> AdapterType {
        AdapterType::Cline
    }

    fn name(&self) -> &str {
        "Cline"
    }

    fn file_name(&self) -> &str {
        ".clinerules"
    }

    fn description(&self) -> &str {
        "Cline VS Code extension"
    }

    fn global_path(&self) -> Result<PathBuf> {
        Ok(get_home_dir()?.join(".clinerules"))
    }

    fn format_content(&self, rules: &[Rule], _enabled_rules_only: bool) -> String {
        let timestamp = rules
            .iter()
            .filter(|r| r.enabled)
            .map(|r| r.updated_at)
            .max()
            .map(|ts| ts.format("%Y-%m-%dT%H:%M:%SZ").to_string())
            .unwrap_or_else(|| chrono::Utc::now().format("%Y-%m-%dT%H:%M:%SZ").to_string());
        let rule_names: Vec<&str> = rules
            .iter()
            .filter(|r| r.enabled)
            .map(|r| r.name.as_str())
            .collect();

        let mut content = format!(
            "# Generated by RuleWeaver - Do not edit manually\n\
             # Last synced: {}\n\
             # Rules: {}\n\n",
            timestamp,
            rule_names.join(", ")
        );

        for rule in rules.iter().filter(|r| r.enabled) {
            content.push_str(&self.format_rule(rule));
            content.push_str("\n\n");
        }

        content
    }

    fn format_rule(&self, rule: &Rule) -> String {
        format!("# Rule: {}\n{}", rule.name, rule.content)
    }
}

pub struct ClaudeCodeAdapter;

impl SyncAdapter for ClaudeCodeAdapter {
    fn id(&self) -> AdapterType {
        AdapterType::ClaudeCode
    }

    fn name(&self) -> &str {
        "Claude Code"
    }

    fn file_name(&self) -> &str {
        "CLAUDE.md"
    }

    fn description(&self) -> &str {
        "Anthropic's Claude Code assistant"
    }

    fn global_path(&self) -> Result<PathBuf> {
        Ok(get_home_dir()?.join(".claude").join("CLAUDE.md"))
    }

    fn format_content(&self, rules: &[Rule], _enabled_rules_only: bool) -> String {
        let timestamp = rules
            .iter()
            .filter(|r| r.enabled)
            .map(|r| r.updated_at)
            .max()
            .map(|ts| ts.format("%Y-%m-%dT%H:%M:%SZ").to_string())
            .unwrap_or_else(|| chrono::Utc::now().format("%Y-%m-%dT%H:%M:%SZ").to_string());
        let rule_names: Vec<&str> = rules
            .iter()
            .filter(|r| r.enabled)
            .map(|r| r.name.as_str())
            .collect();

        let mut content = format!(
            "<!-- Generated by RuleWeaver - Do not edit manually -->\n\
             <!-- Last synced: {} -->\n\
             <!-- Rules: {} -->\n\n",
            timestamp,
            rule_names.join(", ")
        );

        for rule in rules.iter().filter(|r| r.enabled) {
            content.push_str(&self.format_rule(rule));
            content.push_str("\n\n");
        }

        content
    }

    fn format_rule(&self, rule: &Rule) -> String {
        format!("## {}\n{}", rule.name, rule.content)
    }
}

pub struct CodexAdapter;

impl SyncAdapter for CodexAdapter {
    fn id(&self) -> AdapterType {
        AdapterType::Codex
    }

    fn name(&self) -> &str {
        "Codex"
    }

    fn file_name(&self) -> &str {
        "CODEX.md"
    }

    fn description(&self) -> &str {
        "OpenAI Codex assistant"
    }

    fn global_path(&self) -> Result<PathBuf> {
        Ok(get_home_dir()?.join(".codex").join("CODEX.md"))
    }

    fn format_content(&self, rules: &[Rule], _enabled_rules_only: bool) -> String {
        let timestamp = rules
            .iter()
            .filter(|r| r.enabled)
            .map(|r| r.updated_at)
            .max()
            .map(|ts| ts.format("%Y-%m-%dT%H:%M:%SZ").to_string())
            .unwrap_or_else(|| chrono::Utc::now().format("%Y-%m-%dT%H:%M:%SZ").to_string());
        let rule_names: Vec<&str> = rules
            .iter()
            .filter(|r| r.enabled)
            .map(|r| r.name.as_str())
            .collect();

        let mut content = format!(
            "<!-- Generated by RuleWeaver - Do not edit manually -->\n\
             <!-- Last synced: {} -->\n\
             <!-- Rules: {} -->\n\n",
            timestamp,
            rule_names.join(", ")
        );

        for rule in rules.iter().filter(|r| r.enabled) {
            content.push_str(&self.format_rule(rule));
            content.push_str("\n\n");
        }

        content
    }

    fn format_rule(&self, rule: &Rule) -> String {
        format!("## {}\n{}", rule.name, rule.content)
    }
}

pub fn get_all_adapters() -> Vec<Box<dyn SyncAdapter>> {
    vec![
        Box::new(AntigravityAdapter),
        Box::new(GeminiAdapter),
        Box::new(OpenCodeAdapter),
        Box::new(ClineAdapter),
        Box::new(ClaudeCodeAdapter),
        Box::new(CodexAdapter),
    ]
}

#[allow(dead_code)]
pub fn get_adapter(adapter_type: AdapterType) -> Option<Box<dyn SyncAdapter>> {
    match adapter_type {
        AdapterType::Antigravity => Some(Box::new(AntigravityAdapter)),
        AdapterType::Gemini => Some(Box::new(GeminiAdapter)),
        AdapterType::OpenCode => Some(Box::new(OpenCodeAdapter)),
        AdapterType::Cline => Some(Box::new(ClineAdapter)),
        AdapterType::ClaudeCode => Some(Box::new(ClaudeCodeAdapter)),
        AdapterType::Codex => Some(Box::new(CodexAdapter)),
    }
}

pub struct SyncEngine<'a> {
    db: &'a Database,
}

impl<'a> SyncEngine<'a> {
    pub fn new(db: &'a Database) -> Self {
        Self { db }
    }

    fn get_disabled_adapters(&self) -> HashSet<AdapterType> {
        match self.db.get_setting("adapter_settings") {
            Ok(Some(settings_json)) => {
                match serde_json::from_str::<HashMap<String, bool>>(&settings_json) {
                    Ok(settings_map) => settings_map
                        .into_iter()
                        .filter(|(_, enabled)| !enabled)
                        .filter_map(|(id, _)| AdapterType::from_str(&id))
                        .collect(),
                    Err(e) => {
                        eprintln!("Warning: Failed to deserialize adapter_settings: {}", e);
                        HashSet::new()
                    }
                }
            }
            Ok(None) => HashSet::new(),
            Err(e) => {
                eprintln!(
                    "Warning: Failed to load adapter_settings from database: {}",
                    e
                );
                HashSet::new()
            }
        }
    }

    pub fn sync_all(&self, rules: Vec<Rule>) -> SyncResult {
        let mut files_written = Vec::new();
        let mut errors = Vec::new();
        let conflicts = Vec::new();

        let disabled_adapters = self.get_disabled_adapters();
        let adapters = get_all_adapters();

        for adapter in &adapters {
            if disabled_adapters.contains(&adapter.id()) {
                continue;
            }

            let adapter_rules: Vec<Rule> = rules
                .iter()
                .filter(|r| r.enabled_adapters.contains(&adapter.id()))
                .cloned()
                .collect();

            if adapter_rules.is_empty() {
                continue;
            }

            let global_rules: Vec<Rule> = adapter_rules
                .iter()
                .filter(|r| r.scope == Scope::Global)
                .cloned()
                .collect();

            if !global_rules.is_empty() {
                let path = match adapter.global_path() {
                    Ok(p) => p,
                    Err(e) => {
                        errors.push(SyncError {
                            file_path: String::new(),
                            adapter_name: adapter.name().to_string(),
                            message: e.to_string(),
                        });
                        continue;
                    }
                };
                match self.sync_file(adapter.as_ref(), &global_rules, &path) {
                    Ok(()) => files_written.push(path.to_string_lossy().to_string()),
                    Err(e) => errors.push(SyncError {
                        file_path: path.to_string_lossy().to_string(),
                        adapter_name: adapter.name().to_string(),
                        message: e.to_string(),
                    }),
                }
            }

            let local_rules_by_path: HashMap<String, Vec<Rule>> = {
                let mut map: HashMap<String, Vec<Rule>> = HashMap::new();
                for rule in adapter_rules.iter().filter(|r| r.scope == Scope::Local) {
                    if let Some(paths) = &rule.target_paths {
                        for path in paths {
                            match validate_target_path(path) {
                                Ok(_) => {
                                    map.entry(path.clone()).or_default().push(rule.clone());
                                }
                                Err(e) => {
                                    errors.push(SyncError {
                                        file_path: path.clone(),
                                        adapter_name: adapter.name().to_string(),
                                        message: e.to_string(),
                                    });
                                }
                            }
                        }
                    }
                }
                map
            };

            for (base_path, path_rules) in local_rules_by_path {
                let path = PathBuf::from(&base_path).join(adapter.file_name());
                match self.sync_file(adapter.as_ref(), &path_rules, &path) {
                    Ok(()) => files_written.push(path.to_string_lossy().to_string()),
                    Err(e) => errors.push(SyncError {
                        file_path: path.to_string_lossy().to_string(),
                        adapter_name: adapter.name().to_string(),
                        message: e.to_string(),
                    }),
                }
            }
        }

        let success = errors.is_empty() && conflicts.is_empty();

        let status = if errors.is_empty() {
            "success"
        } else if !files_written.is_empty() {
            "partial"
        } else {
            "failed"
        };

        let _ = self
            .db
            .add_sync_log(files_written.len() as u32, status, "manual");

        SyncResult {
            success,
            files_written,
            errors,
            conflicts,
        }
    }

    pub fn sync_rule(&self, rule: Rule) -> SyncResult {
        let mut files_written = Vec::new();
        let mut errors = Vec::new();
        let conflicts = Vec::new();

        let disabled_adapters = self.get_disabled_adapters();
        let adapters = get_all_adapters();

        let all_rules = match self.db.get_all_rules() {
            Ok(r) => r,
            Err(e) => {
                return SyncResult {
                    success: false,
                    files_written: vec![],
                    errors: vec![SyncError {
                        file_path: "".to_string(),
                        adapter_name: "".to_string(),
                        message: format!("Failed to fetch rules: {}", e),
                    }],
                    conflicts: vec![],
                };
            }
        };

        for adapter in &adapters {
            if disabled_adapters.contains(&adapter.id()) || !rule.enabled_adapters.contains(&adapter.id()) {
                continue;
            }

            // For each adapter, we need to sync the file(s) this rule belongs to.
            // This means re-collecting ALL rules for that target file to ensure its content is correct.
            
            if rule.scope == Scope::Global {
                let path = match adapter.global_path() {
                    Ok(p) => p,
                    Err(e) => {
                        errors.push(SyncError {
                            file_path: String::new(),
                            adapter_name: adapter.name().to_string(),
                            message: e.to_string(),
                        });
                        continue;
                    }
                };
                
                let global_rules: Vec<Rule> = all_rules
                    .iter()
                    .filter(|r| r.scope == Scope::Global && r.enabled_adapters.contains(&adapter.id()))
                    .cloned()
                    .collect();

                match self.sync_file(adapter.as_ref(), &global_rules, &path) {
                    Ok(()) => files_written.push(path.to_string_lossy().to_string()),
                    Err(e) => errors.push(SyncError {
                        file_path: path.to_string_lossy().to_string(),
                        adapter_name: adapter.name().to_string(),
                        message: e.to_string(),
                    }),
                }
            } else if rule.scope == Scope::Local {
                if let Some(paths) = &rule.target_paths {
                    for base_path in paths {
                        if let Ok(_) = validate_target_path(base_path) {
                            let path = PathBuf::from(base_path).join(adapter.file_name());
                            
                            let path_rules: Vec<Rule> = all_rules
                                .iter()
                                .filter(|r| {
                                    r.scope == Scope::Local && 
                                    r.enabled_adapters.contains(&adapter.id()) &&
                                    r.target_paths.as_ref().map(|p| p.contains(base_path)).unwrap_or(false)
                                })
                                .cloned()
                                .collect();

                            match self.sync_file(adapter.as_ref(), &path_rules, &path) {
                                Ok(()) => files_written.push(path.to_string_lossy().to_string()),
                                Err(e) => errors.push(SyncError {
                                    file_path: path.to_string_lossy().to_string(),
                                    adapter_name: adapter.name().to_string(),
                                    message: e.to_string(),
                                }),
                            }
                        }
                    }
                }
            }
        }

        let status = if errors.is_empty() {
            "success"
        } else if !files_written.is_empty() {
            "partial"
        } else {
            "failed"
        };

        let _ = self
            .db
            .add_sync_log(files_written.len() as u32, status, "auto");

        SyncResult {
            success: errors.is_empty(),
            files_written,
            errors,
            conflicts,
        }
    }

    pub fn preview(&self, rules: Vec<Rule>) -> SyncResult {
        let mut files_written = Vec::new();
        let mut conflicts = Vec::new();

        let disabled_adapters = self.get_disabled_adapters();
        let adapters = get_all_adapters();

        for adapter in &adapters {
            if disabled_adapters.contains(&adapter.id()) {
                continue;
            }

            let adapter_rules: Vec<Rule> = rules
                .iter()
                .filter(|r| r.enabled_adapters.contains(&adapter.id()))
                .cloned()
                .collect();

            if adapter_rules.is_empty() {
                continue;
            }

            let global_rules: Vec<Rule> = adapter_rules
                .iter()
                .filter(|r| r.scope == Scope::Global)
                .cloned()
                .collect();

            if !global_rules.is_empty() {
                let path = match adapter.global_path() {
                    Ok(p) => p,
                    Err(_) => continue,
                };
                files_written.push(path.to_string_lossy().to_string());

                // TODO: Address race condition between hash read and file computation.
                // The file could change between reading the stored hash and computing the current hash.
                // For now, this is acceptable for a sync preview as we prioritize eventual consistency
                // over strict atomicity. Consider adding file locking for stricter consistency.
                if let Some(local_hash) = self
                    .db
                    .get_file_hash(&path.to_string_lossy())
                    .ok()
                    .flatten()
                {
                    if let Ok(current_hash) = compute_file_hash(&path) {
                        if local_hash != current_hash {
                            conflicts.push(Conflict {
                                id: uuid::Uuid::new_v4().to_string(),
                                file_path: path.to_string_lossy().to_string(),
                                adapter_name: adapter.name().to_string(),
                                adapter_id: Some(adapter.id()),
                                local_hash,
                                current_hash,
                            });
                        }
                    }
                }
            }

            let local_rules_by_path: HashMap<String, Vec<Rule>> = {
                let mut map: HashMap<String, Vec<Rule>> = HashMap::new();
                for rule in adapter_rules.iter().filter(|r| r.scope == Scope::Local) {
                    if let Some(paths) = &rule.target_paths {
                        for base_path in paths {
                            if validate_target_path(base_path).is_ok() {
                                map.entry(base_path.clone()).or_default().push(rule.clone());
                            }
                        }
                    }
                }
                map
            };

            for (base_path, _path_rules) in local_rules_by_path {
                let path = PathBuf::from(&base_path).join(adapter.file_name());
                files_written.push(path.to_string_lossy().to_string());

                // Note: There's a potential race condition here where the file could change
                // between reading the stored hash and computing the current hash.
                // This is acceptable for a sync preview as we prioritize eventual consistency.
                if let Some(local_hash) = self
                    .db
                    .get_file_hash(&path.to_string_lossy())
                    .ok()
                    .flatten()
                {
                    if let Ok(current_hash) = compute_file_hash(&path) {
                        if local_hash != current_hash {
                            conflicts.push(Conflict {
                                id: uuid::Uuid::new_v4().to_string(),
                                file_path: path.to_string_lossy().to_string(),
                                adapter_name: adapter.name().to_string(),
                                adapter_id: Some(adapter.id()),
                                local_hash,
                                current_hash,
                            });
                        }
                    }
                }
            }
        }

        SyncResult {
            success: true,
            files_written,
            errors: vec![],
            conflicts,
        }
    }

    fn sync_file(&self, adapter: &dyn SyncAdapter, rules: &[Rule], path: &Path) -> Result<()> {
        if let Some(parent) = path.parent() {
            fs::create_dir_all(parent)?;
        }

        let content = adapter.format_content(rules, true);
        let hash = compute_content_hash(&content);

        fs::write(path, &content)?;

        self.db.set_file_hash(&path.to_string_lossy(), &hash)?;

        Ok(())
    }

    pub fn sync_file_by_path(&self, rules: &[Rule], file_path: &str) -> Result<()> {
        validate_target_path(file_path)?;

        let path = PathBuf::from(file_path);
        let adapters = get_all_adapters();

        for adapter in &adapters {
            if let Ok(adapter_path) = adapter.global_path() {
                if adapter_path == path {
                    let adapter_rules: Vec<Rule> = rules
                        .iter()
                        .filter(|r| {
                            r.enabled_adapters.contains(&adapter.id()) && r.scope == Scope::Global
                        })
                        .cloned()
                        .collect();

                    if !adapter_rules.is_empty() {
                        return self.sync_file(adapter.as_ref(), &adapter_rules, &path);
                    }
                }
            }

            let file_name = path.file_name().and_then(|n| n.to_str()).unwrap_or("");
            if file_name == adapter.file_name() {
                if let Some(parent) = path.parent() {
                    let parent_str = parent.to_string_lossy();
                    let local_rules: Vec<Rule> = rules
                        .iter()
                        .filter(|r| {
                            r.enabled_adapters.contains(&adapter.id())
                                && r.scope == Scope::Local
                                && r.target_paths
                                    .as_ref()
                                    .map(|paths| paths.contains(&parent_str.to_string()))
                                    .unwrap_or(false)
                        })
                        .cloned()
                        .collect();

                    if !local_rules.is_empty() {
                        return self.sync_file(adapter.as_ref(), &local_rules, &path);
                    }
                }
            }
        }

        Err(crate::error::AppError::InvalidInput {
            message: format!("No adapter found for path: {}", file_path),
        })
    }
}

fn compute_content_hash(content: &str) -> String {
    let mut hasher = Sha256::new();
    hasher.update(content.as_bytes());
    format!("{:x}", hasher.finalize())
}

pub fn compute_content_hash_public(content: &str) -> String {
    compute_content_hash(content)
}

fn compute_file_hash(path: &Path) -> Result<String> {
    let content = fs::read_to_string(path)?;
    Ok(compute_content_hash(&content))
}

#[cfg(test)]
mod tests {
    use super::*;

    fn create_test_rule(name: &str, content: &str, scope: Scope) -> Rule {
        let _now = chrono::Utc::now();
        Rule {
            id: uuid::Uuid::new_v4().to_string(),
            name: name.to_string(),
            content: content.to_string(),
            scope,
            target_paths: None,
            enabled_adapters: vec![AdapterType::Gemini],
            enabled: true,
            created_at: chrono::Utc::now(),
            updated_at: chrono::Utc::now(),
        }
    }

    #[test]
    fn test_gemini_adapter_format() {
        let adapter = GeminiAdapter;
        let rules = vec![
            create_test_rule("Rule 1", "Content 1", Scope::Global),
            create_test_rule("Rule 2", "Content 2", Scope::Global),
        ];

        let content = adapter.format_content(&rules, true);

        assert!(content.contains("Generated by RuleWeaver"));
        assert!(content.contains("Rule 1"));
        assert!(content.contains("Rule 2"));
        assert!(content.contains("Content 1"));
        assert!(content.contains("Content 2"));
    }

    #[test]
    fn test_opencode_adapter_format() {
        let adapter = OpenCodeAdapter;
        let rules = vec![create_test_rule("Test Rule", "Test Content", Scope::Global)];

        let content = adapter.format_content(&rules, true);

        assert!(content.contains("## Test Rule"));
        assert!(content.contains("Test Content"));
    }

    #[test]
    fn test_cline_adapter_format() {
        let adapter = ClineAdapter;
        let rules = vec![create_test_rule("Test Rule", "Test Content", Scope::Global)];

        let content = adapter.format_content(&rules, true);

        assert!(content.contains("# Rule: Test Rule"));
        assert!(content.contains("Test Content"));
        assert!(content.starts_with("# Generated by RuleWeaver"));
    }

    #[test]
    fn test_adapter_global_path() {
        let adapter = GeminiAdapter;
        let path = adapter.global_path().expect("Failed to get home directory");
        assert!(path.to_string_lossy().contains(".gemini"));
        assert!(path.to_string_lossy().contains("GEMINI.md"));
    }

    #[test]
    fn test_compute_content_hash() {
        let hash1 = compute_content_hash("test content");
        let hash2 = compute_content_hash("test content");
        let hash3 = compute_content_hash("different content");

        assert_eq!(hash1, hash2);
        assert_ne!(hash1, hash3);
        assert_eq!(hash1.len(), 64);
    }

    #[test]
    fn test_disabled_rules_not_included() {
        let adapter = GeminiAdapter;
        let mut rule = create_test_rule("Disabled Rule", "Should not appear", Scope::Global);
        rule.enabled = false;

        let content = adapter.format_content(&[rule], true);
        assert!(!content.contains("Should not appear"));
    }

    #[test]
    fn test_all_adapters_have_consistent_interface() {
        let adapters = get_all_adapters();

        for adapter in adapters {
            assert!(!adapter.name().is_empty());
            assert!(!adapter.file_name().is_empty());
            assert!(!adapter.description().is_empty());

            let rules = vec![create_test_rule("Test", "Content", Scope::Global)];
            let content = adapter.format_content(&rules, true);
            assert!(!content.is_empty());
        }
    }
}
