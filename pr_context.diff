diff --git a/.gitignore b/.gitignore
index 2bacbe1..0a8ca9e 100644
--- a/.gitignore
+++ b/.gitignore
@@ -46,3 +46,9 @@ vite.config.js.timestamp-*
 # Log files
 logs
 *.log
+
+# Review files
+review*.md
+review*.txt
+review*.log
+review*.json
\ No newline at end of file
diff --git a/PLAN.md b/PLAN.md
index f67f3e7..4279f4d 100644
--- a/PLAN.md
+++ b/PLAN.md
@@ -1,1199 +1,1965 @@
-# Project Strategy: RuleWeaver Phase 1
+# Project Strategy: RuleWeaver Phase 2 - Custom Commands & MCP
 
 ## 1. High-Level Strategy
 
-Build the Phase 1 MVP for RuleWeaver - a Tauri desktop application that enables users to manage AI coding assistant rules through a unified GUI and sync them to various tools via adapters.
+**Objective:** Transform RuleWeaver from a rule management tool into a complete MCP (Model Context Protocol) server platform. Users will be able to define custom shell commands and expose them as MCP tools to AI assistants like Claude Code and OpenCode.
 
-**Core Objectives:**
+**Core Deliverables:**
 
-1. Establish a solid Tauri + React + TypeScript + TailwindCSS foundation with shadcn/ui components
-2. Implement persistent data storage for rules using Rust backend with SQLite
-3. Build a polished GUI with dashboard, rules management, and markdown editing
-4. Create a sync engine with tool-specific adapters (GEMINI.md, AGENTS.md, .clinerules)
+1. **File-First Storage Architecture (#14)** - Migrate from SQLite-primary to markdown files with YAML frontmatter for git-native, transparent rule storage
+2. **MCP Server Foundation (#5)** - Embed an MCP server in the Tauri app that starts automatically and serves tools
+3. **Command Management System (#6)** - Full CRUD for custom commands with script templates, arguments, and in-app testing
+4. **Command Execution Engine (#7)** - Wire commands to MCP server with secure process spawning and output capture
 
-**Technical Approach:**
+**Architecture Alignment:**
+This plan implements Phase 2 of the roadmap: "Custom Commands MVP & MCP Integration". It follows the three-layer architecture (Presentation Layer, Core Logic Layer, Target Layer) defined in `architecture.md`. Note: Skills are defined in the architecture but will be implemented in Phase 3 (not part of this milestone).
 
-- Frontend: React 18+ with TypeScript, TailwindCSS, shadcn/ui component library
-- Backend: Rust with Tauri IPC commands for frontend communication
-- Database: SQLite embedded via `rusqlite` crate in user's AppData directory
-- File Sync: Trait-based adapter pattern for extensibility
+**Strategic Approach:**
+
+- **Issue #14 first** - File-first storage is marked high priority and provides a better foundation for the rest of Phase 2
+- **Parallel tracks** - MCP Server (#5) and Command Model (#6) can proceed in parallel after #14
+- **Integration** - Issue #7 ties everything together, connecting commands to the MCP server
 
 ---
 
 ## 2. Implementation Plan
 
-### Phase 1.1: Project Setup (Issue #1)
+### Phase 2.0: Project Setup (PREREQUISITE)
 
-**Goal:** Initialize Tauri project with all tooling configured.
+**Goal:** Create feature branch and ensure all tooling is ready.
 
-**Tasks:**
+- [ ] Create feature branch: `git checkout -b feature/phase-2-mcp-commands`
+- [ ] Verify all Phase 1 tests pass
+- [ ] Run lint and typecheck to establish baseline
+- [ ] Review and update any outdated dependencies
+- [ ] Ensure CI/CD pipeline is green
+
+---
+
+### Phase 2.1: File-First Storage Architecture (Issue #14) - HIGH PRIORITY
 
-1. Run `npm create tauri-app@latest` with React, TypeScript, TailwindCSS options
-2. Configure TailwindCSS with custom design tokens (no hardcoded colors)
-3. Install and configure shadcn/ui component library
-4. Setup ESLint, Prettier, and TypeScript strict mode
-5. Configure Rust backend for absolute filesystem paths
-6. Setup Vitest for frontend testing
-7. Setup Rust tests for backend testing
-8. Create base directory structure matching architecture.md
+**Goal:** Replace SQLite as primary storage with markdown files containing YAML frontmatter, keeping SQLite only for indexing/cache.
 
-**Directory Structure:**
+**Why This First:**
+
+- Rules become git-versionable automatically
+- Users can edit `.ruleweaver/rules/*.md` in any editor
+- Portable, transparent, emergency-accessible
+- Better developer experience (review rule changes in PRs)
+- Aligns with architecture.md: "Database: SQLite (Embedded via Rust) or `serde_json` file storage"
+
+#### Backend Implementation
+
+**File Structure:**
 
 ```
-src/
-â”œâ”€â”€ components/          # React components
-â”‚   â”œâ”€â”€ ui/             # shadcn/ui primitives
-â”‚   â””â”€â”€ layout/         # Layout components
-â”œâ”€â”€ hooks/              # Custom React hooks
-â”œâ”€â”€ lib/                # Utilities and helpers
-â”œâ”€â”€ pages/              # Page components
-â”œâ”€â”€ stores/             # State management
-â””â”€â”€ types/              # TypeScript types
-src-tauri/
-â”œâ”€â”€ src/
-â”‚   â”œâ”€â”€ commands/       # Tauri IPC commands
-â”‚   â”œâ”€â”€ database/       # SQLite database layer
-â”‚   â”œâ”€â”€ models/         # Rust data models
-â”‚   â”œâ”€â”€ sync/           # Sync engine and adapters
-â”‚   â””â”€â”€ lib.rs          # Main entry point
-â””â”€â”€ Cargo.toml
+~/.ruleweaver/rules/              # Global rules
+  â”œâ”€â”€ 000-global-coding.md
+  â””â”€â”€ 001-security-guidelines.md
+
+{repo}/.ruleweaver/rules/         # Local rules (per project)
+  â”œâ”€â”€ 000-project-specific.md
+  â””â”€â”€ ...
 ```
 
+**File Format (YAML + Markdown):**
+
+```markdown
+---
+id: abc-123
+name: "TypeScript Rules"
+scope: local
+targetPaths: ["/src"]
+enabledAdapters: [gemini, opencode, cline]
+enabled: true
+createdAt: 2024-01-15T10:30:00Z
+updatedAt: 2024-01-15T10:30:00Z
 ---
 
-### Phase 1.2: Core Data Storage (Issue #2)
+## TypeScript Guidelines
 
-**Goal:** Implement Rust data models and persistent storage with IPC.
+- Use strict mode
+- Prefer interfaces over types
+```
 
-**Tasks:**
+**Rust Module Structure:**
 
-1. Define Rust structs for `Rule`, `Scope`, `TargetDefinition` with serde serialization
-2. Implement SQLite database manager with migrations
-3. Create database migration system for schema versioning
-4. Implement CRUD operations for rules in Rust
-5. Create Tauri IPC commands for all rule operations
-6. Setup database path in platform-specific AppData/Config directory
-7. Add error handling with custom error types
-8. Write comprehensive Rust unit tests for database operations
+```
+src-tauri/src/
+â”œâ”€â”€ file_storage/
+â”‚   â”œâ”€â”€ mod.rs           # Public API
+â”‚   â”œâ”€â”€ parser.rs        # YAML frontmatter parsing
+â”‚   â”œâ”€â”€ serializer.rs    # YAML frontmatter generation
+â”‚   â”œâ”€â”€ watcher.rs       # File system watching
+â”‚   â””â”€â”€ migration.rs     # SQLite to files migration
+```
 
-**Data Models:**
+**Rust Implementation Tasks:**
+
+- Add dependencies to `Cargo.toml`: `serde_yaml`, `notify` (file watcher), `glob`
+- Create `src-tauri/src/file_storage/mod.rs` module
+- Implement YAML frontmatter parser with error handling
+- Implement YAML frontmatter generator
+- Create `RuleFile` struct for file-based rule representation
+- Implement `load_rules_from_disk()` function with directory traversal
+- Implement `save_rule_to_disk()` function with atomic writes
+- Handle global rules directory (`~/.ruleweaver/rules/`)
+- Handle local rules directories (`{repo}/.ruleweaver/rules/`)
+- Create file watcher using `notify` crate for external changes
+- Update SQLite schema - migration v3 to remove content field
+- Keep SQLite as index/cache (id, file_path, content_hash, last_sync_at, modified_at)
+- Implement backward compatibility (fallback to SQLite if files don't exist)
+- Create `migrate_to_file_storage()` IPC command with progress reporting
+- Create `verify_file_storage_integrity()` health check
+- Implement `rollback_migration()` for safety
+- Update `Database` to work with file-based rules
+- Update all existing IPC commands to use file storage
+- Handle edge cases:
+  - File permission errors (readable/writable check)
+  - Concurrent editing (file vs app) with conflict detection
+  - Large files (>1MB) with chunked reading
+  - Special characters in rule content (Unicode handling)
+  - Duplicate IDs across different directories
+  - Orphaned files (no matching rule in index)
+  - Git merge conflicts in rule files
+
+#### Frontend Implementation
+
+**New UI Components:**
+
+- `FileStorageStatus` - Shows current storage mode
+- `MigrationDialog` - Migration progress and status
+- `FilePathDisplay` - Shows file path with copy button
+- `RevealInExplorerButton` - Opens file location
+
+**Frontend Tasks:**
+
+- Add "Open in Editor" button to rule cards
+- Show file path in rule detail view
+- Display file timestamps (created/modified)
+- Implement "Reveal in Explorer" for rule files
+- Add file system health indicators
+- Show migration status/progress dialog
+- Add storage mode indicator in settings
+- Create migration UI with:
+  - Progress bar
+  - Current file being migrated
+  - Error display
+  - Rollback option
+
+#### Error Handling
+
+| Error Type         | User Message                                                       | Recovery                                 |
+| ------------------ | ------------------------------------------------------------------ | ---------------------------------------- |
+| File permissions   | "Cannot read/write rule file at {path}. Check folder permissions." | "Open folder" button + "Retry"           |
+| YAML parse error   | "Invalid YAML frontmatter in {filename}"                           | "View file" button + "Reset to default"  |
+| File not found     | "Rule file not found at expected path"                             | "Locate file" or "Recreate"              |
+| Concurrent edit    | "Rule file was modified externally"                                | "Reload from disk" or "Overwrite"        |
+| Git merge conflict | "Merge conflict detected in {filename}"                            | Show conflict markers, manual resolution |
+| Large file         | "Rule file exceeds size limit (1MB)"                               | "Split into smaller rules"               |
+| Orphaned file      | "File has no matching rule in database"                            | "Import" or "Delete file"                |
+| Duplicate ID       | "Multiple files have the same rule ID"                             | "Resolve duplicates" wizard              |
+
+#### Documentation Tasks
+
+- [ ] Update README.md with new file-based architecture
+- [ ] Document `.ruleweaver/rules/` directory structure
+- [ ] Document YAML frontmatter schema
+- [ ] Add migration guide for existing users
+- [ ] Document file watching behavior
+- [ ] Document manual editing best practices
 
-```rust
-pub enum Scope { Global, Local }
+#### Tests
 
-pub struct Rule {
-    pub id: String,
-    pub name: String,
-    pub content: String,
-    pub scope: Scope,
-    pub target_paths: Option<Vec<String>>,
-    pub enabled_adapters: Vec<String>,
-    pub created_at: i64,
-    pub updated_at: i64,
-}
-```
+**Unit Tests (Rust):**
 
-**IPC Commands:**
+- [ ] `test_yaml_frontmatter_parse_success` - Happy path
+- [ ] `test_yaml_frontmatter_parse_invalid_yaml` - Failure path
+- [ ] `test_yaml_frontmatter_parse_missing_required_fields` - Validation
+- [ ] `test_yaml_frontmatter_generate` - Serialization
+- [ ] `test_load_rules_from_disk_empty_directory` - Edge case
+- [ ] `test_load_rules_from_disk_mixed_files` - Multiple rules
+- [ ] `test_load_rules_from_disk_special_characters` - Unicode content
+- [ ] `test_save_rule_to_disk_atomic_write` - File safety
+- [ ] `test_save_rule_to_disk_overwrite_existing` - Update scenario
+- [ ] `test_file_watcher_detects_external_change` - External edits
+- [ ] `test_migration_preserves_all_data` - Data integrity
+- [ ] `test_migration_rollback` - Safety mechanism
+- [ ] `test_backward_compatibility_sqlite_fallback` - Compatibility
+- [ ] `test_concurrent_edit_detection` - Race conditions
+
+**Integration Tests:**
+
+- [ ] `test_full_migration_flow` - End-to-end migration
+- [ ] `test_file_watcher_integration` - Real file system events
+- [ ] `test_git_workflow_compatibility` - Commit, pull, merge
+
+**Frontend Tests:**
+
+- [ ] Test MigrationDialog renders progress correctly
+- [ ] Test FileStorageStatus shows correct state
+- [ ] Test "Open in Editor" button functionality
 
-- `get_all_rules` - Fetch all rules
-- `get_rule_by_id` - Fetch single rule
-- `create_rule` - Create new rule
-- `update_rule` - Update existing rule
-- `delete_rule` - Delete rule
-- `get_app_data_path` - Get storage path for display
+**Coverage Target:** 80%+ (high-value tests only, no trivial getter/setter tests)
 
 ---
 
-### Phase 1.3: The GUI (Issue #3)
-
-**Goal:** Build a world-class, intuitive GUI with excellent UX for managing rules.
-
-#### Core Layout & Navigation
-
-- [ ] MainLayout with collapsible sidebar navigation
-- [ ] Sidebar items: Dashboard, Rules, Settings
-- [ ] Responsive design (works at 1024px+ width)
-- [ ] Dark/Light/System theme toggle in header
-- [ ] Keyboard navigation support throughout
-
-#### Dashboard Page
-
-- [ ] Welcome card with app description and "How it works" diagram
-- [ ] Quick stats: Total rules, Global rules, Local rules, Last sync time
-- [ ] "Create your first rule" CTA when no rules exist (empty state)
-- [ ] Quick-start templates carousel:
-  - TypeScript Best Practices
-  - React Component Guidelines
-  - Python Standards
-  - Git Commit Conventions
-- [ ] Recent activity feed (last 5 sync operations)
-- [ ] Quick actions: "New Rule", "Sync All"
-
-#### Rules Page
-
-- [ ] **Rules List View:**
-  - Search bar with instant filtering
-  - Sort dropdown (Name A-Z, Name Z-A, Date Modified, Scope)
-  - Filter chips: Global | Local
-  - Adapter filter dropdown
-  - Rule cards showing: name, scope badge, adapter icons, last modified
-  - Enable/disable toggle per rule (without deleting)
-  - Overflow menu: Edit, Duplicate, Delete
-  - Bulk selection with bulk actions (Enable/Disable/Delete)
-- [ ] **Empty State:**
-  - Illustration + "No rules yet"
-  - "Create your first rule" primary button
-  - "Browse templates" secondary button
-
-- [ ] **Rule Editor (dedicated page/view):**
-  - Three-panel layout: Sidebar (rule list) | Editor | Preview
-  - Editor panel:
-    - Rule name input (required, validated)
-    - Markdown editor with formatting toolbar
-    - Word/character count
-    - Autosave indicator ("Saved" or "Saving...")
-  - Settings panel (collapsible):
-    - Scope toggle: Global | Local
-    - Local paths: Directory picker with add/remove
-    - Adapter selection: Checkboxes with icons and tooltips
-  - Preview panel:
-    - Tabbed view showing output for each selected adapter
-    - File path display for each adapter output
-    - "View in file system" link (opens folder)
-
-#### Settings Page
-
-- [ ] **General Settings:**
-  - App data location (read-only + "Open in Explorer" button)
-  - Default scope for new rules
-  - Default adapter selections (remembered)
-  - Theme: Light | Dark | System
-- [ ] **Adapters Section:**
-  - List of all adapters with enable/disable toggles
-  - Each adapter shows: Name, Icon, Output filename, Global path
-  - Tooltips explaining what each adapter is for
-- [ ] **About Section:**
-  - App version
-  - "Check for updates" button
-  - Links: GitHub, Documentation, Report Issue
-
-#### Dialogs & Modals
-
-- [ ] **Create Rule Dialog:**
-  - Name input
-  - "Start from template" dropdown
-  - "Create blank" or "Use template" buttons
-- [ ] **Delete Confirmation Dialog:**
-  - Rule name prominently displayed
-  - "Delete" (destructive) and "Cancel" buttons
-  - Warning message about file sync implications
-- [ ] **Conflict Resolution Dialog:**
-  - Show file path and adapter
-  - Show diff view (current vs incoming)
-  - Options: "Overwrite", "Keep External", "Cancel"
-- [ ] **Sync Preview Dialog:**
-  - List of files that will be written
-  - Green checkmark for new/modified files
-  - Yellow warning for conflicts
-  - "Sync Now" or "Cancel" buttons
-
-#### Toast Notifications
-
-- [ ] Success: Rule saved, Rule deleted, Sync completed
-- [ ] Warning: File conflict detected, Large content warning
-- [ ] Error: Save failed, Sync failed, Permission denied
-- [ ] Undo toast for delete (10 second undo window)
+### Phase 2.2: MCP Server Foundation (Issue #5)
 
-#### Keyboard Shortcuts
+**Goal:** Research, integrate, and boot an MCP server within the Tauri application.
 
-- [ ] `Ctrl/Cmd + N` - New rule
-- [ ] `Ctrl/Cmd + S` - Save current rule
-- [ ] `Ctrl/Cmd + Shift + S` - Sync all
-- [ ] `Ctrl/Cmd + F` - Focus search
-- [ ] `Ctrl/Cmd + ,` - Open settings
-- [ ] `Escape` - Close dialogs/cancel
-- [ ] `?` - Show keyboard shortcuts help
+#### Research & Architecture
 
-#### Loading States & Feedback
+**MCP Protocol Basics:**
 
-- [ ] Skeleton loaders for rules list
-- [ ] Spinner during sync operations
-- [ ] Progress bar for bulk sync (X of Y files)
-- [ ] Optimistic UI updates where appropriate
-- [ ] Error boundaries with friendly error messages
+- JSON-RPC 2.0 over stdio or HTTP
+- Key endpoints: `tools/list` (returns available tools), `tools/call` (executes tool)
+- Transport: Start with stdio (simpler), consider HTTP later
 
-#### Accessibility
+**Rust SDK Options to Evaluate:**
 
-- [ ] All interactive elements keyboard accessible
-- [ ] Focus visible outlines
-- [ ] ARIA labels for icons
-- [ ] Screen reader announcements for toasts
-- [ ] Sufficient color contrast (WCAG AA)
-- [ ] Reduced motion respect
+1. `rmcp` crate (if available)
+2. Custom JSON-RPC implementation using `tokio` and `tower`
+3. `jsonrpc-core` crate
 
-#### UI Component Inventory
+**Selection Criteria:**
 
-| Component         | Purpose                              |
-| ----------------- | ------------------------------------ |
-| MainLayout        | App shell with sidebar               |
-| Sidebar           | Navigation + collapse toggle         |
-| Header            | Title, theme toggle, user menu       |
-| Dashboard         | Welcome, stats, templates, activity  |
-| RulesList         | Searchable, sortable list of rules   |
-| RuleCard          | Individual rule display with actions |
-| RuleEditor        | Markdown editing with toolbar        |
-| RuleSettings      | Scope, paths, adapters config        |
-| PreviewPanel      | Tabbed adapter output preview        |
-| SettingsPage      | App preferences                      |
-| AdapterConfig     | Adapter enable/disable + info        |
-| EmptyState        | Illustrated empty rules state        |
-| ConfirmDialog     | Destructive action confirmation      |
-| ConflictDialog    | File conflict resolution             |
-| SyncPreviewDialog | Pre-sync file list                   |
-| Toast             | Success/warning/error notifications  |
-| TemplatePicker    | Quick-start rule templates           |
-| DirectoryPicker   | File system directory selection      |
-| SearchInput       | Filter rules with debounce           |
-| Toggle            | Enable/disable switches              |
-| Badge             | Scope/adapter labels                 |
-| Skeleton          | Loading placeholders                 |
-
-#### Wireframes (ASCII Layout)
-
-**Dashboard Page:**
+- Active maintenance
+- Tauri compatibility
+- Async support
+- Error handling quality
 
-```
-â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-â”‚  RuleWeaver                                    ğŸŒ™ Dark  âš™ Settings â”‚
-â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
-â”‚            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
-â”‚  Dashboard â”‚  â”‚  Welcome to RuleWeaver                          â”‚  â”‚
-â”‚            â”‚  â”‚  Manage your AI coding assistant rules in one   â”‚  â”‚
-â”‚  > Rules   â”‚  â”‚  place. Sync to GEMINI.md, AGENTS.md, .clinerulesâ”‚  â”‚
-â”‚            â”‚  â”‚                              [Create First Rule] â”‚  â”‚
-â”‚  Settings  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
-â”‚            â”‚                                                        â”‚
-â”‚            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
-â”‚            â”‚  â”‚ 3 Rules      â”‚ â”‚ 2 Global     â”‚ â”‚ 1 Local      â”‚   â”‚
-â”‚            â”‚  â”‚ Total        â”‚ â”‚ Rules        â”‚ â”‚ Rules        â”‚   â”‚
-â”‚            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
-â”‚            â”‚                                                        â”‚
-â”‚            â”‚  Quick Start Templates                                â”‚
-â”‚            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
-â”‚            â”‚  â”‚TypeScriptâ”‚ â”‚ React   â”‚ â”‚ Python  â”‚ â”‚ Git     â”‚      â”‚
-â”‚            â”‚  â”‚  Best   â”‚ â”‚Componentsâ”‚ â”‚Standard â”‚ â”‚ Commits â”‚      â”‚
-â”‚            â”‚  â”‚Practicesâ”‚ â”‚         â”‚ â”‚         â”‚ â”‚         â”‚      â”‚
-â”‚            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
-â”‚            â”‚                                                        â”‚
-â”‚            â”‚  Recent Activity                    [Sync All â–¸]       â”‚
-â”‚            â”‚  â€¢ Synced 3 rules to 5 files - 2 mins ago             â”‚
-â”‚            â”‚  â€¢ Created "TypeScript Standards" - 1 hour ago         â”‚
-â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
-```
+#### Backend Implementation
 
-**Rules List Page:**
+**Rust Module Structure:**
 
 ```
-â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-â”‚  RuleWeaver                                    ğŸŒ™ Dark  âš™ Settings â”‚
-â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
-â”‚            â”‚  Rules                              [+ New Rule]       â”‚
-â”‚  > Dashboardâ”‚                                                      â”‚
-â”‚            â”‚  ğŸ” Search rules...        Sort: Modified â–¾  Filter:  â”‚
-â”‚  Rules     â”‚                                      [Global] [Local]  â”‚
-â”‚            â”‚                                                        â”‚
-â”‚  Settings  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
-â”‚            â”‚  â”‚ ğŸŸ¢ TypeScript Best Practices     GLOBAL    â‹®     â”‚ â”‚
-â”‚            â”‚  â”‚     Always use TypeScript for new...  Modified 2h â”‚ â”‚
-â”‚            â”‚  â”‚     ğŸ“ Gemini  ğŸ“ OpenCode  ğŸ“ Cline              â”‚ â”‚
-â”‚            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
-â”‚            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
-â”‚            â”‚  â”‚ ğŸŸ¢ React Component Guidelines    GLOBAL    â‹®     â”‚ â”‚
-â”‚            â”‚  â”‚     Use functional components with... Modified 1d â”‚ â”‚
-â”‚            â”‚  â”‚     ğŸ“ Gemini  ğŸ“ OpenCode                        â”‚ â”‚
-â”‚            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
-â”‚            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
-â”‚            â”‚  â”‚ âšª Monorepo Standards           LOCAL     â‹®     â”‚ â”‚
-â”‚            â”‚  â”‚     Use turborepo for caching...     Modified 3d  â”‚ â”‚
-â”‚            â”‚  â”‚     ğŸ“ OpenCode  ğŸ“ Cline  Path: /home/user/repo  â”‚ â”‚
-â”‚            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
-â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+src-tauri/src/
+â”œâ”€â”€ mcp/
+â”‚   â”œâ”€â”€ mod.rs           # Public API
+â”‚   â”œâ”€â”€ server.rs        # Server lifecycle
+â”‚   â”œâ”€â”€ protocol.rs      # JSON-RPC types
+â”‚   â”œâ”€â”€ handlers.rs      # Endpoint handlers
+â”‚   â””â”€â”€ transport.rs     # Stdio/HTTP transport
 ```
 
-**Rule Editor Page:**
+**Server Implementation:**
 
-```
-â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-â”‚  RuleWeaver                                    ğŸŒ™ Dark  âš™ Settings â”‚
-â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
-â”‚            â”‚  â† Back to Rules                   [Preview] [Save]   â”‚
-â”‚  Dashboard â”‚                                                        â”‚
-â”‚            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
-â”‚  Rules     â”‚  â”‚ TypeScript Best Pract...â”‚ Settings               â”‚ â”‚
-â”‚            â”‚  â”‚                         â”‚                        â”‚ â”‚
-â”‚  Settings  â”‚  â”‚ # TypeScript Standards  â”‚ Scope: â—‹ Global â— Localâ”‚ â”‚
-â”‚            â”‚  â”‚                         â”‚                        â”‚ â”‚
-â”‚            â”‚  â”‚ Always use TypeScript   â”‚ Target Paths:          â”‚ â”‚
-â”‚            â”‚  â”‚ for all new projects.   â”‚ ğŸ“ /home/user/project  â”‚ â”‚
-â”‚            â”‚  â”‚                         â”‚   [+ Add Path]         â”‚ â”‚
-â”‚            â”‚  â”‚ - Prefer interfaces     â”‚                        â”‚ â”‚
-â”‚            â”‚  â”‚   over types            â”‚ Adapters:              â”‚ â”‚
-â”‚            â”‚  â”‚ - Use strict mode       â”‚ â˜‘ Gemini  GEMINI.md    â”‚ â”‚
-â”‚            â”‚  â”‚ - Enable noImplicitAny  â”‚ â˜‘ OpenCode AGENTS.md   â”‚ â”‚
-â”‚            â”‚  â”‚                         â”‚ â˜ Cline    .clinerules â”‚ â”‚
-â”‚            â”‚  â”‚                         â”‚                        â”‚ â”‚
-â”‚            â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
-â”‚            â”‚  â”‚ Preview                           Gemini â–¾        â”‚ â”‚
-â”‚            â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
-â”‚            â”‚  â”‚ â”‚ <!-- Generated by RuleWeaver -->            â”‚  â”‚ â”‚
-â”‚            â”‚  â”‚ â”‚ ## TypeScript Standards                     â”‚  â”‚ â”‚
-â”‚            â”‚  â”‚ â”‚ Always use TypeScript...                   â”‚  â”‚ â”‚
-â”‚            â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
-â”‚            â”‚  â”‚ Will write to: ~/.gemini/GEMINI.md  [ğŸ“ Open]    â”‚ â”‚
-â”‚            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
-â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
-```
+```rust
+pub struct McpServer {
+    port: u16,
+    running: Arc<AtomicBool>,
+    commands: Arc<RwLock<Vec<Command>>>,
+    transport: Box<dyn Transport>,
+}
 
-**Sync Preview Dialog:**
+impl McpServer {
+    pub fn new(port: u16) -> Result<Self>;
+    pub async fn start(&self) -> Result<()>;
+    pub async fn stop(&self) -> Result<()>;
+    pub fn is_running(&self) -> bool;
+    pub fn get_status(&self) -> ServerStatus;
+}
 
+pub enum ServerStatus {
+    Running { port: u16, uptime: Duration },
+    Stopped,
+    Error(String),
+    Starting,
+}
 ```
-â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-â”‚  Sync Preview                                              [âœ•]  â”‚
-â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
-â”‚                                                                 â”‚
-â”‚  The following 5 files will be updated:                         â”‚
-â”‚                                                                 â”‚
-â”‚  âœ“ ~/.gemini/GEMINI.md              [Gemini]      Modified      â”‚
-â”‚  âœ“ ~/.opencode/AGENTS.md            [OpenCode]    Modified      â”‚
-â”‚  âš  /project/GEMINI.md               [Gemini]      CONFLICT      â”‚
-â”‚  âœ“ /project/.clinerules             [Cline]       New           â”‚
-â”‚  âœ“ /project/AGENTS.md               [OpenCode]    Unchanged     â”‚
-â”‚                                                                 â”‚
-â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
-â”‚                                                                 â”‚
-â”‚  âš  1 conflict detected - external changes found                â”‚
-â”‚                                                                 â”‚
-â”‚                                         [Cancel]  [Resolve & Sync]â”‚
-â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+
+**Tasks:**
+
+- Add `tokio` and `serde_json` dependencies to `Cargo.toml`
+- Evaluate and integrate chosen MCP SDK (or custom impl)
+- Create `src-tauri/src/mcp/mod.rs` module
+- Define JSON-RPC request/response types
+- Implement `McpServer` struct with state management
+- Implement `start()` method with configurable port binding
+- Implement `stop()` method with graceful shutdown
+- Implement basic `tools/list` endpoint (empty list initially)
+- Implement `initialize` endpoint (MCP protocol handshake)
+- Add server status tracking (running/stopped/error/starting)
+- Handle graceful shutdown on app close (Tauri lifecycle hook)
+- Add MCP server configuration persistence (port, auto-start)
+- Implement stdio transport layer
+- Implement connection logging
+
+**IPC Commands:**
+
+- `get_mcp_status` - Returns server status, port, uptime
+- `start_mcp_server` - Manually start server (returns error if already running)
+- `stop_mcp_server` - Manually stop server
+- `restart_mcp_server` - Stop then start
+- `get_mcp_connection_instructions` - Get setup instructions for clients
+- `get_mcp_logs` - Get recent connection logs
+
+**Configuration:**
+
+```rust
+pub struct McpConfig {
+    pub enabled: bool,
+    pub port: u16,
+    pub auto_start: bool,
+    pub log_level: LogLevel,
+    pub max_connections: u32,
+}
 ```
 
+#### Frontend Implementation
+
+**New UI Components:**
+
+- `McpStatusIndicator` - Green/red status light with tooltip
+- `McpConnectionPanel` - Full connection details
+- `ConnectionInstructions` - Copy-able config snippets
+- `McpSettingsSection` - Configuration UI
+- `McpLogsViewer` - Connection history
+
+**MCP Status Page:**
+
+- Server status indicator (Running/Stopped/Error/Starting)
+- Current port display
+- Uptime counter
+- Connection count (active clients)
+- Recent activity log
+- Start/Stop/Restart buttons
+- Error message display
+
+**Connection Instructions:**
+
+- Claude Code config (`claude_desktop_config.json`):
+  ```json
+  {
+    "mcpServers": {
+      "ruleweaver": {
+        "command": "ruleweaver-mcp",
+        "args": ["--port", "8080"]
+      }
+    }
+  }
+  ```
+- OpenCode config (`~/.opencode/config.json`):
+  ```json
+  {
+    "mcp": {
+      "servers": [
+        {
+          "name": "ruleweaver",
+          "url": "http://localhost:8080"
+        }
+      ]
+    }
+  }
+  ```
+- Copy buttons for each config
+- Step-by-step setup wizard
+
+**Settings Page Updates:**
+
+- MCP Server section with:
+  - Enable/disable toggle
+  - Port input with validation (1024-65535)
+  - Port conflict detection
+  - Auto-start on app launch toggle
+  - Max connections setting
+  - Log level selector
+  - Connection instructions link
+
+#### Error Handling
+
+| Error Type        | User Message                                           | Recovery                               |
+| ----------------- | ------------------------------------------------------ | -------------------------------------- |
+| Port in use       | "Port {port} is already in use by another application" | "Use different port" suggestion        |
+| Bind error        | "Cannot bind to {port}. Check firewall settings."      | "Try different port" or "Run as admin" |
+| Protocol error    | "Invalid MCP message received"                         | Log error, continue                    |
+| Transport error   | "Connection error: {details}"                          | Auto-restart server                    |
+| Client disconnect | Silent (expected)                                      | None                                   |
+
+#### Documentation Tasks
+
+- [ ] Document MCP protocol support
+- [ ] Document connection setup for Claude Code
+- [ ] Document connection setup for OpenCode
+- [ ] Document MCP troubleshooting
+- [ ] Add MCP architecture diagram
+
+#### Tests
+
+**Unit Tests (Rust):**
+
+- [ ] `test_server_initialization` - Happy path
+- [ ] `test_server_start_success` - Server starts
+- [ ] `test_server_stop_success` - Server stops gracefully
+- [ ] `test_server_double_start_fails` - Error handling
+- [ ] `test_server_port_already_in_use` - Port conflict
+- [ ] `test_jsonrpc_initialize_request` - Protocol handshake
+- [ ] `test_jsonrpc_tools_list_request` - Tools endpoint
+- [ ] `test_jsonrpc_invalid_request` - Error handling
+- [ ] `test_graceful_shutdown` - Cleanup
+- [ ] `test_status_tracking` - State machine
+
+**Integration Tests:**
+
+- [ ] `test_mcp_server_lifecycle` - Full start/stop flow
+- [ ] `test_mcp_client_connection` - Real client connection
+- [ ] `test_concurrent_client_connections` - Multi-client
+- [ ] `test_port_conflict_handling` - Real port binding
+
+**Frontend Tests:**
+
+- [ ] Test McpStatusIndicator shows correct colors
+- [ ] Test ConnectionInstructions copy buttons work
+- [ ] Test port validation in settings
+
 ---
 
-### Phase 1.4: The File Sync Engine (Issue #4)
+### Phase 2.3: Command Management System (Issue #6)
 
-**Goal:** Build adapter-based sync system with excellent user feedback and transparency.
+**Goal:** Create full CRUD system for custom commands with script templates, dynamic arguments, and in-app testing.
 
 #### Backend Implementation
 
-- [ ] Define `SyncAdapter` Rust trait with format and path methods
-- [ ] Implement `GeminiAdapter` for GEMINI.md format
-- [ ] Implement `OpenCodeAdapter` for AGENTS.md format
-- [ ] Implement `ClineAdapter` for .clinerules format
-- [ ] Create SyncEngine orchestrator that runs all active adapters
-- [ ] Implement file hash tracking for conflict detection
-- [ ] Create IPC command `sync_rules` to trigger sync
-- [ ] Create IPC command `preview_sync` to get planned changes without writing
-- [ ] Handle edge cases (missing directories, permission errors)
+**Data Model:**
 
-#### Sync UX Flow
+```rust
+// src-tauri/src/models/command.rs
+pub struct Command {
+    pub id: String,
+    pub name: String,
+    pub description: String,
+    pub script: String,           // Template with {{arg}} placeholders
+    pub arguments: Vec<CommandArgument>,
+    pub expose_via_mcp: bool,
+    pub working_directory: Option<String>,  // Optional cwd
+    pub environment_variables: HashMap<String, String>,  // Optional env vars
+    pub timeout_seconds: u32,     // Default 60
+    pub created_at: i64,
+    pub updated_at: i64,
+}
 
-```
-User clicks "Sync"
-    â†“
-Show Sync Preview Dialog
-    - List all files that will be written
-    - Highlight conflicts in yellow/warning
-    - Show new files with green checkmark
-    â†“
-User confirms or cancels
-    â†“
-If conflicts exist â†’ Show Conflict Resolution Dialog
-    - For each conflict: show diff, allow overwrite/keep/cancel
-    â†“
-Execute sync with progress indicator
-    - Per-file status updates
-    - Success/error per file
-    â†“
-Show Sync Results Summary
-    - X files written successfully
-    - Y files skipped (conflicts kept)
-    - Z errors
-    - Clickable file paths to open in explorer
-    â†“
-Dismiss or view details
+pub struct CommandArgument {
+    pub name: String,
+    pub description: String,
+    pub arg_type: ArgumentType,   // string, number, boolean, enum
+    pub required: bool,
+    pub default_value: Option<String>,
+    pub enum_values: Option<Vec<String>>,  // For enum type
+}
+
+pub enum ArgumentType {
+    String,
+    Number,
+    Boolean,
+    Enum(Vec<String>),
+}
 ```
 
-#### Sync Preview Dialog
+**File Storage (YAML + Markdown, same pattern as Rules):**
 
-- [ ] List view of all files to be written
-- [ ] Status indicators: New, Modified, Conflict, Unchanged
-- [ ] File path display with "Open folder" icon
-- [ ] Adapter badge for each file
-- [ ] "Dry Run" checkbox (preview only, no writes)
-- [ ] "Sync" button (enabled only if no unresolved conflicts)
-- [ ] Summary counts at top
+```
+~/.ruleweaver/commands/
+  â”œâ”€â”€ 000-format-code.md
+  â””â”€â”€ 001-run-tests.md
+```
 
-#### Conflict Resolution Dialog
+**File Format:**
 
-- [ ] File path prominently displayed
-- [ ] Side-by-side diff view (Current vs Incoming)
-- [ ] Line numbers for context
-- [ ] Resolution options:
-  - "Overwrite external changes"
-  - "Keep external changes" (skip this file)
-  - "Cancel sync"
-- [ ] "Apply to all conflicts" checkbox
+```markdown
+---
+id: cmd-123
+name: "Format Code"
+description: "Run prettier on the specified files"
+script: "npx prettier --write {{files}}"
+arguments:
+  - name: files
+    description: "Files to format"
+    type: string
+    required: true
+exposeViaMcp: true
+workingDirectory: null
+environmentVariables: {}
+timeoutSeconds: 60
+createdAt: 2024-01-15T10:30:00Z
+updatedAt: 2024-01-15T10:30:00Z
+---
 
-#### Sync Progress Indicator
+Additional documentation about this command...
+```
 
-- [ ] Modal overlay during sync
-- [ ] Progress bar: "Writing file X of Y"
-- [ ] Current file name display
-- [ ] Per-file status ticks (âœ“ success, âœ— error)
-- [ ] Cancel button (stops after current file)
+**Rust Module Structure:**
 
-#### Sync Results Summary
+```
+src-tauri/src/
+â”œâ”€â”€ commands/
+â”‚   â”œâ”€â”€ mod.rs           # Existing rule commands
+â”‚   â””â”€â”€ command_commands.rs  # New command CRUD
+â”œâ”€â”€ models/
+â”‚   â”œâ”€â”€ mod.rs
+â”‚   â”œâ”€â”€ rule.rs
+â”‚   â””â”€â”€ command.rs       # New
+```
 
-- [ ] Success count with green checkmark
-- [ ] Conflict count (if any kept) with yellow warning
-- [ ] Error count (if any) with red X
-- [ ] Expandable list of all files with status
-- [ ] Clickable paths open file in explorer
-- [ ] "View Sync History" link
+**Tasks:**
 
-#### Sync History (Settings/Activity Page)
+- Create `src-tauri/src/models/command.rs` module
+- Define `Command` and `CommandArgument` structs with serde
+- Define `ArgumentType` enum with JSON Schema conversion
+- Add `commands` table to SQLite (for index/cache only)
+- Implement `load_commands_from_disk()` using file storage
+- Implement `save_command_to_disk()` with YAML frontmatter
+- Create commands directory structure (`~/.ruleweaver/commands/`)
+- Implement IPC command: `get_all_commands`
+- Implement IPC command: `get_command_by_id`
+- Implement IPC command: `create_command`
+- Implement IPC command: `update_command`
+- Implement IPC command: `delete_command`
+- Implement script template parser (find `{{arg}}` placeholders)
+- Implement template argument validator (ensure all args have definitions)
+- Implement script injection prevention:
+  - Escape shell metacharacters in arguments
+  - Validate argument values against type
+  - Block dangerous patterns (rm -rf, etc.)
+- Implement IPC command: `test_command` with process spawn
+- Implement timeout handling for test execution
+- Capture stdout/stderr with size limits (max 10MB)
+- Return structured test result with exit code, output, duration
+
+**Script Template Engine:**
 
-- [ ] Table of past sync operations
-- [ ] Columns: Timestamp, Files Written, Status, Triggered By
-- [ ] Expandable to see per-file details
-- [ ] Filter by date range
-- [ ] Export history as JSON/CSV
+```rust
+pub struct TemplateEngine;
+
+impl TemplateEngine {
+    pub fn extract_placeholders(script: &str) -> Vec<String>;
+    pub fn validate_template(script: &str, args: &[CommandArgument]) -> Result<()>;
+    pub fn render_script(script: &str, values: &HashMap<String, String>) -> Result<String>;
+    pub fn escape_shell_arg(value: &str) -> String;
+    pub fn detect_dangerous_patterns(script: &str) -> Vec<String>;
+}
+```
 
-#### Adapter-Specific Headers
+**Security Measures:**
+
+- Escape all arguments before shell execution
+- Validate argument types (string, number, boolean, enum)
+- Block dangerous patterns: `rm -rf`, `> /dev/null`, `|`, `;`, `&&`, `` ` ``, `$()`
+- Timeout all executions
+- Size limit on output (prevent memory exhaustion)
+
+#### Frontend Implementation
+
+**New UI Components:**
+
+- `CommandsPage` - Main commands list
+- `CommandCard` - Individual command display
+- `CommandEditor` - Full editor
+- `ScriptEditor` - Code editor for scripts
+- `ArgumentBuilder` - Dynamic argument form builder
+- `ArgumentTypeSelector` - Type selection dropdown
+- `McpSchemaPreview` - JSON schema preview
+- `CommandTester` - In-app testing panel
+- `TestOutputViewer` - Stdout/stderr display
+- `ExecutionTimeDisplay` - Duration formatting
+
+**Commands Page:**
+
+- Similar layout to Rules page
+- List view with: name, description, MCP badge, argument count, last modified
+- Search bar with debounced filtering
+- Sort dropdown: Name (A-Z, Z-A), Date Modified, Has Arguments
+- Filter chips: Exposed via MCP, Has Arguments, Recently Used
+- Enable/disable toggle per command
+- Quick test button (opens test panel)
+- Overflow menu: Edit, Duplicate, Delete, View History
+- Bulk selection with bulk actions
+
+**Command Editor:**
+
+- **Header:** Name input, description textarea
+- **Script Section:**
+  - Monaco/CodeMirror editor with shell syntax highlighting
+  - Placeholder highlighting (`{{arg}}` in different color)
+  - Line numbers
+  - Placeholder validation (underlines undefined placeholders)
+- **Arguments Section:**
+  - Dynamic list of argument definitions
+  - Add/Remove/Drag to reorder
+  - Each argument card:
+    - Name input (must match placeholder)
+    - Description textarea
+    - Type selector (String, Number, Boolean, Enum)
+    - Required checkbox
+    - Default value input (type-specific)
+    - Enum values textarea (for enum type)
+- **Settings Section:**
+  - MCP exposure toggle
+  - Working directory input (optional)
+  - Environment variables key-value pairs
+  - Timeout slider (5-300 seconds)
+- **MCP Schema Preview Panel:**
+  - Read-only JSON preview of generated tool schema
+  - Copy button
+  - Validates in real-time
+- **Test Panel:**
+  - Input fields for each argument (dynamic based on type)
+  - "Test Run" button with loading state
+  - Output display:
+    - Exit code badge (green for 0, red for non-zero)
+    - Execution time
+    - Stdout tab (with syntax highlighting if detectable)
+    - Stderr tab
+    - Copy output buttons
+  - Clear output button
+
+**TypeScript Types:**
 
-Each synced file includes a header identifying RuleWeaver as the source:
+```typescript
+// types/command.ts
+export type ArgumentType = "string" | "number" | "boolean" | "enum";
 
-```markdown
-<!-- Generated by RuleWeaver - Do not edit manually -->
-<!-- Last synced: 2026-02-21T15:30:00Z -->
-<!-- Rules: general-tech-stack, monorepo-standards -->
+export interface CommandArgument {
+  name: string;
+  description: string;
+  type: ArgumentType;
+  required: boolean;
+  defaultValue?: string;
+  enumValues?: string[];
+}
 
-# [Adapter-specific content follows]
+export interface Command {
+  id: string;
+  name: string;
+  description: string;
+  script: string;
+  arguments: CommandArgument[];
+  exposeViaMcp: boolean;
+  workingDirectory: string | null;
+  environmentVariables: Record<string, string>;
+  timeoutSeconds: number;
+  createdAt: number;
+  updatedAt: number;
+}
+
+export interface TestCommandResult {
+  success: boolean;
+  exitCode: number;
+  stdout: string;
+  stderr: string;
+  durationMs: number;
+  error?: string;
+}
 ```
 
-This allows:
+**State Management:**
 
-- Conflict detection (if header missing or modified)
-- Attribution back to RuleWeaver
-- List of source rules in generated file
+```typescript
+// stores/commandsStore.ts
+interface CommandsState {
+  commands: Command[];
+  selectedCommand: Command | null;
+  isLoading: boolean;
+  error: string | null;
+  testResults: Map<string, TestCommandResult>;
+
+  fetchCommands: () => Promise<void>;
+  createCommand: (input: CreateCommandInput) => Promise<void>;
+  updateCommand: (id: string, input: UpdateCommandInput) => Promise<void>;
+  deleteCommand: (id: string) => Promise<void>;
+  testCommand: (id: string, args: Record<string, unknown>) => Promise<TestCommandResult>;
+  selectCommand: (command: Command | null) => void;
+}
+```
 
-#### SyncAdapter Trait
+#### Sync Adapter Updates for Commands
+
+Extend `SyncAdapter` trait:
 
 ```rust
 pub trait SyncAdapter: Send + Sync {
-    fn id(&self) -> &str;
-    fn name(&self) -> &str;
-    fn file_name(&self) -> &str;
-    fn icon(&self) -> &'static str; // Icon identifier for UI
-    fn description(&self) -> &str;
-    fn format_content(&self, rules: &[Rule]) -> String;
-    fn get_target_path(&self, scope: &Scope, local_path: Option<&str>) -> PathBuf;
-    fn is_enabled(&self, db: &Database) -> bool;
+    // Existing rule methods...
+
+    // New command methods
+    fn format_commands_content(&self, commands: &[Command]) -> String;
+    fn get_command_file_name(&self) -> &str;
+    fn get_command_global_path(&self) -> Result<PathBuf>;
 }
 ```
 
-#### Adapter Output Formats
-
-GEMINI.md:
+**Command Sync Output:**
 
-```markdown
-<!-- Generated by RuleWeaver - Do not edit manually -->
-<!-- Last synced: 2026-02-21T15:30:00Z -->
+Gemini CLI (`~/.gemini/COMMANDS.toml`):
 
-<!-- Rule: General Tech Stack -->
-
-Always use TypeScript.
+```toml
+# Generated by RuleWeaver - Do not edit manually
+# Last synced: 2024-01-15T10:30:00Z
 
-<!-- Rule: Monorepo Standards -->
+[[command]]
+name = "format-code"
+description = "Run prettier on files"
+script = "npx prettier --write {{files}}"
 
-Use turborepo caching.
+[command.arguments]
+files = { type = "string", required = true }
 ```
 
-AGENTS.md:
+Claude Code (`~/.claude/COMMANDS.md`):
 
 ```markdown
 <!-- Generated by RuleWeaver - Do not edit manually -->
-<!-- Last synced: 2026-02-21T15:30:00Z -->
+<!-- Last synced: 2024-01-15T10:30:00Z -->
 
-## General Tech Stack
+## format-code
 
-Always use TypeScript.
+**Description:** Run prettier on files
 
-## Monorepo Standards
+**Usage:**
+```
+
+/format-code files=<path>
 
-Use turborepo caching.
 ```
 
-.clinerules:
+**Arguments:**
+- `files` (string, required): Files to format
+```
+
+OpenCode (`~/.opencode/COMMANDS.md`):
 
 ```markdown
-# Generated by RuleWeaver - Do not edit manually
+# RuleWeaver Commands
 
-# Last synced: 2026-02-21T15:30:00Z
+## format-code
 
-# Rule: General Tech Stack
+Run prettier on files.
 
-Always use TypeScript.
+**Command:** `npx prettier --write {{files}}`
 
-# Rule: Monorepo Standards
+**Parameters:**
 
-Use turborepo caching.
+- `files` (string, required)
 ```
 
-#### IPC Commands
-
-- `sync_rules` - Execute full sync, return SyncResult
-- `preview_sync` - Return planned changes without writing
-- `resolve_conflict` - Resolve a specific conflict
-- `get_sync_history` - Get paginated sync history
-- `get_file_preview` - Preview formatted output for specific adapter
-
-#### Error Handling UX
+**Tasks:**
 
-| Error Type          | User Message                                        | Recovery Action           |
-| ------------------- | --------------------------------------------------- | ------------------------- |
-| Permission denied   | "Cannot write to {path}. Check folder permissions." | "Open folder" button      |
-| Directory not found | "Target directory doesn't exist"                    | "Create directory" option |
-| File locked         | "File is in use by another application"             | "Retry" button            |
-| Disk full           | "Not enough disk space"                             | None, show alert          |
-| Path too long       | "File path exceeds system limit"                    | Suggest shorter path      |
+- Extend `SyncAdapter` trait with command methods
+- Implement `format_commands_content()` for each adapter
+- Implement `get_command_file_name()` for each adapter
+- Implement `get_command_global_path()` for each adapter
+- Update `SyncEngine` to sync commands alongside rules
+- Add command file generation to sync process
+
+#### Error Handling
+
+| Error Type                | User Message                                       | Recovery                  |
+| ------------------------- | -------------------------------------------------- | ------------------------- |
+| Template syntax error     | "Invalid placeholder syntax: {{invalid}}"          | Highlight error location  |
+| Undefined placeholder     | "Placeholder {{arg}} not defined in arguments"     | "Add argument" quick fix  |
+| Unused argument           | "Argument 'foo' is defined but not used in script" | Warning only              |
+| Script injection detected | "Dangerous pattern detected in script"             | Block save, show patterns |
+| Type mismatch             | "Expected string, got number for argument 'foo'"   | Validation error          |
+| Timeout                   | "Command exceeded timeout of {X}s"                 | Show partial output       |
+| Command not found         | "Script interpreter not found"                     | Check PATH settings       |
+| Permission denied         | "Cannot execute script: permission denied"         | "Open folder" button      |
+
+#### Documentation Tasks
+
+- [ ] Document Command file format (YAML frontmatter)
+- [ ] Document script template syntax
+- [ ] Document available argument types
+- [ ] Document security restrictions
+- [ ] Add command examples and best practices
+- [ ] Document MCP tool naming conventions
 
 #### Tests
 
-- [ ] Unit tests for each adapter's format_content
-- [ ] Unit tests for path resolution (global/local)
-- [ ] Unit tests for conflict detection (hash matching)
-- [ ] Unit tests for header generation
-- [ ] Integration tests for full sync flow
-- [ ] Integration tests for conflict resolution flow
-- [ ] Integration tests for error scenarios
+**Unit Tests (Rust):**
+
+- [ ] `test_command_serialization` - Round-trip
+- [ ] `test_extract_placeholders_simple` - Basic case
+- [ ] `test_extract_placeholders_multiple` - Multiple args
+- [ ] `test_extract_placeholders_nested` - Complex case
+- [ ] `test_validate_template_success` - Happy path
+- [ ] `test_validate_template_undefined_placeholder` - Error case
+- [ ] `test_render_script_success` - Template rendering
+- [ ] `test_render_script_escaping` - Injection prevention
+- [ ] `test_escape_shell_arg_special_chars` - Security
+- [ ] `test_detect_dangerous_patterns_rm_rf` - Security
+- [ ] `test_detect_dangerous_patterns_pipes` - Security
+- [ ] `test_test_command_success` - Happy path
+- [ ] `test_test_command_failure` - Non-zero exit
+- [ ] `test_test_command_timeout` - Timeout handling
+- [ ] `test_test_command_large_output` - Size limits
+- [ ] `test_crud_create_command` - Create
+- [ ] `test_crud_update_command` - Update
+- [ ] `test_crud_delete_command` - Delete
+- [ ] `test_adapter_format_commands_gemini` - Gemini format
+- [ ] `test_adapter_format_commands_opencode` - OpenCode format
+
+**Integration Tests:**
+
+- [ ] `test_command_full_lifecycle` - Create, test, delete
+- [ ] `test_command_sync_to_files` - File generation
+- [ ] `test_command_security_boundaries` - Injection attempts
+- [ ] `test_concurrent_command_editing` - Race conditions
+
+**Frontend Tests:**
+
+- [ ] Test CommandEditor renders all fields
+- [ ] Test placeholder validation in ScriptEditor
+- [ ] Test ArgumentBuilder add/remove/reorder
+- [ ] Test MCP schema preview updates
+- [ ] Test CommandTester executes and displays output
+- [ ] Test type-specific input fields
 
 ---
 
-## 3. Execution Checklist
-
-### Setup & Foundation
-
-- [ ] Create feature branch `feature/phase-1-foundation`
-- [ ] Initialize Tauri project with React + TypeScript
-- [ ] Configure TailwindCSS with design tokens
-- [ ] Install and setup shadcn/ui components
-- [ ] Configure ESLint, Prettier, TypeScript strict mode
-- [ ] Setup Vitest for frontend testing
-- [ ] Setup Rust testing infrastructure
-- [ ] Create directory structure per architecture.md
-
-### Phase 1.2: Data Storage
-
-- [ ] Create Rust models for Rule, Scope, TargetDefinition
-- [ ] Add rusqlite and serde dependencies to Cargo.toml
-- [ ] Implement database manager with connection pooling
-- [ ] Create migrations system with initial schema
-- [ ] Implement CRUD operations for rules
-- [ ] Create custom error types for database operations
-- [ ] Implement all Tauri IPC commands for rules
-- [ ] Get AppData path working cross-platform
-- [ ] Write unit tests for database manager
-- [ ] Write unit tests for CRUD operations
-- [ ] Write unit tests for IPC command handlers
-
-### Phase 1.3: GUI
-
-#### Layout & Navigation
-
-- [ ] MainLayout with collapsible sidebar
-- [ ] Sidebar navigation (Dashboard, Rules, Settings)
-- [ ] Header with theme toggle
-- [ ] Keyboard navigation support
-
-#### Dashboard
-
-- [ ] Welcome card with app description
-- [ ] "How it works" visual diagram
-- [ ] Stats display (total rules, global, local, last sync)
-- [ ] Empty state with "Create first rule" CTA
-- [ ] Quick-start templates carousel
-- [ ] Recent activity feed
-
-#### Rules List
-
-- [ ] Search bar with instant filtering
-- [ ] Sort dropdown
-- [ ] Filter chips (Global/Local)
-- [ ] Adapter filter dropdown
-- [ ] Rule cards with enable/disable toggle
-- [ ] Overflow menu (Edit, Duplicate, Delete)
-- [ ] Bulk selection and actions
-- [ ] Empty state with templates option
-
-#### Rule Editor
-
-- [ ] Three-panel layout (list, editor, preview)
-- [ ] Rule name input with validation
-- [ ] Markdown editor with formatting toolbar
-- [ ] Word/character count
-- [ ] Autosave indicator
-- [ ] Settings panel (scope, paths, adapters)
-- [ ] Preview panel with adapter tabs
-- [ ] File path display with "Open folder" link
-
-#### Settings Page
-
-- [ ] App data location display
-- [ ] "Open in Explorer" button
-- [ ] Default scope selection
-- [ ] Default adapters selection
-- [ ] Theme toggle (Light/Dark/System)
-- [ ] Adapters enable/disable section
-- [ ] About section with version
-
-#### Dialogs
-
-- [ ] Create Rule dialog with template picker
-- [ ] Delete confirmation dialog
-- [ ] Conflict resolution dialog with diff view
-- [ ] Sync preview dialog
-
-#### Feedback & Notifications
-
-- [ ] Toast notification system
-- [ ] Undo toast for deletions
-- [ ] Loading skeletons
-- [ ] Error boundaries
-- [ ] Optimistic UI updates
+### Phase 2.4: Command Execution & MCP Integration (Issue #7)
 
-#### Keyboard Shortcuts
+**Goal:** Wire saved commands to the MCP server's `tools/list` and implement secure `tools/call` execution.
 
-- [ ] Ctrl+N (New rule)
-- [ ] Ctrl+S (Save)
-- [ ] Ctrl+Shift+S (Sync)
-- [ ] Ctrl+F (Search)
-- [ ] Ctrl+, (Settings)
-- [ ] ? (Show shortcuts)
+#### Backend Implementation
 
-#### Accessibility
+**MCP Tool Schema Generation:**
 
-- [ ] Keyboard accessible all elements
-- [ ] Focus visible outlines
-- [ ] ARIA labels
-- [ ] Screen reader announcements
-- [ ] Color contrast (WCAG AA)
-- [ ] Reduced motion respect
+```rust
+impl Command {
+    pub fn to_tool_schema(&self) -> ToolSchema {
+        ToolSchema {
+            name: self.name.to_snake_case(),
+            description: self.description.clone(),
+            input_schema: self.build_input_schema(),
+        }
+    }
 
-#### Tests
+    fn build_input_schema(&self) -> Value {
+        let mut properties = Map::new();
+        let mut required = Vec::new();
+
+        for arg in &self.arguments {
+            let property = match arg.arg_type {
+                ArgumentType::String => json!({
+                    "type": "string",
+                    "description": arg.description
+                }),
+                ArgumentType::Number => json!({
+                    "type": "number",
+                    "description": arg.description
+                }),
+                ArgumentType::Boolean => json!({
+                    "type": "boolean",
+                    "description": arg.description
+                }),
+                ArgumentType::Enum(values) => json!({
+                    "type": "string",
+                    "description": arg.description,
+                    "enum": values
+                }),
+            };
+
+            properties.insert(arg.name.clone(), property);
+
+            if arg.required {
+                required.push(json!(arg.name.clone()));
+            }
+        }
+
+        json!({
+            "type": "object",
+            "properties": properties,
+            "required": required
+        })
+    }
+}
+```
 
-- [ ] Tests for MainLayout
-- [ ] Tests for RulesList
-- [ ] Tests for RuleEditor
-- [ ] Tests for RuleSettings
-- [ ] Tests for Settings page
-- [ ] Tests for all dialogs
-- [ ] Accessibility audit
-
-### Phase 1.4: Sync Engine
-
-#### Backend
-
-- [ ] SyncAdapter trait definition
-- [ ] GeminiAdapter implementation
-- [ ] OpenCodeAdapter implementation
-- [ ] ClineAdapter implementation
-- [ ] SyncEngine orchestrator
-- [ ] File hash tracking
-- [ ] sync_rules IPC command
-- [ ] preview_sync IPC command
-- [ ] resolve_conflict IPC command
-- [ ] get_sync_history IPC command
-
-#### Sync UX
-
-- [ ] Sync preview dialog
-- [ ] Conflict resolution dialog with diff
-- [ ] Sync progress indicator
-- [ ] Sync results summary
-- [ ] Sync history page/section
-- [ ] Error handling with recovery actions
+**MCP Server Integration:**
 
-#### Tests
+```rust
+impl McpServer {
+    pub fn register_commands(&self, commands: Vec<Command>) {
+        let mut cmds = self.commands.write().unwrap();
+        *cmds = commands.into_iter()
+            .filter(|c| c.expose_via_mcp)
+            .collect();
+    }
 
-- [ ] Unit tests for adapter format_content
-- [ ] Unit tests for path resolution
-- [ ] Unit tests for conflict detection
-- [ ] Unit tests for header generation
-- [ ] Integration tests for sync flow
-- [ ] Integration tests for conflict resolution
-- [ ] Integration tests for error scenarios
-
-### Polish & Verification
-
-- [ ] Run all lint commands (ESLint, Clippy)
-- [ ] Run all type checks (TypeScript, Rust)
-- [ ] Achieve 80% test coverage on new code
-- [ ] Manual end-to-end testing on Windows
-- [ ] Verify database persistence across app restarts
-- [ ] Verify sync writes files to correct locations
-- [ ] Review UI for consistency and polish
-- [ ] Ensure no hardcoded colors remain
+    pub fn list_tools(&self) -> Vec<ToolSchema> {
+        let cmds = self.commands.read().unwrap();
+        cmds.iter().map(|c| c.to_tool_schema()).collect()
+    }
 
----
+    pub async fn call_tool(&self, name: &str, args: Value) -> Result<CallToolResult> {
+        // 1. Find command by snake_case name
+        let command = self.find_command(name)?;
 
-## 4. Detailed Implementation Guides
+        // 2. Validate arguments against schema
+        self.validate_args(&command, &args)?;
 
-### Frontend State Management (Zustand)
+        // 3. Convert args to HashMap<String, String>
+        let arg_map = self.extract_args(&args)?;
 
-```typescript
-// stores/rulesStore.ts
-interface RulesState {
-  rules: Rule[];
-  selectedRule: Rule | null;
-  isLoading: boolean;
-  error: string | null;
+        // 4. Render script with arguments
+        let script = TemplateEngine::render_script(&command.script, &arg_map)?;
 
-  // Actions
-  fetchRules: () => Promise<void>;
-  createRule: (rule: CreateRuleInput) => Promise<void>;
-  updateRule: (id: string, rule: UpdateRuleInput) => Promise<void>;
-  deleteRule: (id: string) => Promise<void>;
-  selectRule: (rule: Rule | null) => void;
-}
+        // 5. Execute with timeout and capture output
+        let output = self.execute_script(&script, &command).await?;
 
-// stores/syncStore.ts
-interface SyncState {
-  isSyncing: boolean;
-  lastSyncTime: Date | null;
-  syncErrors: SyncError[];
-  conflicts: Conflict[];
+        // 6. Log execution
+        self.log_execution(&command, &args, &output).await?;
 
-  syncRules: () => Promise<void>;
-  resolveConflict: (conflictId: string, resolution: "overwrite" | "skip") => void;
+        // 7. Return MCP-compliant result
+        Ok(CallToolResult {
+            content: vec![TextContent {
+                text: format!("Exit code: {}\n\nstdout:\n{}\n\nstderr:\n{}",
+                    output.exit_code,
+                    output.stdout,
+                    output.stderr
+                ),
+            }],
+            is_error: output.exit_code != 0,
+        })
+    }
 }
 ```
 
-### TypeScript Types (mirroring Rust models)
-
-```typescript
-// types/rule.ts
-export type Scope = "global" | "local";
+**Secure Execution Engine:**
 
-export interface Rule {
-  id: string;
-  name: string;
-  content: string;
-  scope: Scope;
-  targetPaths: string[] | null;
-  enabledAdapters: AdapterType[];
-  createdAt: number;
-  updatedAt: number;
+```rust
+pub struct ExecutionEngine;
+
+impl ExecutionEngine {
+    pub async fn execute(
+        script: &str,
+        working_dir: Option<&str>,
+        env_vars: &HashMap<String, String>,
+        timeout_secs: u32,
+    ) -> Result<ExecutionOutput> {
+        let mut cmd = if cfg!(target_os = "windows") {
+            let mut c = std::process::Command::new("cmd");
+            c.arg("/C").arg(script);
+            c
+        } else {
+            let mut c = std::process::Command::new("sh");
+            c.arg("-c").arg(script);
+            c
+        };
+
+        // Set working directory
+        if let Some(dir) = working_dir {
+            cmd.current_dir(dir);
+        }
+
+        // Set environment variables
+        cmd.envs(env_vars);
+
+        // Execute with timeout
+        let output = tokio::time::timeout(
+            Duration::from_secs(timeout_secs as u64),
+            cmd.output()
+        ).await.map_err(|_| AppError::ExecutionTimeout)?;
+
+        let output = output?;
+
+        // Limit output size
+        let stdout = String::from_utf8_lossy(&output.stdout)
+            .into_owned()
+            .chars()
+            .take(10_000)
+            .collect();
+
+        let stderr = String::from_utf8_lossy(&output.stderr)
+            .into_owned()
+            .chars()
+            .take(10_000)
+            .collect();
+
+        Ok(ExecutionOutput {
+            exit_code: output.status.code().unwrap_or(-1),
+            stdout,
+            stderr,
+        })
+    }
 }
+```
 
-export type AdapterType = "gemini" | "opencode" | "cline";
+**Execution Logging:**
 
-export interface CreateRuleInput {
-  name: string;
-  content: string;
-  scope: Scope;
-  targetPaths?: string[];
-  enabledAdapters: AdapterType[];
+```rust
+pub struct ExecutionLog {
+    pub id: String,
+    pub command_id: String,
+    pub command_name: String,
+    pub arguments: Value,           // JSON
+    pub script_rendered: String,    // Script with args injected
+    pub stdout: String,
+    pub stderr: String,
+    pub exit_code: i32,
+    pub duration_ms: u64,
+    pub executed_at: DateTime<Utc>,
+    pub triggered_by: String,       // "mcp" or "test"
+    pub client_info: Option<String>, // MCP client identifier
 }
 
-export interface SyncResult {
-  success: boolean;
-  filesWritten: string[];
-  errors: SyncError[];
-  conflicts: Conflict[];
-}
+// Database schema
+CREATE TABLE execution_logs (
+    id TEXT PRIMARY KEY NOT NULL,
+    command_id TEXT NOT NULL,
+    command_name TEXT NOT NULL,
+    arguments TEXT NOT NULL,
+    script_rendered TEXT NOT NULL,
+    stdout TEXT,
+    stderr TEXT,
+    exit_code INTEGER NOT NULL,
+    duration_ms INTEGER NOT NULL,
+    executed_at INTEGER NOT NULL,
+    triggered_by TEXT NOT NULL,
+    client_info TEXT
+);
 
-export interface Conflict {
-  filePath: string;
-  adapterName: string;
-  localHash: string;
-  currentHash: string;
-}
+CREATE INDEX idx_execution_logs_command_id ON execution_logs(command_id);
+CREATE INDEX idx_execution_logs_executed_at ON execution_logs(executed_at);
 ```
 
-### Tauri IPC Integration Layer
+**IPC Commands:**
 
-```typescript
-// lib/tauri.ts
-import { invoke } from "@tauri-apps/api";
-
-export const api = {
-  rules: {
-    getAll: () => invoke<Rule[]>("get_all_rules"),
-    getById: (id: string) => invoke<Rule>("get_rule_by_id", { id }),
-    create: (input: CreateRuleInput) => invoke<Rule>("create_rule", { input }),
-    update: (id: string, input: UpdateRuleInput) => invoke<Rule>("update_rule", { id, input }),
-    delete: (id: string) => invoke<void>("delete_rule", { id }),
-  },
-  sync: {
-    syncRules: () => invoke<SyncResult>("sync_rules"),
-    getAppDataPath: () => invoke<string>("get_app_data_path"),
-    resolveConflict: (conflictId: string, resolution: string) =>
-      invoke<void>("resolve_conflict", { conflictId, resolution }),
-  },
-};
-```
+- `get_execution_history` - Get paginated execution logs
+- `get_execution_by_id` - Get single execution details
+- `clear_execution_history` - Delete old logs (with confirmation)
+- `get_command_execution_stats` - Stats per command (success rate, avg duration)
 
-### Markdown Editor Implementation
+#### Frontend Implementation
 
-Use `@uiw/react-md-editor` or similar with:
+**New UI Components:**
 
-- Split-pane live preview
-- Syntax highlighting
-- Toolbar with common markdown actions
-- Controlled component pattern for form integration
+- `ExecutionHistoryPage` - Full history view
+- `ExecutionLogTable` - Paginated table
+- `ExecutionLogDetail` - Expanded view with full output
+- `ExecutionStats` - Charts/graphs of command usage
+- `McpConnectionStatus` - Real-time connection indicator
+- `RecentExecutions` - Live feed of recent calls
 
-```typescript
-// components/RuleEditor.tsx
-import MDEditor from '@uiw/react-md-editor';
-
-export function RuleEditor({ value, onChange }: RuleEditorProps) {
-  return (
-    <div className="h-full" data-color-mode="system">
-      <MDEditor
-        value={value}
-        onChange={onChange}
-        preview="live"
-        height="100%"
-        visibleDragbar={false}
-      />
-    </div>
-  );
-}
-```
+**Execution History Page:**
 
-### Adapter Selection UI
+- Table columns: Timestamp, Command, Arguments, Exit Code, Duration, Triggered By
+- Expandable rows showing full output
+- Filter by: Command, Date Range, Success/Failure, Trigger Source
+- Export to CSV/JSON
+- Bulk delete old logs
+- Pagination (25/50/100 per page)
 
-```typescript
-// components/AdapterSelector.tsx
-const ADAPTERS = [
-  { id: "gemini", name: "Gemini CLI", file: "GEMINI.md", icon: GeminiIcon },
-  { id: "opencode", name: "OpenCode", file: "AGENTS.md", icon: OpenCodeIcon },
-  { id: "cline", name: "Cline", file: ".clinerules", icon: ClineIcon },
-] as const;
-
-// Checkbox group for selecting which adapters receive this rule
-```
+**Dashboard Updates:**
 
-### Conflict Resolution Flow
+- Recent executions widget (last 10)
+- MCP connection status indicator
+- Commands exposed via MCP count
+- Total executions today
+- Success rate chart
 
-1. User clicks "Sync Now"
-2. Backend checks file hashes for all target files
-3. If hash mismatch detected:
-   - Return conflicts in SyncResult
-   - Show modal with conflict details
-   - User chooses: "Overwrite" | "Keep External Changes" | "Cancel"
-4. On resolution, re-run sync with user's choice
+**Real-Time Updates:**
 
-### Error Handling Pattern (Rust)
+- WebSocket or polling for live execution feed
+- Toast notifications for new MCP invocations
+- Sound notification option (configurable)
 
-```rust
-// src/error.rs
-#[derive(Debug, thiserror::Error)]
-pub enum AppError {
-    #[error("Database error: {0}")]
-    Database(#[from] rusqlite::Error),
+#### Error Handling
 
-    #[error("IO error: {0}")]
-    Io(#[from] std::io::Error),
+| Error Type        | User Message                                        | Recovery                |
+| ----------------- | --------------------------------------------------- | ----------------------- |
+| Command not found | "Command '{name}' not found or not exposed via MCP" | Return error to client  |
+| Invalid arguments | "Invalid arguments: {validation_errors}"            | Return schema to client |
+| Execution timeout | "Command timed out after {X}s"                      | Return partial output   |
+| Execution error   | "Command failed with exit code {N}"                 | Return stderr to client |
+| Output too large  | "Output truncated (exceeded 10MB limit)"            | Return first/last 5MB   |
+| Logging error     | "Failed to log execution"                           | Continue without log    |
+| Client disconnect | Silent (expected during long execution)             | Continue execution      |
 
-    #[error("Rule not found: {id}")]
-    RuleNotFound { id: String },
+#### Documentation Tasks
 
-    #[error("Sync conflict detected: {file_path}")]
-    SyncConflict { file_path: String },
+- [ ] Document MCP tool execution flow
+- [ ] Document execution logging
+- [ ] Document error handling from client perspective
+- [ ] Add troubleshooting guide for MCP connections
+- [ ] Document performance considerations (timeouts, output limits)
 
-    #[error("Invalid input: {message}")]
-    InvalidInput { message: String },
-}
+#### Tests
 
-impl serde::Serialize for AppError {
-    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
-    where S: serde::Serializer {
-        serializer.serialize_str(&self.to_string())
-    }
-}
-```
+**Unit Tests (Rust):**
+
+- [ ] `test_to_tool_schema_simple` - Basic schema
+- [ ] `test_to_tool_schema_all_types` - All argument types
+- [ ] `test_to_tool_schema_required_optional` - Required fields
+- [ ] `test_find_command_by_name` - Lookup
+- [ ] `test_validate_args_success` - Valid args
+- [ ] `test_validate_args_missing_required` - Validation error
+- [ ] `test_validate_args_wrong_type` - Type error
+- [ ] `test_extract_args_conversion` - Arg extraction
+- [ ] `test_execute_success` - Happy path
+- [ ] `test_execute_failure` - Non-zero exit
+- [ ] `test_execute_timeout` - Timeout
+- [ ] `test_execute_large_output` - Truncation
+- [ ] `test_log_execution` - Audit trail
+- [ ] `test_windows_command` - Windows shell
+- [ ] `test_unix_command` - Unix shell
+
+**Integration Tests:**
+
+- [ ] `test_mcp_full_execution_flow` - End-to-end
+- [ ] `test_mcp_concurrent_executions` - Parallel commands
+- [ ] `test_mcp_client_reconnect` - Resilience
+- [ ] `test_execution_history_persistence` - Database
+
+**Frontend Tests:**
+
+- [ ] Test ExecutionHistoryPage renders correctly
+- [ ] Test filtering and pagination
+- [ ] Test real-time updates
+- [ ] Test export functionality
 
-### Database Schema (SQLite)
+---
 
-```sql
--- migrations/001_initial.sql
-CREATE TABLE rules (
-    id TEXT PRIMARY KEY NOT NULL,
-    name TEXT NOT NULL,
-    content TEXT NOT NULL,
-    scope TEXT NOT NULL CHECK(scope IN ('global', 'local')),
-    target_paths TEXT, -- JSON array
-    enabled_adapters TEXT NOT NULL, -- JSON array
-    created_at INTEGER NOT NULL,
-    updated_at INTEGER NOT NULL
-);
+### Phase 2.5: GUI Polish & World-Class UX
 
-CREATE TABLE sync_history (
-    id TEXT PRIMARY KEY NOT NULL,
-    file_path TEXT NOT NULL UNIQUE,
-    content_hash TEXT NOT NULL,
-    last_sync_at INTEGER NOT NULL
-);
+**Goal:** Ensure the UI meets "world-class UI/UX" standards per our rules.
 
-CREATE INDEX idx_rules_scope ON rules(scope);
-```
+#### Visual Polish
 
-### Rust IPC Commands Structure
+- [ ] Verify NO hardcoded colors (use Tailwind tokens/CSS variables)
+- [ ] Audit all components for color consistency
+- [ ] Ensure responsive design (1024px minimum, mobile-friendly where applicable)
+- [ ] Verify dark mode support throughout
+- [ ] Add smooth transitions/animations (respect reduced-motion)
+- [ ] Ensure consistent spacing (use design tokens)
+- [ ] Verify typography hierarchy
 
-```rust
-// src/commands/rules.rs
-#[tauri::command]
-pub async fn get_all_rules(db: State<'_, Database>) -> Result<Vec<Rule>, AppError> {
-    db.get_all_rules().await
-}
+#### Accessibility
 
-#[tauri::command]
-pub async fn create_rule(input: CreateRuleInput, db: State<'_, Database>) -> Result<Rule, AppError> {
-    // Validate input
-    // Generate UUID
-    // Set timestamps
-    // Insert into database
-    // Return created rule
-}
+- [ ] All interactive elements keyboard accessible
+- [ ] Focus visible outlines on all focusable elements
+- [ ] ARIA labels for all icons and non-text buttons
+- [ ] Screen reader announcements for toasts and status changes
+- [ ] Color contrast WCAG AA compliance (use contrast checker)
+- [ ] Skip navigation links
+- [ ] Form field labels and error associations
+- [ ] Modal/dialog focus trapping
+
+#### Keyboard Shortcuts
+
+- [ ] `Ctrl/Cmd + N` - New rule
+- [ ] `Ctrl/Cmd + Shift + N` - New command
+- [ ] `Ctrl/Cmd + S` - Save current item
+- [ ] `Ctrl/Cmd + Shift + S` - Sync all
+- [ ] `Ctrl/Cmd + F` - Focus search
+- [ ] `Ctrl/Cmd + ,` - Open settings
+- [ ] `Ctrl/Cmd + 1` - Go to Dashboard
+- [ ] `Ctrl/Cmd + 2` - Go to Rules
+- [ ] `Ctrl/Cmd + 3` - Go to Commands
+- [ ] `Escape` - Close dialogs/cancel
+- [ ] `?` - Show keyboard shortcuts help
+
+#### Feedback & Loading States
+
+- [ ] Skeleton loaders for all async data fetching
+- [ ] Loading spinners for actions
+- [ ] Progress indicators for long operations
+- [ ] Optimistic UI updates where appropriate
+- [ ] Error boundaries with friendly error messages
+- [ ] Toast notifications for all CRUD operations
+- [ ] Undo functionality for delete operations
+
+#### UI Component Inventory
+
+**Phase 2 New Components:**
+
+| Component              | Purpose                | Location             |
+| ---------------------- | ---------------------- | -------------------- |
+| FileStorageStatus      | Storage mode indicator | Header               |
+| MigrationDialog        | Migration UI           | Dialog               |
+| FilePathDisplay        | File path with copy    | Rule cards           |
+| McpStatusIndicator     | MCP connection status  | Header/Dashboard     |
+| McpConnectionPanel     | Connection details     | Settings             |
+| ConnectionInstructions | Setup guide            | Settings             |
+| McpLogsViewer          | Connection logs        | Settings             |
+| CommandsPage           | Commands list          | Page                 |
+| CommandCard            | Command display        | CommandsPage         |
+| CommandEditor          | Full command editor    | Page                 |
+| ScriptEditor           | Code editor            | CommandEditor        |
+| ArgumentBuilder        | Dynamic args form      | CommandEditor        |
+| ArgumentTypeSelector   | Type dropdown          | ArgumentBuilder      |
+| McpSchemaPreview       | JSON preview           | CommandEditor        |
+| CommandTester          | Test panel             | CommandEditor        |
+| TestOutputViewer       | Output display         | CommandTester        |
+| ExecutionHistoryPage   | History view           | Page                 |
+| ExecutionLogTable      | Paginated table        | ExecutionHistoryPage |
+| ExecutionLogDetail     | Expanded view          | ExecutionLogTable    |
+| ExecutionStats         | Usage charts           | Dashboard            |
+| RecentExecutions       | Live feed              | Dashboard            |
+
+---
+
+## 3. Execution Checklist
+
+### Phase 2.0: Project Setup
+
+- [ ] Create feature branch `feature/phase-2-mcp-commands`
+- [ ] Run all Phase 1 tests to establish baseline
+- [ ] Run lint and typecheck (should pass)
+- [ ] Verify CI/CD pipeline is green
+- [ ] Review and update any outdated dependencies
+
+### Phase 2.1: File-First Storage (Issue #14)
+
+**Backend:**
+
+- [ ] Add `serde_yaml`, `notify`, `glob` to Cargo.toml
+- [ ] Create `src-tauri/src/file_storage/mod.rs`
+- [ ] Create `src-tauri/src/file_storage/parser.rs` - YAML parsing
+- [ ] Create `src-tauri/src/file_storage/serializer.rs` - YAML generation
+- [ ] Create `src-tauri/src/file_storage/watcher.rs` - File watching
+- [ ] Create `src-tauri/src/file_storage/migration.rs` - Migration logic
+- [ ] Implement `load_rules_from_disk()` with directory traversal
+- [ ] Implement `save_rule_to_disk()` with atomic writes
+- [ ] Implement file watcher with debounced events
+- [ ] Create database migration v3 (remove content field from rules)
+- [ ] Update SQLite schema for index-only storage
+- [ ] Create `migrate_to_file_storage()` IPC command
+- [ ] Create `verify_file_storage_integrity()` health check
+- [ ] Implement `rollback_migration()` for safety
+- [ ] Update all existing rule IPC commands
+- [ ] Handle file permission errors
+- [ ] Handle concurrent editing conflicts
+- [ ] Handle large files with chunked reading
+- [ ] Handle special characters and Unicode
+- [ ] Handle duplicate IDs across directories
+- [ ] Handle orphaned files
+- [ ] Handle git merge conflicts
+
+**Frontend:**
+
+- [ ] Create `FileStorageStatus` component
+- [ ] Create `MigrationDialog` component with progress
+- [ ] Create `FilePathDisplay` component
+- [ ] Create `RevealInExplorerButton` component
+- [ ] Add "Open in Editor" button to rule cards
+- [ ] Show file path in rule detail view
+- [ ] Display file timestamps in UI
+- [ ] Add file system health indicators
+- [ ] Add storage mode indicator in settings
+
+**Documentation:**
+
+- [ ] Update README.md with file-based architecture
+- [ ] Document `.ruleweaver/rules/` directory structure
+- [ ] Document YAML frontmatter schema
+- [ ] Add migration guide for existing users
+- [ ] Document file watching behavior
+- [ ] Document manual editing best practices
+
+**Tests:**
+
+- [ ] Unit tests for YAML parsing (happy path, invalid, missing fields)
+- [ ] Unit tests for file I/O operations
+- [ ] Unit tests for migration (forward and rollback)
+- [ ] Unit tests for file watcher
+- [ ] Unit tests for edge cases (permissions, large files, Unicode)
+- [ ] Integration tests for full migration flow
+- [ ] Integration tests for git workflow compatibility
+- [ ] Frontend component tests
+- [ ] 80% coverage target (high-value tests only)
+
+### Phase 2.2: MCP Server (Issue #5)
+
+**Backend:**
+
+- [ ] Research and select MCP SDK (or custom implementation)
+- [ ] Add `tokio` dependency to Cargo.toml
+- [ ] Create `src-tauri/src/mcp/mod.rs`
+- [ ] Create `src-tauri/src/mcp/server.rs`
+- [ ] Create `src-tauri/src/mcp/protocol.rs` - JSON-RPC types
+- [ ] Create `src-tauri/src/mcp/handlers.rs` - Endpoint handlers
+- [ ] Create `src-tauri/src/mcp/transport.rs` - Stdio transport
+- [ ] Define JSON-RPC request/response types
+- [ ] Implement `McpServer` struct with state management
+- [ ] Implement `start()` with port binding
+- [ ] Implement `stop()` with graceful shutdown
+- [ ] Implement `initialize` endpoint
+- [ ] Implement `tools/list` endpoint (initially empty)
+- [ ] Implement connection logging
+- [ ] Add MCP configuration persistence
+- [ ] Create IPC commands: get_mcp_status, start_mcp_server, stop_mcp_server
+- [ ] Create IPC commands: restart_mcp_server, get_mcp_connection_instructions
+- [ ] Create IPC commands: get_mcp_logs
+- [ ] Implement port conflict detection
+- [ ] Handle graceful shutdown on app close
+
+**Frontend:**
+
+- [ ] Create `McpStatusIndicator` component
+- [ ] Create `McpConnectionPanel` component
+- [ ] Create `ConnectionInstructions` component
+- [ ] Create `McpLogsViewer` component
+- [ ] Create `McpSettingsSection` component
+- [ ] Build MCP status page with controls
+- [ ] Build connection instructions panel
+- [ ] Add MCP settings to Settings page
+- [ ] Add port configuration with validation
+- [ ] Add auto-start toggle
+- [ ] Add log level selector
+- [ ] Create copy buttons for client configs
+
+**Documentation:**
+
+- [ ] Document MCP protocol support
+- [ ] Document connection setup for Claude Code
+- [ ] Document connection setup for OpenCode
+- [ ] Document MCP troubleshooting
+- [ ] Add MCP architecture diagram
+
+**Tests:**
+
+- [ ] Unit tests for server initialization
+- [ ] Unit tests for start/stop lifecycle
+- [ ] Unit tests for JSON-RPC message handling
+- [ ] Unit tests for error handling
+- [ ] Integration tests for server lifecycle
+- [ ] Integration tests for client connection
+- [ ] Integration tests for concurrent clients
+- [ ] Integration tests for port conflicts
+- [ ] Frontend component tests
+- [ ] 80% coverage target
+
+### Phase 2.3: Command Management (Issue #6)
+
+**Backend:**
+
+- [ ] Create `src-tauri/src/models/command.rs`
+- [ ] Define `Command` struct with all fields
+- [ ] Define `CommandArgument` struct
+- [ ] Define `ArgumentType` enum
+- [ ] Add `commands` table to SQLite (index only)
+- [ ] Implement `load_commands_from_disk()`
+- [ ] Implement `save_command_to_disk()`
+- [ ] Create commands directory structure
+- [ ] Implement IPC: get_all_commands
+- [ ] Implement IPC: get_command_by_id
+- [ ] Implement IPC: create_command
+- [ ] Implement IPC: update_command
+- [ ] Implement IPC: delete_command
+- [ ] Create `TemplateEngine` struct
+- [ ] Implement `extract_placeholders()`
+- [ ] Implement `validate_template()`
+- [ ] Implement `render_script()`
+- [ ] Implement `escape_shell_arg()`
+- [ ] Implement `detect_dangerous_patterns()`
+- [ ] Block dangerous patterns (rm -rf, pipes, etc.)
+- [ ] Implement IPC: test_command
+- [ ] Implement timeout handling
+- [ ] Capture stdout/stderr with size limits
+- [ ] Extend `SyncAdapter` trait for commands
+- [ ] Implement command sync for Gemini (TOML)
+- [ ] Implement command sync for OpenCode (MD)
+- [ ] Implement command sync for Claude Code (MD)
+- [ ] Implement command sync for Cline (MD)
+
+**Frontend:**
+
+- [ ] Create TypeScript types for Command model
+- [ ] Create `commandsStore.ts` with Zustand
+- [ ] Create `CommandsPage` component
+- [ ] Create `CommandCard` component
+- [ ] Create `CommandEditor` component
+- [ ] Create `ScriptEditor` component (Monaco/CodeMirror)
+- [ ] Create `ArgumentBuilder` component
+- [ ] Create `ArgumentTypeSelector` component
+- [ ] Create `McpSchemaPreview` component
+- [ ] Create `CommandTester` component
+- [ ] Create `TestOutputViewer` component
+- [ ] Implement commands list view with search/sort/filter
+- [ ] Implement command editor with all sections
+- [ ] Implement dynamic argument builder
+- [ ] Implement script template validation
+- [ ] Implement MCP schema preview
+- [ ] Implement in-app testing with output display
+- [ ] Add TypeScript types for all components
+
+**Documentation:**
+
+- [ ] Document Command file format (YAML frontmatter)
+- [ ] Document script template syntax
+- [ ] Document available argument types
+- [ ] Document security restrictions
+- [ ] Add command examples and best practices
+- [ ] Document MCP tool naming conventions
+
+**Tests:**
+
+- [ ] Unit tests for Command model serialization
+- [ ] Unit tests for template parsing
+- [ ] Unit tests for template validation
+- [ ] Unit tests for script rendering
+- [ ] Unit tests for shell argument escaping
+- [ ] Unit tests for dangerous pattern detection
+- [ ] Unit tests for test execution (happy path)
+- [ ] Unit tests for test execution (failure paths)
+- [ ] Unit tests for timeout handling
+- [ ] Unit tests for CRUD operations
+- [ ] Unit tests for sync adapter extensions
+- [ ] Integration tests for full command lifecycle
+- [ ] Integration tests for security boundaries
+- [ ] Frontend component tests
+- [ ] 80% coverage target
+
+### Phase 2.4: MCP Execution (Issue #7)
+
+**Backend:**
+
+- [ ] Implement `to_tool_schema()` for Command
+- [ ] Implement `build_input_schema()` for JSON Schema
+- [ ] Implement `register_commands()` in McpServer
+- [ ] Implement `list_tools()` in McpServer
+- [ ] Implement `find_command_by_name()`
+- [ ] Implement argument validation against schema
+- [ ] Implement `extract_args()` for MCP requests
+- [ ] Implement `call_tool()` handler
+- [ ] Create `ExecutionEngine` struct
+- [ ] Implement `execute()` with Windows/Unix support
+- [ ] Implement working directory handling
+- [ ] Implement environment variable handling
+- [ ] Implement execution timeout
+- [ ] Implement stdout/stderr capture
+- [ ] Implement output size limiting
+- [ ] Create `execution_logs` table in SQLite
+- [ ] Implement execution logging
+- [ ] Create IPC: get_execution_history
+- [ ] Create IPC: get_execution_by_id
+- [ ] Create IPC: clear_execution_history
+- [ ] Create IPC: get_command_execution_stats
+- [ ] Handle execution errors gracefully
+- [ ] Return structured MCP responses
+
+**Frontend:**
+
+- [ ] Create `ExecutionHistoryPage` component
+- [ ] Create `ExecutionLogTable` component
+- [ ] Create `ExecutionLogDetail` component
+- [ ] Create `ExecutionStats` component
+- [ ] Create `McpConnectionStatus` component
+- [ ] Create `RecentExecutions` component
+- [ ] Build execution history page
+- [ ] Build paginated log table
+- [ ] Build expanded detail view
+- [ ] Build stats/charts for command usage
+- [ ] Add recent executions to Dashboard
+- [ ] Implement real-time updates
+- [ ] Add toast notifications for executions
+
+**Documentation:**
+
+- [ ] Document MCP tool execution flow
+- [ ] Document execution logging
+- [ ] Document error handling from client perspective
+- [ ] Add troubleshooting guide for MCP connections
+- [ ] Document performance considerations
+
+**Tests:**
+
+- [ ] Unit tests for tool schema generation
+- [ ] Unit tests for JSON Schema building
+- [ ] Unit tests for argument validation
+- [ ] Unit tests for argument extraction
+- [ ] Unit tests for script rendering with args
+- [ ] Unit tests for execution engine
+- [ ] Unit tests for Windows shell execution
+- [ ] Unit tests for Unix shell execution
+- [ ] Unit tests for timeout handling
+- [ ] Unit tests for output limiting
+- [ ] Unit tests for execution logging
+- [ ] Integration tests for full MCP execution flow
+- [ ] Integration tests for concurrent executions
+- [ ] Integration tests for client reconnection
+- [ ] Frontend component tests
+- [ ] 80% coverage target
+
+### Phase 2.5: Polish & Verification
+
+**Visual Polish:**
+
+- [ ] Verify NO hardcoded colors anywhere
+- [ ] Audit all components for color consistency
+- [ ] Verify responsive design (1024px minimum)
+- [ ] Verify dark mode support throughout
+- [ ] Add smooth transitions (respect reduced-motion)
+- [ ] Ensure consistent spacing
+- [ ] Verify typography hierarchy
+
+**Accessibility:**
+
+- [ ] Keyboard accessibility audit
+- [ ] Focus visible on all elements
+- [ ] ARIA labels for icons
+- [ ] Screen reader announcements
+- [ ] Color contrast WCAG AA check
+- [ ] Skip navigation links
+- [ ] Form labels and errors
+- [ ] Modal focus trapping
+
+**Keyboard Shortcuts:**
+
+- [ ] Implement Ctrl/Cmd + N (New rule)
+- [ ] Implement Ctrl/Cmd + Shift + N (New command)
+- [ ] Implement Ctrl/Cmd + S (Save)
+- [ ] Implement Ctrl/Cmd + Shift + S (Sync)
+- [ ] Implement Ctrl/Cmd + F (Search)
+- [ ] Implement Ctrl/Cmd + , (Settings)
+- [ ] Implement Ctrl/Cmd + 1/2/3 (Navigation)
+- [ ] Implement Escape (Close)
+- [ ] Implement ? (Shortcuts help)
+
+**Feedback & Loading:**
+
+- [ ] Skeleton loaders for async data
+- [ ] Loading spinners for actions
+- [ ] Progress indicators for long ops
+- [ ] Optimistic UI updates
+- [ ] Error boundaries
+- [ ] Toast notifications
+- [ ] Undo for delete
+
+**Quality Assurance:**
+
+- [ ] Run `npm run lint` - no warnings
+- [ ] Run `npm run typecheck` - no errors
+- [ ] Run `npm run lint:rust` - no warnings
+- [ ] Run `npm run test` - all passing
+- [ ] Run `npm run test:rust` - all passing
+- [ ] Verify 80% test coverage on new code
+- [ ] Manual testing on Windows
+- [ ] Test file migration from SQLite to files
+- [ ] Test MCP server connection from Claude Code
+- [ ] Test MCP server connection from OpenCode
+- [ ] Test command execution via MCP
+- [ ] Test in-app command testing
+- [ ] Test execution history and logging
+- [ ] Test sync of commands to files
+- [ ] Test all keyboard shortcuts
+- [ ] Test accessibility (keyboard-only navigation)
+- [ ] Test responsive design
+- [ ] Test dark mode
+- [ ] Test error scenarios
+- [ ] Verify all edge cases handled
+- [ ] Review UI consistency
+- [ ] Verify no hardcoded colors
+- [ ] Accessibility audit with screen reader
+
+**Documentation:**
+
+- [ ] Update main README.md with Phase 2 features
+- [ ] Document breaking changes
+- [ ] Update architecture diagram
+- [ ] Add troubleshooting section
+- [ ] Add FAQ for common issues
+- [ ] Update screenshots/GIFs
+
+---
+
+## 4. Technical Specifications
+
+### Dependencies (Rust)
 
-// src/commands/sync.rs
-#[tauri::command]
-pub async fn sync_rules(
-    db: State<'_, Database>,
-    sync_engine: State<'_, SyncEngine>,
-) -> Result<SyncResult, AppError> {
-    let rules = db.get_all_rules().await?;
-    sync_engine.sync_all(rules).await
+```toml
+# Add to src-tauri/Cargo.toml
+
+# File Storage
+serde_yaml = "0.9"              # YAML serialization
+notify = "6"                    # File system watching
+glob = "0.3"                    # File pattern matching
+
+# MCP Server
+tokio = { version = "1", features = ["full"] }  # Async runtime
+# Option 1: rmcp = "0.1"        # Rust MCP SDK (if available)
+# Option 2: jsonrpc-core = "18" # JSON-RPC framework
+# Option 3: Custom implementation with hyper/axum
+
+# Additional utilities
+indexmap = "2"                  # Ordered HashMap for YAML
+unicode-segmentation = "1"      # Unicode handling
+```
+
+### Dependencies (Frontend)
+
+```json
+// package.json additions
+{
+  "dependencies": {
+    "@monaco-editor/react": "^4.6.0" // For script editing (optional)
+  }
 }
 ```
 
-### Testing File Structure
+### File Locations
 
 ```
-src-tauri/
-â”œâ”€â”€ src/
-â”‚   â””â”€â”€ ...
-â””â”€â”€ tests/
-    â”œâ”€â”€ database_tests.rs
-    â”œâ”€â”€ sync_adapter_tests.rs
-    â””â”€â”€ integration_tests.rs
-
-src/
-â”œâ”€â”€ __tests__/
-â”‚   â”œâ”€â”€ components/
-â”‚   â”‚   â”œâ”€â”€ RulesList.test.tsx
-â”‚   â”‚   â”œâ”€â”€ RuleEditor.test.tsx
-â”‚   â”‚   â””â”€â”€ AdapterSelector.test.tsx
-â”‚   â”œâ”€â”€ stores/
-â”‚   â”‚   â””â”€â”€ rulesStore.test.ts
-â”‚   â””â”€â”€ lib/
-â”‚       â””â”€â”€ tauri.test.ts
+# Rule Files (Global)
+~/.ruleweaver/rules/                    # User home directory
+  â”œâ”€â”€ 000-global-coding.md
+  â””â”€â”€ 001-security-guidelines.md
+
+# Rule Files (Local - per project)
+{project}/.ruleweaver/rules/            # Project root
+  â”œâ”€â”€ 000-project-specific.md
+  â””â”€â”€ ...
+
+# Command Files (Global only for now)
+~/.ruleweaver/commands/                 # User home directory
+  â”œâ”€â”€ 000-format-code.md
+  â””â”€â”€ 001-run-tests.md
+
+# Database (Index/Cache only)
+%APPDATA%/RuleWeaver/ruleweaver.db      # Windows
+~/.local/share/RuleWeaver/ruleweaver.db # Linux
+~/Library/Application Support/RuleWeaver/ruleweaver.db # macOS
+
+# Synced Rule Outputs
+~/.gemini/GEMINI.md                     # Gemini CLI rules
+~/.opencode/AGENTS.md                   # OpenCode rules
+~/.clinerules                           # Cline rules
+~/.claude/CLAUDE.md                     # Claude Code rules
+~/.codex/CODEX.md                       # Codex rules
+~/.antigravity/ANTIGRAVITY.md           # Antigravity rules
+
+# Synced Command Outputs
+~/.gemini/COMMANDS.toml                 # Gemini CLI commands
+~/.opencode/COMMANDS.md                 # OpenCode commands
+~/.claude/COMMANDS.md                   # Claude Code commands
 ```
 
+### YAML Frontmatter Schema
+
+**Rules:**
+
+```yaml
+---
+id: string (UUID)              # Required: unique identifier
+name: string                   # Required: display name
+scope: "global" | "local"      # Required: scope type
+targetPaths: string[]          # Optional: for local scope
+enabledAdapters: string[]      # Required: gemini, opencode, cline, etc.
+enabled: boolean               # Required: active status
+createdAt: ISO8601             # Required: creation timestamp
+updatedAt: ISO8601             # Required: last modified
 ---
+```
 
-## 5. Technical Specifications
+**Commands:**
 
-### Dependencies (Rust)
+```yaml
+---
+id: string (UUID) # Required: unique identifier
+name: string # Required: display name
+description: string # Required: command description
+script: string # Required: script template
+arguments: # Required: argument definitions
+  - name: string
+    description: string
+    type: string | number | boolean | enum
+    required: boolean
+    defaultValue: string # Optional
+    enumValues: string[] # Optional (for enum type)
+exposeViaMcp: boolean # Required: expose as MCP tool
+workingDirectory: string # Optional: default working dir
+environmentVariables: # Optional: env vars
+  KEY: value
+timeoutSeconds: number # Required: default 60
+createdAt: ISO8601 # Required: creation timestamp
+updatedAt: ISO8601 # Required: last modified
+---
+```
 
-- `tauri` - Desktop framework
-- `rusqlite` - SQLite database
-- `serde` / `serde_json` - Serialization
-- `thiserror` - Error handling
-- `uuid` - ID generation
-- `sha2` - File hashing
+### IPC Commands Reference
 
-### Dependencies (Frontend)
+**File Storage:**
 
-- `react` / `react-dom` - UI framework
-- `@tauri-apps/api` - Tauri frontend API
-- `tailwindcss` - Styling
-- `@radix-ui/*` - shadcn/ui primitives
-- `react-hook-form` - Form handling
-- `zod` - Validation
-- `lucide-react` - Icons
-- `zustand` - State management
+- `migrate_to_file_storage() -> Result<MigrationReport>` - One-time migration
+- `verify_file_storage_integrity() -> Result<HealthReport>` - Health check
+- `rollback_migration() -> Result<()>` - Rollback to SQLite
+- `get_storage_type() -> StorageType` - "file" or "sqlite"
 
-### Testing Strategy
+**MCP Server:**
 
-- Frontend: Vitest + Testing Library for component tests
-- Backend: Rust built-in test framework for unit tests
-- Integration: Test full sync flow with temp directories
-- Coverage target: 80% (high-value tests only, no low-value tests)
+- `get_mcp_status() -> McpStatus` - Server status, port, uptime
+- `start_mcp_server() -> Result<()>` - Start server
+- `stop_mcp_server() -> Result<()>` - Stop server
+- `restart_mcp_server() -> Result<()>` - Restart server
+- `get_mcp_connection_instructions() -> ConnectionInstructions` - Setup guide
+- `get_mcp_logs(limit: u32) -> Vec<McpLogEntry>` - Connection logs
 
-### File Locations
+**Commands:**
+
+- `get_all_commands() -> Vec<Command>` - List all commands
+- `get_command_by_id(id: String) -> Command` - Get single command
+- `create_command(input: CreateCommandInput) -> Command` - Create command
+- `update_command(id: String, input: UpdateCommandInput) -> Command` - Update command
+- `delete_command(id: String) -> Result<()>` - Delete command
+- `test_command(id: String, args: Value) -> TestCommandResult` - Test execute
+
+**Execution:**
+
+- `get_execution_history(limit: u32, offset: u32) -> Vec<ExecutionLog>` - Paginated history
+- `get_execution_by_id(id: String) -> ExecutionLog` - Single execution details
+- `clear_execution_history(before: Option<DateTime>) -> Result<()>` - Delete old logs
+- `get_command_execution_stats(command_id: String) -> CommandStats` - Usage stats
+
+### Security Checklist
+
+**File System:**
+
+- [ ] All file paths validated before operations
+- [ ] Path traversal prevention (only allow within .ruleweaver directories)
+- [ ] File permission checks before read/write
+- [ ] Atomic file writes (write to temp, then rename)
+
+**Command Execution:**
 
-- Database: `%APPDATA%/RuleWeaver/rules.db` (Windows)
-- Global GEMINI.md: `~/.gemini/GEMINI.md`
-- Global AGENTS.md: `~/.opencode/AGENTS.md`
-- Local files: `{repo_path}/GEMINI.md`, `{repo_path}/AGENTS.md`, `{repo_path}/.clinerules`
+- [ ] All arguments escaped before shell execution
+- [ ] Dangerous patterns blocked (rm -rf, pipes, redirections, command substitution)
+- [ ] Timeout on all executions (configurable, max 5 minutes)
+- [ ] Output size limits (prevent memory exhaustion)
+- [ ] Working directory validation
+- [ ] Environment variable sanitization
+
+**MCP Protocol:**
+
+- [ ] Server binds to localhost only (127.0.0.1)
+- [ ] No external network exposure
+- [ ] Input validation on all JSON-RPC messages
+- [ ] Rate limiting on tool calls (prevent abuse)
+- [ ] Execution logging for audit trail
+
+**Input Validation:**
+
+- [ ] Command names: alphanumeric, dashes, underscores only
+- [ ] Argument names: same restrictions
+- [ ] Script length limit (10,000 chars)
+- [ ] Argument count limit (20 per command)
+- [ ] Description length limit (500 chars)
 
 ---
 
-## 6. Implementation Order & Dependencies
+## 5. Implementation Order & Dependencies
 
 ```
-Issue #1 (Project Setup)
+Phase 2.0: Project Setup
+    â”‚
+    â–¼
+Phase 2.1: File-First Storage (#14)
     â”‚
-    â”œâ”€â”€â–º Issue #2 (Data Storage) â”€â”€â–º Issue #3 (GUI) â”€â”€â–º Issue #4 (Sync Engine)
-    â”‚                                      â”‚                    â”‚
-    â”‚                                      â””â”€â”€ Uses IPC â”€â”€â”€â”€â”€â”€â”€â”€â”˜
-    â”‚                                            â”‚
-    â””â”€â”€ All issues depend on base project setup â”€â”€â”˜
+    â”œâ”€â”€â–º Phase 2.2: MCP Server (#5) â”€â”€â”
+    â”‚                                  â”‚
+    â””â”€â”€â–º Phase 2.3: Commands (#6) â”€â”€â”€â”€â”€â”¤
+                                       â”‚
+                                       â–¼
+                            Phase 2.4: MCP Execution (#7)
+                                       â”‚
+                                       â–¼
+                            Phase 2.5: Polish & Verification
 ```
 
-### Recommended Build Sequence
+### Dependency Notes
 
-1. **Day 1-2:** Issue #1 - Full project setup including all tooling
-2. **Day 3-5:** Issue #2 - Data layer complete with all tests passing
-3. **Day 6-10:** Issue #3 - GUI with basic read/write to database
-4. **Day 11-14:** Issue #4 - Sync engine integration with GUI
-5. **Day 15:** Polish, final testing, documentation
+- **#14 must complete before #6** - Commands use same file storage pattern
+- **#5 and #6 can run in parallel** after #14
+- **#7 requires both #5 and #6** - Connects commands to MCP server
+- **#5 can start research early** - SDK selection doesn't depend on #14
 
-### Issue Dependencies
+### Timeline Estimate
 
-- **Issue #2 requires:** Issue #1 (project structure, Rust setup)
-- **Issue #3 requires:** Issue #2 (IPC commands to fetch/save rules)
-- **Issue #4 requires:** Issue #2 (rules from database), Issue #3 (sync button UI)
+| Phase | Issue  | Priority | Duration | Dependencies  |
+| ----- | ------ | -------- | -------- | ------------- |
+| 2.0   | Setup  | HIGH     | 0.5 day  | None          |
+| 2.1   | #14    | HIGH     | 4-5 days | 2.0           |
+| 2.2   | #5     | MEDIUM   | 3-4 days | 2.1 (partial) |
+| 2.3   | #6     | MEDIUM   | 4-5 days | 2.1           |
+| 2.4   | #7     | MEDIUM   | 3-4 days | 2.2, 2.3      |
+| 2.5   | Polish | HIGH     | 2-3 days | 2.4           |
+
+**Total: ~17-22 days** with parallelization on #5 and #6.
 
 ---
 
-## 7. CI/CD Setup
+## 6. Risk Assessment & Mitigation
 
-### GitHub Actions Workflow
+| Risk                             | Likelihood | Impact   | Mitigation                                            |
+| -------------------------------- | ---------- | -------- | ----------------------------------------------------- |
+| MCP SDK not mature               | Medium     | High     | Build custom JSON-RPC implementation as fallback      |
+| File watcher performance         | Low        | Medium   | Use debouncing, test with large directories           |
+| Migration data loss              | Low        | Critical | Backup SQLite before migration, implement rollback    |
+| Script injection vulnerability   | Low        | Critical | Thorough security review, dangerous pattern detection |
+| Cross-platform shell differences | Medium     | Medium   | Test on Windows, macOS, Linux; use appropriate shells |
+| Large output memory issues       | Medium     | Medium   | Implement output size limits and streaming            |
+| Concurrent edit conflicts        | Medium     | Low      | Clear UI warnings, conflict resolution options        |
 
-```yaml
-# .github/workflows/ci.yml
-name: CI
-
-on: [push, pull_request]
-
-jobs:
-  frontend:
-    runs-on: ubuntu-latest
-    steps:
-      - uses: actions/checkout@v4
-      - uses: actions/setup-node@v4
-        with: { node-version: "20" }
-      - run: npm ci
-      - run: npm run lint
-      - run: npm run typecheck
-      - run: npm run test
-
-  backend:
-    runs-on: ubuntu-latest
-    steps:
-      - uses: actions/checkout@v4
-      - uses: actions-rust-lang/setup-rust-toolchain@v1
-      - run: cargo clippy -- -D warnings
-      - run: cargo test
-
-  build:
-    needs: [frontend, backend]
-    runs-on: windows-latest
-    steps:
-      - uses: actions/checkout@v4
-      - uses: actions/setup-node@v4
-      - run: npm ci
-      - uses: tauri-apps/tauri-action@v0
-```
+---
 
-### Package Scripts
+## 7. Definition of Done
 
-```json
-{
-  "scripts": {
-    "dev": "tauri dev",
-    "build": "tauri build",
-    "lint": "eslint src --ext .ts,.tsx",
-    "lint:fix": "eslint src --ext .ts,.tsx --fix",
-    "typecheck": "tsc --noEmit",
-    "test": "vitest run",
-    "test:watch": "vitest",
-    "test:coverage": "vitest run --coverage"
-  }
-}
-```
+Each issue (#14, #5, #6, #7) is complete when:
+
+### Code Completeness
+
+- [ ] All features implemented per specifications
+- [ ] No TODO, FIXME, or placeholder comments
+- [ ] All error cases handled with user-friendly messages
+- [ ] No unwrap() or expect() in production code (use proper error handling)
+- [ ] All edge cases addressed
+
+### Testing
+
+- [ ] All unit tests passing
+- [ ] All integration tests passing
+- [ ] 80%+ test coverage (high-value tests only)
+- [ ] Happy paths tested
+- [ ] Failure paths tested
+- [ ] Edge cases tested
+- [ ] Security boundaries tested
+
+### Quality
+
+- [ ] Lint and typecheck passing with no warnings
+- [ ] No hardcoded colors (using design tokens)
+- [ ] Responsive design verified
+- [ ] Dark mode support verified
+- [ ] Accessibility audit passed
+- [ ] Keyboard shortcuts working
+- [ ] Performance acceptable (no obvious lag)
+
+### Documentation
+
+- [ ] README updated
+- [ ] Architecture docs updated if changed
+- [ ] User-facing documentation complete
+- [ ] Code comments for complex logic
+- [ ] API documentation (IPC commands)
+
+### Manual Verification
+
+- [ ] Manual testing completed on Windows
+- [ ] All features work end-to-end
+- [ ] Error scenarios tested manually
+- [ ] UI polish verified
+- [ ] No console errors
 
 ---
 
-## 8. Edge Cases & Error Scenarios
+## 8. Future Work (Phase 3+ Acknowledgment)
+
+Per `architecture.md` and `roadmap.md`, the following are **acknowledged but NOT in this plan**:
+
+### Phase 3: Skills MVP (Roadmap)
 
-### File System Edge Cases
+- Support for complex, multi-file execution environments
+- "Skills Manager" UI for bundled workflows
+- Skills as directories with SKILL.md and auxiliary scripts
+- Multi-stage python/bash script execution
+- Templates for common skills
 
-| Scenario                       | Handling                                     |
-| ------------------------------ | -------------------------------------------- |
-| Target directory doesn't exist | Create recursively with `fs::create_dir_all` |
-| Permission denied              | Return error, show toast with path info      |
-| File locked by another process | Retry with backoff, then fail with message   |
-| Disk full                      | Return IO error, show user-friendly message  |
-| Path too long (Windows)        | Validate paths before sync, show warning     |
+### Phase 4: Polish & Extensibility (Roadmap)
 
-### Data Edge Cases
+- System tray icon for background operation
+- Enhanced conflict resolution
+- Import/export configurations
 
-| Scenario                        | Handling                                      |
-| ------------------------------- | --------------------------------------------- |
-| Rule with empty content         | Allow but warn in UI                          |
-| Rule with no adapters selected  | Block save, show validation error             |
-| Local rule with no target paths | Block save, require at least one path         |
-| Duplicate rule name             | Allow (names not unique), use ID for identity |
-| Very large rule content (>1MB)  | Warn user, suggest splitting                  |
+### Phase 5: Advanced Ecosystem (Roadmap)
 
-### Sync Edge Cases
+- **Secrets & Vault Management** - NIST SP 800-63B password security compliance
+- Live execution logging dashboard
+- Community Hub / Registry for sharing rules
 
-| Scenario                               | Handling                                        |
-| -------------------------------------- | ----------------------------------------------- |
-| External file modified since last sync | Detect via hash, prompt for conflict resolution |
-| Multiple rules targeting same file     | Concatenate in defined order                    |
-| Adapter format changes needed          | Track version, re-format on next sync           |
-| Sync interrupted mid-way               | Each file is atomic, resume on next sync        |
+These are explicitly out of scope for Milestone #2 but acknowledged in the architecture.
 
 ---
 
-## 9. Security Considerations
+## 9. Notes
 
-### File System Access
+### Why File-First Storage is Critical
 
-- Use Tauri's allowlist to restrict filesystem access
-- Only allow writes to designated paths (user-selected, AppData, home)
-- Never execute files from user-provided paths (Phase 1 - no command execution)
+Issue #14 is marked HIGH PRIORITY because:
 
-### Input Validation
+1. Git-native version control for rules
+2. Transparency - users can edit files directly
+3. Portability - no database export needed
+4. Emergency access - rules remain readable even if app breaks
+5. Developer-friendly - review rule changes in PRs
+6. Aligns with architecture flexibility (SQLite OR file storage)
 
-- Sanitize rule names (no path traversal characters)
-- Validate target paths are within allowed scopes
-- Limit content size to prevent memory issues
+### MCP Transport Decision
 
-### Database
+Start with **stdio transport** (simpler, no port conflicts):
 
-- Store in user's AppData (OS-appropriate location)
-- No sensitive data in Phase 1 (secrets come in Phase 5)
+- Claude Code and OpenCode support stdio MCP servers
+- HTTP can be added later as enhancement
+- stdio is more secure (no network exposure)
+
+### Security First
+
+Command execution is the highest security risk:
+
+- All user input must be escaped
+- Dangerous patterns must be blocked
+- Timeouts prevent runaway processes
+- Audit logging for accountability
+- Principle of least privilege (minimal permissions)
+
+### Testing Philosophy
+
+Per our rules:
+
+- High-value tests > coverage metrics
+- No low-value tests (getters/setters, trivial functions)
+- Both happy and failure paths
+- If 80% coverage requires low-value tests, stop at lower percentage
+
+### Documentation Standards
+
+- Update README.md for user-facing changes
+- Document architecture decisions in comments
+- Keep AGENTS.md updated (if exists)
+- Screenshots/GIFs for major UI changes
 
 ---
 
-## 10. Definition of Done
+## 10. Robust MCP Mode Addendum
 
-Each issue is complete when:
+To make MCP reliable for daily workflows and tool reconnects, we add a dual-mode runtime:
 
-- [ ] All code implemented per specifications
-- [ ] All unit tests passing (80%+ coverage, high-value only)
-- [ ] Integration tests passing
-- [ ] Lint and typecheck passing with no warnings
-- [ ] Manual testing completed on Windows
-- [ ] Code reviewed
-- [ ] No TODOs or placeholders in code
-- [ ] Error handling comprehensive
-- [ ] Loading states and error messages in UI
-- [ ] Accessibility verified (keyboard navigation works)
+### A. Embedded MCP (Desktop App Runtime)
+
+- Keep MCP server embedded in Tauri for integrated UX and settings controls.
+- Add `mcp_auto_start` setting so MCP can start automatically when app launches.
+- Expose status/start/stop/restart and connection instructions in Settings.
+
+### B. Standalone MCP Binary (`ruleweaver-mcp`)
+
+- Ship a separate CLI/EXE entrypoint that starts MCP without opening the desktop UI.
+- Command shape: `ruleweaver-mcp --port <PORT>`.
+- Reuse the same database and command registry as the desktop app.
+- Include standalone launch snippet in MCP connection instructions so AI tools can call it directly.
+
+### C. Process & Background Expectations
+
+- Embedded mode requires RuleWeaver app process alive.
+- Standalone mode requires `ruleweaver-mcp` process alive.
+- No Docker container is required.
+
+### D. Remaining hardening after implementation
+
+- Add system tray/background mode to keep embedded MCP alive when window closes.
+- Add startup conflict handling between embedded MCP and standalone MCP on same port.
+- Add reconnect-resilience tests for long-lived MCP clients.
+
+### E. Implementation status in current branch
+
+- Tray/background mode implemented (`minimize_to_tray` + tray menu controls).
+- Standalone MCP binary implemented (`ruleweaver-mcp`).
+- Command stub sync implemented (`sync_commands` for Gemini/OpenCode/Claude Code files).
+- Phase 3 foundation started: Skills CRUD backend + initial Skills page/navigation.
diff --git a/README.md b/README.md
index bd69f96..0901f84 100644
--- a/README.md
+++ b/README.md
@@ -9,12 +9,21 @@ Managing different file formats and local/global settings across 6+ AI tools is
 Different types of AI configurations require different management strategies:
 
 1. **Rules (Static Context):** Managed via **File Sync**. You write your global or repo-specific rules in the RuleWeaver UI. The app then uses **Tool-Specific Adapters (Post-Processors)** to automatically translate and copy these rules into the specific proprietary formats and directories required by each target tool (e.g., configuring TOML for Gemini CLI, `.clinerules` for Cline, or `AGENTS.md` for OpenCode).
-2. **Commands & Skills (Executable Actions):** Managed via an **Internal MCP Server** combined with **UI Stub Syncing**. Because users love the autocomplete dropdowns in tools like Claude Code (e.g., typing `/`), RuleWeaver will automatically generate the required `.md` or `.toml` command definitions (the "Stubs") and sync them to your local folders. However, the heavy lifting and execution of those commands are securely handled by the lightweight, local Model Context Protocol (MCP) server running in the background. You configure your AI tools to connect to this server, granting them unified access while still getting the beautiful UI integration.
+2. **Commands & Skills (Executable Actions):** Managed via a **Local MCP Server** combined with **UI Stub Syncing**. RuleWeaver supports two MCP runtime modes:
+   - **Embedded mode:** MCP runs inside the desktop app process.
+   - **Standalone mode:** MCP runs as a separate binary (`ruleweaver-mcp --port 8080`).
+
+   RuleWeaver generates the `.md`/`.toml` command stubs for tool UX, while command execution happens through MCP.
 
 ## Features
 
 - **Standalone GUI:** A fast, native desktop application (built with Tauri).
 - **Scope Management:** Clearly define if a Configuration is "Global" (applied everywhere) or "Local" (applied only when the AI is operating within specific defined repository paths).
+- **Dual MCP Runtime:** Embedded MCP in app process or standalone `ruleweaver-mcp` process.
+- **Command Manager:** CRUD commands, test runs, MCP exposure toggles, and execution history.
+- **Command Stub Sync:** Generates command files for supported tools (`COMMANDS.toml` / `COMMANDS.md`).
+- **Background Keep-Alive:** Optional close-to-tray behavior keeps MCP available.
+- **Skills Foundation:** Initial Skills CRUD and UI scaffolding is available.
 - **Priority Tiering:**
   1. Rules First (System Prompts, Code Standards)
   2. Custom Commands Second (Single scripts, quick actions)
@@ -26,6 +35,13 @@ _(Installation instructions will be added as the MVP is developed)_
 
 ## Development
 
+## User Documentation
+
+- See `USER_GUIDE.md` for:
+  - rules and skills management
+  - MCP setup and runtime modes
+  - agent connection guidance
+
 ### Prerequisites
 
 - [Node.js](https://nodejs.org/) (v20+)
@@ -39,6 +55,19 @@ npm install
 npm run tauri:dev
 ```
 
+### MCP Runtime Modes
+
+- **Embedded MCP:** Start RuleWeaver desktop app and use Settings -> MCP Server controls.
+- **Standalone MCP:** Build and run:
+
+```bash
+cargo run --manifest-path src-tauri/Cargo.toml --bin ruleweaver-mcp -- --port 8080
+```
+
+Use the connection snippets shown in Settings to configure Claude Code/OpenCode.
+
+If **Minimize to tray on close** is enabled (Settings -> MCP Server), closing the window keeps RuleWeaver and embedded MCP running in the background.
+
 ### Build Scripts
 
 | Script                                 | Description                               |
diff --git a/USER_GUIDE.md b/USER_GUIDE.md
new file mode 100644
index 0000000..7b5c893
--- /dev/null
+++ b/USER_GUIDE.md
@@ -0,0 +1,112 @@
+# RuleWeaver User Guide
+
+## 1) Manage Rules
+
+- Open `Rules` in the sidebar.
+- Create or edit a rule with:
+  - name
+  - markdown content
+  - scope (`global` or `local`)
+  - enabled adapters
+- Save changes.
+- Use `Sync` to generate adapter-specific rule files.
+
+Rule storage modes:
+
+- `SQLite` (legacy)
+- `File` (recommended): markdown files with YAML frontmatter under:
+  - global: `~/.ruleweaver/rules/`
+  - local: `{repo}/.ruleweaver/rules/`
+
+You can switch/migrate in `Settings -> Storage`.
+
+## 2) Manage Commands
+
+- Open `Commands` in the sidebar.
+- Create a command with:
+  - name
+  - description
+  - script template (supports placeholders like `{{arg}}`)
+  - argument definitions
+  - `Expose via MCP` toggle
+- Use `Test Run` to execute locally and inspect stdout/stderr.
+- Use `Sync Command Files` to generate command stubs for client UX.
+
+Generated command files:
+
+- `~/.gemini/COMMANDS.toml`
+- `~/.opencode/COMMANDS.md`
+- `~/.claude/COMMANDS.md`
+
+## 3) Manage Skills (Phase 3 Foundation)
+
+- Open `Skills` in the sidebar.
+- Create a skill with:
+  - name
+  - description
+  - instructions
+  - enabled flag
+
+Current status:
+
+- Skills CRUD and UI are available.
+- Advanced MCP skill execution is planned next.
+
+Security note:
+
+- Skills run with your local user permissions.
+- Only enable/import Skills you trust.
+
+## 4) MCP Server Modes
+
+RuleWeaver supports two MCP runtime modes:
+
+1. Embedded MCP (desktop app process)
+2. Standalone MCP binary (`ruleweaver-mcp`)
+
+### Embedded MCP
+
+- Start RuleWeaver desktop app.
+- Go to `Settings -> MCP Server`.
+- Click `Start`.
+- Optional:
+  - enable `Auto-start MCP`
+  - enable `Minimize to tray on close` to keep MCP running in background
+
+### Standalone MCP
+
+Run directly:
+
+```bash
+cargo run --manifest-path src-tauri/Cargo.toml --bin ruleweaver-mcp -- --port 8080
+```
+
+Or use built binary:
+
+```bash
+ruleweaver-mcp --port 8080
+```
+
+## 5) Add MCP to Agent Tools
+
+Use the snippets shown in `Settings -> MCP Server`.
+
+### Claude Code
+
+Use the generated `claude_code_json` snippet from RuleWeaver settings.
+
+### OpenCode
+
+Use the generated `opencode_json` snippet from RuleWeaver settings.
+
+### Gemini, Cline, Codex, Antigravity
+
+- Use synced rule/command files from RuleWeaver.
+- If a specific MCP client integration is available in that tool, configure it to connect to the same localhost MCP endpoint shown in settings.
+
+## 6) Troubleshooting
+
+- Port conflict: change MCP port or stop the conflicting process.
+- No tools listed: confirm commands are `Expose via MCP` and saved.
+- No rules updating: verify adapter toggle in `Settings -> Adapters`, then resync.
+- App closed unexpectedly: enable `Minimize to tray on close` to keep embedded MCP alive.
diff --git a/architecture.md b/architecture.md
index 5ec9fdf..cd2e08c 100644
--- a/architecture.md
+++ b/architecture.md
@@ -3,36 +3,66 @@
 RuleWeaver is designed as a standalone desktop application. It requires deep filesystem access to sync tool configurations globally and locally, as well as network capabilities to host a local server.
 
 ## Tech Stack
-*   **Framework:** [Tauri](https://tauri.app/) (Provides a lightweight, fast, cross-platform standalone executable by combining a native Rust backend with a web frontend).
-*   **Frontend:** React, TypeScript, TailwindCSS (for the GUI).
-*   **Backend:** Rust.
-*   **Database:** SQLite (Embedded via Rust) or `serde_json` file storage to store the master configurations.
+
+- **Framework:** [Tauri](https://tauri.app/) (desktop shell + native Rust backend).
+- **Frontend:** React, TypeScript, TailwindCSS.
+- **Backend:** Rust.
+- **Persistence:** File-first markdown + YAML frontmatter (`~/.ruleweaver/rules/*.md`, `{repo}/.ruleweaver/rules/*.md`) with SQLite as index/cache and settings store.
+- **MCP Runtime:** Embedded MCP manager in app process and standalone MCP binary (`ruleweaver-mcp`).
 
 ## High-Level Architecture
 
 The system is composed of three main layers:
 
 ### 1. The Presentation Layer (Frontend)
+
 The React/TypeScript application running in the Tauri webview.
-*   **State Management:** Holds the UI state for editing Rules, Commands, and Skills.
-*   **Communication:** Communicates with the Rust backend via Tauri IPC (Inter-Process Communication) to save rules, trigger syncs, and start/stop the MCP server.
+
+- **State Management:** Holds the UI state for editing Rules, Commands, and Skills.
+- **Communication:** Communicates with the Rust backend via Tauri IPC (Inter-Process Communication) to save rules, trigger syncs, and start/stop the MCP server.
 
 ### 2. The Core Logic Layer (Rust Backend)
+
 This layer handles all OS-level operations.
-*   **Database Manager:** Reads and writes the master configuration (the definitions of Global/Local rules and their textual content).
-*   **File Sync Engine (The "Adapters"):** 
-    *   Because every AI tool expects a different filename (`GEMINI.md`, `AGENTS.md`, `.clinerules`) or specific frontmatter, the Sync Engine acts as a collection of **Tool-Specific Adapters (Post-Processors)**.
-    *   When a sync is triggered, the engine takes the master Rule and runs it through each active adapter. The adapter handles tool-specific formatting (e.g., prepending XML tags for Claude, or formatting TOML headers) and determines the exact target directory based on the "Scope".
-    *   Writes file outputs directly to the filesystem.
-*   **MCP Server Engine:**
-    *   Runs a local HTTP/Stdio MCP server on a designated port.
-    *   Reads the "Commands" and "Skills" from the database.
-    *   Exposes these as MCP-compliant `tools` to any client that connects.
-    *   Executes the shell commands when an AI agent requests a tool invocation.
+
+- **Database Manager:** Stores indexed metadata, command definitions, execution logs, and settings (including MCP settings and storage mode).
+- **File Storage Engine:** Reads/writes rule markdown files with YAML frontmatter, supports migration/rollback, and handles local+global rule roots.
+- **File Sync Engine (The "Adapters"):**
+  - Because every AI tool expects a different filename (`GEMINI.md`, `AGENTS.md`, `.clinerules`) or specific frontmatter, the Sync Engine acts as a collection of **Tool-Specific Adapters (Post-Processors)**.
+  - When a sync is triggered, the engine takes the master Rule and runs it through each active adapter. The adapter handles tool-specific formatting (e.g., prepending XML tags for Claude, or formatting TOML headers) and determines the exact target directory based on the "Scope".
+  - Writes file outputs directly to the filesystem.
+- **Command Stub Sync Engine:**
+  - Generates tool-facing command definition files (`COMMANDS.toml` / `COMMANDS.md`) for supported adapters.
+  - Keeps command UX in client tools while execution remains centralized in MCP.
+- **MCP Server Engine:**
+  - Runs a local MCP-compatible HTTP JSON-RPC server on localhost.
+  - Reads commands from database and exposes them as `tools/list`.
+  - Handles `tools/call` execution and returns stdout/stderr payloads.
+  - Available in two modes:
+    - **Embedded mode:** runs inside RuleWeaver desktop app.
+    - **Standalone mode:** runs via `ruleweaver-mcp --port <PORT>`.
+- **Skills Engine (Phase 3 Foundation):**
+  - Stores and manages Skills metadata/instructions in database.
+  - Exposes CRUD in UI with MCP execution expansion planned for full Phase 3.
 
 ### 3. The Target Layer (The AI Tools)
-*   **File Watchers:** AI tools (like Cline, OpenCode) naturally watch for changes in their rule files. When the Sync Engine updates a file, the AI tool seamlessly picks it up.
-*   **MCP Clients:** AI tools (like Claude Code, OpenCode) connect to the Rust MCP Server port. When asked to perform an action, they query the MCP server for available Commands/Skills.
+
+- **File Watchers:** AI tools (like Cline, OpenCode) naturally watch for changes in their rule files. When the Sync Engine updates a file, the AI tool seamlessly picks it up.
+- **MCP Clients:** AI tools (Claude Code, OpenCode, etc.) connect to localhost MCP endpoint or launch standalone `ruleweaver-mcp` binary. They use `tools/list` + `tools/call` to invoke commands.
+
+## Runtime Topology
+
+```text
+Option A: Embedded MCP
+AI Tool -> localhost:PORT -> RuleWeaver Desktop App (MCP manager)
+
+Option B: Standalone MCP
+AI Tool -> launches `ruleweaver-mcp` -> localhost:PORT -> MCP manager
+
+Window Lifecycle:
+- With `minimize_to_tray = true`, close requests hide the window and keep the app/MCP process alive.
+- System tray menu controls show/hide and quit behavior.
+```
 
 ## Data Model (Conceptual)
 
@@ -60,6 +90,15 @@ This layer handles all OS-level operations.
       "script": "npm run format",
       "expose_via_mcp": true
     }
+  ],
+  "skills": [
+    {
+      "id": "abc",
+      "name": "Lint and Fix",
+      "description": "Run lint and auto-fix pipeline",
+      "instructions": "Run npm run lint then npm run format",
+      "enabled": true
+    }
   ]
 }
 ```
diff --git a/roadmap.md b/roadmap.md
index 82f024b..0c4416a 100644
--- a/roadmap.md
+++ b/roadmap.md
@@ -3,7 +3,9 @@
 This roadmap defines the path to the Minimum Viable Product (MVP), structured around the requested priority: Rules > Commands > Skills.
 
 ## Phase 1: Foundation & "Rules" MVP (High Priority)
-*Goal: Establish the GUI, database, and the File Sync Engine to manage static context.*
+
+_Goal: Establish the GUI, database, and the File Sync Engine to manage static context._
+
 - [ ] Initialize Tauri (Rust + React/TypeScript) project.
 - [ ] Set up local embedded database (SQLite or JSON store) for configuration state.
 - [ ] **UI:** Build the main dashboard, Scope Selection (Global vs. Local repo paths), and a Markdown editor.
@@ -11,26 +13,39 @@ This roadmap defines the path to the Minimum Viable Product (MVP), structured ar
 - [ ] **Core Engine:** "Sync Engine". Detect changes in the database and run rules through **Tool-Specific Adapters/Post-Processors** to automatically transpile and copy rule files to the correct target directories on the host operating system (e.g., `.clinerules`, `AGENTS.md`, `~/.gemini/GEMINI.md`).
 
 ## Phase 2: "Custom Commands" MVP & MCP Integration (Medium Priority)
-*Goal: Introduce the built-in MCP server to serve simple executable commands.*
-- [ ] **Core Engine:** Integrate a lightweight MCP Server running in the Rust backend of the Tauri app.
-- [ ] **UI:** Build the "Commands Manager". Interface to define shell commands, scripts, and their required arguments.
-- [ ] **Feature:** Map defined Custom Commands to dynamically generated MCP `tools`.
-- [ ] Document instructions on how to connect the target AI tools (Claude Code, OpenCode, etc.) to the local RuleWeaver MCP port.
+
+_Goal: Introduce the built-in MCP server to serve simple executable commands._
+
+- [x] **Core Engine:** Integrate a lightweight MCP Server running in the Rust backend of the Tauri app.
+- [x] **UI:** Build the "Commands Manager". Interface to define shell commands, scripts, and their required arguments.
+- [x] **Feature:** Map defined Custom Commands to dynamically generated MCP `tools`.
+- [x] Document instructions on how to connect the target AI tools (Claude Code, OpenCode, etc.) to the local RuleWeaver MCP port.
+- [x] Add standalone MCP binary mode (`ruleweaver-mcp`) for tool-managed process startup.
+- [x] Add MCP auto-start setting in desktop app.
+- [x] Add command stub sync output generation (`COMMANDS.toml`/`COMMANDS.md`) for supported tools.
+- [x] Add in-app command execution history view.
 
 ## Phase 3: "Skills" MVP (Lower Priority)
-*Goal: Support complex, multi-file execution environments (Agent Skills).*
+
+_Goal: Support complex, multi-file execution environments (Agent Skills)._
+
 - [ ] **UI:** Build the "Skills Manager". UI to manage bundled workflows (directories with a `SKILL.md` and auxiliary scripts).
 - [ ] **Feature:** Expand the MCP Server to expose complex "Skills" as tools that return structured output or execute multi-stage python/bash scripts securely.
 - [ ] Provide templates for common skills (e.g., "Run Linter and auto-fix", "Fetch Jira Ticket").
+- [x] **Backend Foundation:** Add Skills data model + CRUD persistence scaffolding.
 
 ## Phase 4: Polish & Extensibility
-*Goal: Harden the application for daily use.*
-- [ ] Add systemic tray icon to run in background.
+
+_Goal: Harden the application for daily use._
+
+- [x] Add system tray icon to keep embedded MCP running in background.
 - [ ] Conflict resolution (if a tool overwrites a synced file manually).
 - [ ] Support for importing/exporting configurations to share with teams.
 
 ## Phase 5: Advanced Ecosystem (Post-MVP)
-*Goal: Make the central repository a true power-user control center.*
+
+_Goal: Make the central repository a true power-user control center._
+
 - [ ] **Secrets & Vault Management:** Integrating a secure key-store so "Skills" (like creating a GitHub issue or fetching a Jira ticket) can access API tokens securely without hardcoding them in the sync rules.
-- [ ] **Live Execution Logging:** A "Logs" dashboard in the GUI that tracks every single connection to the MCP Server. You can audit exactly *which* AI agent ran *what* command and when, and read the `stdout` they were provided.
+- [ ] **Live Execution Logging:** A "Logs" dashboard in the GUI that tracks every single connection to the MCP Server. You can audit exactly _which_ AI agent ran _what_ command and when, and read the `stdout` they were provided.
 - [ ] **Community Hub / Registry:** Support for pasting a GitHub URL to instantly import community-created rule sets (e.g., "Google Chrome Official Extension Developer Pattern") or advanced Skills directly into your database.
diff --git a/src-tauri/Cargo.toml b/src-tauri/Cargo.toml
index d81fd4f..f37fda2 100644
--- a/src-tauri/Cargo.toml
+++ b/src-tauri/Cargo.toml
@@ -5,6 +5,14 @@ description = "A unified desktop app for managing AI coding assistant rules and
 authors = ["ChrisUFO"]
 edition = "2021"
 
+[[bin]]
+name = "ruleweaver"
+path = "src/main.rs"
+
+[[bin]]
+name = "ruleweaver-mcp"
+path = "src/bin/mcp-server.rs"
+
 [lib]
 name = "ruleweaver_lib"
 crate-type = ["staticlib", "cdylib", "rlib"]
@@ -13,7 +21,7 @@ crate-type = ["staticlib", "cdylib", "rlib"]
 tauri-build = { version = "2", features = [] }
 
 [dependencies]
-tauri = { version = "2", features = [] }
+tauri = { version = "2", features = ["tray-icon"] }
 tauri-plugin-opener = "2"
 serde = { version = "1", features = ["derive"] }
 serde_json = "1"
@@ -23,3 +31,14 @@ uuid = { version = "1", features = ["v4", "serde"] }
 sha2 = "0.10"
 chrono = { version = "0.4", features = ["serde"] }
 dirs = "6"
+serde_yaml = "0.9"
+notify = "6"
+glob = "0.3"
+walkdir = "2"
+tokio = { version = "1", features = ["full"] }
+regex = "1"
+log = "0.4"
+env_logger = "0.11"
+clap = { version = "4", features = ["derive"] }
+axum = "0.7"
+tower-http = { version = "0.5", features = ["cors"] }
diff --git a/src-tauri/src/bin/mcp-server.rs b/src-tauri/src/bin/mcp-server.rs
new file mode 100644
index 0000000..484eb68
--- /dev/null
+++ b/src-tauri/src/bin/mcp-server.rs
@@ -0,0 +1,24 @@
+use clap::Parser;
+
+#[derive(Parser, Debug)]
+#[command(author, version, about, long_about = None)]
+struct Args {
+    /// Port to listen on
+    #[arg(short, long, default_value_t = 8080)]
+    port: u16,
+}
+
+fn main() {
+    env_logger::init();
+    log::info!("MCP Server starting up");
+
+    let args = Args::parse();
+    let port = args.port;
+
+    log::info!("Starting MCP server on port {}", port);
+    if let Err(e) = ruleweaver_lib::run_mcp_cli(port) {
+        log::error!("MCP server error: {}", e);
+        eprintln!("ruleweaver-mcp error: {}", e);
+        std::process::exit(1);
+    }
+}
diff --git a/src-tauri/src/commands/mod.rs b/src-tauri/src/commands/mod.rs
index 383ff04..48d9187 100644
--- a/src-tauri/src/commands/mod.rs
+++ b/src-tauri/src/commands/mod.rs
@@ -1,10 +1,22 @@
-use crate::database::{get_app_data_path, Database};
+use crate::database::{get_app_data_path, Database, ExecutionLogInput};
 use crate::error::{AppError, Result};
-use crate::models::{CreateRuleInput, Rule, SyncHistoryEntry, SyncResult, UpdateRuleInput};
+use crate::execution::{
+    argument_env_var_name, execute_shell_with_timeout_env, replace_template_with_env_ref,
+    sanitize_argument_value, slugify,
+};
+use crate::file_storage;
+use crate::mcp::{McpConnectionInstructions, McpManager, McpStatus};
+use crate::models::{
+    Command, CreateCommandInput, CreateRuleInput, CreateSkillInput, ExecutionLog, Rule, Skill,
+    SyncError, SyncHistoryEntry, SyncResult, TestCommandResult, UpdateCommandInput,
+    UpdateRuleInput, UpdateSkillInput,
+};
 use crate::sync::SyncEngine;
 use std::collections::HashMap;
 use std::fs;
 use std::path::PathBuf;
+use std::sync::Arc;
+use std::time::Duration;
 use tauri::State;
 
 fn validate_path(path: &str) -> Result<PathBuf> {
@@ -27,6 +39,10 @@ fn validate_path(path: &str) -> Result<PathBuf> {
 
 const MAX_RULE_NAME_LENGTH: usize = 200;
 const MAX_RULE_CONTENT_LENGTH: usize = 1_000_000;
+const MAX_COMMAND_NAME_LENGTH: usize = 120;
+const MAX_COMMAND_SCRIPT_LENGTH: usize = 10_000;
+const MAX_SKILL_NAME_LENGTH: usize = 160;
+const MAX_SKILL_INSTRUCTIONS_LENGTH: usize = 200_000;
 
 fn validate_rule_input(name: &str, content: &str) -> Result<()> {
     let trimmed_name = name.trim();
@@ -54,24 +70,264 @@ fn validate_rule_input(name: &str, content: &str) -> Result<()> {
     Ok(())
 }
 
+fn validate_command_input(name: &str, script: &str) -> Result<()> {
+    let trimmed_name = name.trim();
+    if trimmed_name.is_empty() {
+        return Err(AppError::InvalidInput {
+            message: "Command name cannot be empty".to_string(),
+        });
+    }
+    if trimmed_name.len() > MAX_COMMAND_NAME_LENGTH {
+        return Err(AppError::InvalidInput {
+            message: format!(
+                "Command name too long (max {} characters)",
+                MAX_COMMAND_NAME_LENGTH
+            ),
+        });
+    }
+    if script.trim().is_empty() {
+        return Err(AppError::InvalidInput {
+            message: "Command script cannot be empty".to_string(),
+        });
+    }
+    if script.len() > MAX_COMMAND_SCRIPT_LENGTH {
+        return Err(AppError::InvalidInput {
+            message: format!(
+                "Command script too long (max {} characters)",
+                MAX_COMMAND_SCRIPT_LENGTH
+            ),
+        });
+    }
+    Ok(())
+}
+
+fn validate_skill_input(name: &str, instructions: &str) -> Result<()> {
+    let trimmed_name = name.trim();
+    if trimmed_name.is_empty() {
+        return Err(AppError::InvalidInput {
+            message: "Skill name cannot be empty".to_string(),
+        });
+    }
+    if trimmed_name.len() > MAX_SKILL_NAME_LENGTH {
+        return Err(AppError::InvalidInput {
+            message: format!(
+                "Skill name too long (max {} characters)",
+                MAX_SKILL_NAME_LENGTH
+            ),
+        });
+    }
+    if instructions.trim().is_empty() {
+        return Err(AppError::InvalidInput {
+            message: "Skill instructions cannot be empty".to_string(),
+        });
+    }
+    if instructions.len() > MAX_SKILL_INSTRUCTIONS_LENGTH {
+        return Err(AppError::InvalidInput {
+            message: format!(
+                "Skill instructions too large (max {} characters)",
+                MAX_SKILL_INSTRUCTIONS_LENGTH
+            ),
+        });
+    }
+    Ok(())
+}
+
+fn markdown_escape_inline(input: &str) -> String {
+    input.replace('`', "\\`")
+}
+
+fn command_file_targets() -> Result<Vec<(String, String)>> {
+    let home = dirs::home_dir()
+        .ok_or_else(|| AppError::Path("Could not determine home directory".to_string()))?;
+    Ok(vec![
+        (
+            home.join(".gemini")
+                .join("COMMANDS.toml")
+                .to_string_lossy()
+                .to_string(),
+            "gemini".to_string(),
+        ),
+        (
+            home.join(".opencode")
+                .join("COMMANDS.md")
+                .to_string_lossy()
+                .to_string(),
+            "opencode".to_string(),
+        ),
+        (
+            home.join(".claude")
+                .join("COMMANDS.md")
+                .to_string_lossy()
+                .to_string(),
+            "claude-code".to_string(),
+        ),
+    ])
+}
+
+fn format_commands_toml(commands: &[Command]) -> String {
+    let mut out = String::from("# Generated by RuleWeaver - Do not edit manually\n\n");
+    for cmd in commands.iter().filter(|c| c.expose_via_mcp) {
+        out.push_str("[[command]]\n");
+        out.push_str(&format!("name = \"{}\"\n", slugify(&cmd.name)));
+        out.push_str(&format!(
+            "description = \"{}\"\n",
+            cmd.description.replace('"', "\\\"")
+        ));
+        out.push_str(&format!(
+            "script = \"{}\"\n",
+            cmd.script.replace('"', "\\\"")
+        ));
+        if !cmd.arguments.is_empty() {
+            out.push_str("[command.arguments]\n");
+            for arg in &cmd.arguments {
+                out.push_str(&format!(
+                    "{} = {{ type = \"string\", required = {} }}\n",
+                    arg.name, arg.required
+                ));
+            }
+        }
+        out.push('\n');
+    }
+    out
+}
+
+fn format_commands_markdown(commands: &[Command], title: &str) -> String {
+    let mut out = format!("# {}\n\n", title);
+    out.push_str("<!-- Generated by RuleWeaver - Do not edit manually -->\n\n");
+    for cmd in commands.iter().filter(|c| c.expose_via_mcp) {
+        out.push_str(&format!("## {}\n\n", cmd.name));
+        out.push_str(&format!("{}\n\n", cmd.description));
+        out.push_str(&format!(
+            "**Command:** `{}`\n\n",
+            markdown_escape_inline(&cmd.script)
+        ));
+        if !cmd.arguments.is_empty() {
+            out.push_str("**Arguments:**\n");
+            for arg in &cmd.arguments {
+                out.push_str(&format!(
+                    "- `{}` (string, {}): {}\n",
+                    arg.name,
+                    if arg.required { "required" } else { "optional" },
+                    arg.description
+                ));
+            }
+            out.push('\n');
+        }
+    }
+    out
+}
+
+fn use_file_storage(db: &Database) -> bool {
+    db.get_storage_mode()
+        .map(|mode| mode == "file")
+        .unwrap_or(false)
+}
+
+const LOCAL_RULE_PATHS_KEY: &str = "local_rule_paths";
+
+fn get_local_rule_roots(db: &Database) -> Vec<PathBuf> {
+    db.get_setting(LOCAL_RULE_PATHS_KEY)
+        .ok()
+        .flatten()
+        .and_then(|json| serde_json::from_str::<Vec<String>>(&json).ok())
+        .map(|items| items.into_iter().map(PathBuf::from).collect())
+        .unwrap_or_default()
+}
+
+fn register_local_rule_paths(db: &Database, rule: &Rule) -> Result<()> {
+    if !matches!(rule.scope, crate::models::Scope::Local) {
+        return Ok(());
+    }
+
+    let mut roots = get_local_rule_roots(db)
+        .into_iter()
+        .map(|p| p.to_string_lossy().to_string())
+        .collect::<Vec<_>>();
+
+    if let Some(paths) = &rule.target_paths {
+        for path in paths {
+            if !roots.iter().any(|p| p == path) {
+                roots.push(path.clone());
+            }
+        }
+    }
+
+    let encoded = serde_json::to_string(&roots)?;
+    db.set_setting(LOCAL_RULE_PATHS_KEY, &encoded)
+}
+
+fn storage_location_for_rule(rule: &Rule) -> file_storage::StorageLocation {
+    match rule.scope {
+        crate::models::Scope::Global => file_storage::StorageLocation::Global,
+        crate::models::Scope::Local => {
+            if let Some(paths) = &rule.target_paths {
+                if let Some(first) = paths.first() {
+                    return file_storage::StorageLocation::Local(PathBuf::from(first));
+                }
+            }
+            file_storage::StorageLocation::Global
+        }
+    }
+}
+
 #[tauri::command]
-pub fn get_all_rules(db: State<'_, Database>) -> Result<Vec<Rule>> {
-    db.get_all_rules()
+pub fn get_all_rules(db: State<'_, Arc<Database>>) -> Result<Vec<Rule>> {
+    if use_file_storage(&db) {
+        let local_roots = get_local_rule_roots(&db);
+        let loaded = file_storage::load_rules_from_locations(&local_roots)?;
+        Ok(loaded.rules)
+    } else {
+        db.get_all_rules()
+    }
 }
 
 #[tauri::command]
-pub fn get_rule_by_id(id: String, db: State<'_, Database>) -> Result<Rule> {
-    db.get_rule_by_id(&id)
+pub fn get_rule_by_id(id: String, db: State<'_, Arc<Database>>) -> Result<Rule> {
+    if use_file_storage(&db) {
+        let local_roots = get_local_rule_roots(&db);
+        let loaded = file_storage::load_rules_from_locations(&local_roots)?;
+        loaded
+            .rules
+            .into_iter()
+            .find(|r| r.id == id)
+            .ok_or_else(|| AppError::RuleNotFound { id })
+    } else {
+        db.get_rule_by_id(&id)
+    }
 }
 
 #[tauri::command]
-pub fn create_rule(input: CreateRuleInput, db: State<'_, Database>) -> Result<Rule> {
+pub fn create_rule(input: CreateRuleInput, db: State<'_, Arc<Database>>) -> Result<Rule> {
     validate_rule_input(&input.name, &input.content)?;
-    db.create_rule(input)
+
+    if matches!(input.scope, crate::models::Scope::Local) {
+        if let Some(ref paths) = input.target_paths {
+            if paths.is_empty() {
+                return Err(AppError::InvalidInput {
+                    message: "Local rules must have at least one target path".to_string(),
+                });
+            }
+        } else {
+            return Err(AppError::InvalidInput {
+                message: "Local rules must have target paths specified".to_string(),
+            });
+        }
+    }
+
+    let created = db.create_rule(input)?;
+
+    if use_file_storage(&db) {
+        let location = storage_location_for_rule(&created);
+        file_storage::save_rule_to_disk(&created, &location)?;
+        db.update_rule_file_index(&created.id, &location)?;
+        register_local_rule_paths(&db, &created)?;
+    }
+
+    Ok(created)
 }
 
 #[tauri::command]
-pub fn update_rule(id: String, input: UpdateRuleInput, db: State<'_, Database>) -> Result<Rule> {
+pub fn update_rule(id: String, input: UpdateRuleInput, db: State<'_, Arc<Database>>) -> Result<Rule> {
     if let Some(ref name) = input.name {
         if let Some(ref content) = input.content {
             validate_rule_input(name, content)?;
@@ -83,28 +339,368 @@ pub fn update_rule(id: String, input: UpdateRuleInput, db: State<'_, Database>)
         let existing = db.get_rule_by_id(&id)?;
         validate_rule_input(&existing.name, content)?;
     }
-    db.update_rule(&id, input)
+
+    // Validate scope change or local rule path requirement
+    if let Some(scope) = input.scope {
+        if matches!(scope, crate::models::Scope::Local) {
+            if let Some(ref p) = input.target_paths {
+                if p.is_empty() {
+                    return Err(AppError::InvalidInput {
+                        message: "Local rules must have at least one target path".to_string(),
+                    });
+                }
+            } else {
+                // If we're changing scope to Local, we MUST provide target_paths
+                let existing = db.get_rule_by_id(&id)?;
+                if existing.target_paths.as_ref().map(|p| p.is_empty()).unwrap_or(true) {
+                    return Err(AppError::InvalidInput {
+                        message: "Local rules must have at least one target path".to_string(),
+                    });
+                }
+            }
+        }
+    } else {
+        // If scope is not changing, but we're updating target_paths for an existing local rule
+        let existing = db.get_rule_by_id(&id)?;
+        if matches!(existing.scope, crate::models::Scope::Local) {
+            if let Some(ref p) = input.target_paths {
+                if p.is_empty() {
+                    return Err(AppError::InvalidInput {
+                        message: "Local rules must have at least one target path".to_string(),
+                    });
+                }
+            }
+        }
+    }
+
+    let updated = db.update_rule(&id, input)?;
+
+    if use_file_storage(&db) {
+        let location = storage_location_for_rule(&updated);
+        file_storage::save_rule_to_disk(&updated, &location)?;
+        db.update_rule_file_index(&updated.id, &location)?;
+        register_local_rule_paths(&db, &updated)?;
+    }
+
+    Ok(updated)
 }
 
 #[tauri::command]
-pub fn delete_rule(id: String, db: State<'_, Database>) -> Result<()> {
+pub fn delete_rule(id: String, db: State<'_, Arc<Database>>) -> Result<()> {
+    if use_file_storage(&db) {
+        if let Ok(existing) = db.get_rule_by_id(&id) {
+            let location = storage_location_for_rule(&existing);
+            file_storage::delete_rule_file(&id, &location)?;
+            db.remove_rule_file_index(&id)?;
+        }
+    }
     db.delete_rule(&id)
 }
 
 #[tauri::command]
-pub fn toggle_rule(id: String, enabled: bool, db: State<'_, Database>) -> Result<Rule> {
-    db.toggle_rule(&id, enabled)
+pub fn toggle_rule(id: String, enabled: bool, db: State<'_, Arc<Database>>) -> Result<Rule> {
+    let toggled = db.toggle_rule(&id, enabled)?;
+
+    if use_file_storage(&db) {
+        let location = storage_location_for_rule(&toggled);
+        file_storage::save_rule_to_disk(&toggled, &location)?;
+        db.update_rule_file_index(&toggled.id, &location)?;
+        register_local_rule_paths(&db, &toggled)?;
+    }
+
+    Ok(toggled)
+}
+
+#[tauri::command]
+pub fn migrate_to_file_storage(db: State<'_, Arc<Database>>) -> Result<file_storage::MigrationResult> {
+    let result = file_storage::migrate_to_file_storage(&db)?;
+    if result.success {
+        db.set_storage_mode("file")?;
+        if let Some(path) = &result.backup_path {
+            db.set_setting("file_storage_backup_path", path)?;
+        }
+    }
+    Ok(result)
+}
+
+#[tauri::command]
+pub fn rollback_file_migration(backup_path: String, db: State<'_, Arc<Database>>) -> Result<()> {
+    file_storage::rollback_migration(&backup_path)?;
+    db.set_storage_mode("sqlite")?;
+    db.set_setting("file_storage_backup_path", "")
+}
+
+#[tauri::command]
+pub fn verify_file_migration(db: State<'_, Arc<Database>>) -> Result<file_storage::VerificationResult> {
+    file_storage::verify_migration(&db)
+}
+
+#[tauri::command]
+pub fn get_file_migration_progress() -> file_storage::MigrationProgress {
+    file_storage::get_migration_progress()
+}
+
+#[tauri::command]
+pub fn get_storage_info() -> Result<HashMap<String, String>> {
+    let info = file_storage::get_storage_info()?;
+    let mut out = HashMap::new();
+    out.insert(
+        "global_dir".to_string(),
+        info.global_dir.to_string_lossy().to_string(),
+    );
+    out.insert("exists".to_string(), info.exists.to_string());
+    out.insert("rule_count".to_string(), info.rule_count.to_string());
+    out.insert(
+        "total_size_bytes".to_string(),
+        info.total_size_bytes.to_string(),
+    );
+    Ok(out)
+}
+
+#[tauri::command]
+pub fn get_storage_mode(db: State<'_, Arc<Database>>) -> Result<String> {
+    db.get_storage_mode()
+}
+
+#[tauri::command]
+pub fn get_all_commands(db: State<'_, Arc<Database>>) -> Result<Vec<Command>> {
+    db.get_all_commands()
+}
+
+#[tauri::command]
+pub fn get_command_by_id(id: String, db: State<'_, Arc<Database>>) -> Result<Command> {
+    db.get_command_by_id(&id)
+}
+
+#[tauri::command]
+pub fn create_command(
+    input: CreateCommandInput,
+    db: State<'_, Arc<Database>>,
+    mcp: State<'_, McpManager>,
+) -> Result<Command> {
+    validate_command_input(&input.name, &input.script)?;
+    let created = db.create_command(input)?;
+    let _ = mcp.refresh_commands(&db);
+    Ok(created)
+}
+
+#[tauri::command]
+pub fn update_command(
+    id: String,
+    input: UpdateCommandInput,
+    db: State<'_, Arc<Database>>,
+    mcp: State<'_, McpManager>,
+) -> Result<Command> {
+    if let Some(name) = &input.name {
+        if let Some(script) = &input.script {
+            validate_command_input(name, script)?;
+        } else {
+            let existing = db.get_command_by_id(&id)?;
+            validate_command_input(name, &existing.script)?;
+        }
+    } else if let Some(script) = &input.script {
+        let existing = db.get_command_by_id(&id)?;
+        validate_command_input(&existing.name, script)?;
+    }
+
+    let updated = db.update_command(&id, input)?;
+    let _ = mcp.refresh_commands(&db);
+    Ok(updated)
+}
+
+#[tauri::command]
+pub fn delete_command(
+    id: String,
+    db: State<'_, Arc<Database>>,
+    mcp: State<'_, McpManager>,
+) -> Result<()> {
+    db.delete_command(&id)?;
+    let _ = mcp.refresh_commands(&db);
+    Ok(())
+}
+
+#[tauri::command]
+pub async fn test_command(
+    id: String,
+    args: HashMap<String, String>,
+    db: State<'_, Arc<Database>>,
+) -> Result<TestCommandResult> {
+    let cmd = db.get_command_by_id(&id)?;
+    let mut script = cmd.script.clone();
+    let mut envs: Vec<(String, String)> = Vec::new();
+
+    for arg in &cmd.arguments {
+        script = replace_template_with_env_ref(&script, &arg.name);
+
+        let raw_value = args
+            .get(&arg.name)
+            .cloned()
+            .or_else(|| arg.default_value.clone())
+            .unwrap_or_default();
+        let safe_value = sanitize_argument_value(&raw_value)?;
+        envs.push((argument_env_var_name(&arg.name), safe_value));
+    }
+
+    let start = std::time::Instant::now();
+    let (exit_code, stdout, stderr) =
+        execute_shell_with_timeout_env(&script, Duration::from_secs(30), &envs).await?;
+    let duration_ms = start.elapsed().as_millis() as u64;
+    let success = exit_code == 0;
+
+    let args_json = serde_json::to_string(&args)?;
+    let _ = db.add_execution_log(&ExecutionLogInput {
+        command_id: &cmd.id,
+        command_name: &cmd.name,
+        arguments_json: &args_json,
+        stdout: &stdout,
+        stderr: &stderr,
+        exit_code,
+        duration_ms,
+        triggered_by: "test",
+    });
+
+    Ok(TestCommandResult {
+        success,
+        stdout,
+        stderr,
+        exit_code,
+        duration_ms,
+    })
+}
+
+#[tauri::command]
+pub fn sync_commands(db: State<'_, Arc<Database>>) -> Result<SyncResult> {
+    let commands = db.get_all_commands()?;
+    let mut files_written = Vec::new();
+    let mut errors = Vec::new();
+
+    for (path_str, adapter_name) in command_file_targets()? {
+        let path = PathBuf::from(&path_str);
+        if let Some(parent) = path.parent() {
+            if let Err(e) = fs::create_dir_all(parent) {
+                errors.push(SyncError {
+                    file_path: path_str.clone(),
+                    adapter_name: adapter_name.clone(),
+                    message: e.to_string(),
+                });
+                continue;
+            }
+        }
+
+        let content = if adapter_name == "gemini" {
+            format_commands_toml(&commands)
+        } else if adapter_name == "opencode" {
+            format_commands_markdown(&commands, "RuleWeaver Commands")
+        } else {
+            format_commands_markdown(&commands, "RuleWeaver Commands (Claude Code)")
+        };
+
+        match fs::write(&path, content) {
+            Ok(()) => files_written.push(path_str),
+            Err(e) => errors.push(SyncError {
+                file_path: path.to_string_lossy().to_string(),
+                adapter_name,
+                message: e.to_string(),
+            }),
+        }
+    }
+
+    Ok(SyncResult {
+        success: errors.is_empty(),
+        files_written,
+        errors,
+        conflicts: Vec::new(),
+    })
+}
+
+#[tauri::command]
+pub fn get_all_skills(db: State<'_, Arc<Database>>) -> Result<Vec<Skill>> {
+    db.get_all_skills()
+}
+
+#[tauri::command]
+pub fn get_skill_by_id(id: String, db: State<'_, Arc<Database>>) -> Result<Skill> {
+    db.get_skill_by_id(&id)
+}
+
+#[tauri::command]
+pub fn create_skill(input: CreateSkillInput, db: State<'_, Arc<Database>>) -> Result<Skill> {
+    validate_skill_input(&input.name, &input.instructions)?;
+    db.create_skill(input)
+}
+
+#[tauri::command]
+pub fn update_skill(id: String, input: UpdateSkillInput, db: State<'_, Arc<Database>>) -> Result<Skill> {
+    if let Some(ref name) = input.name {
+        if let Some(ref instructions) = input.instructions {
+            validate_skill_input(name, instructions)?;
+        } else {
+            let existing = db.get_skill_by_id(&id)?;
+            validate_skill_input(name, &existing.instructions)?;
+        }
+    } else if let Some(ref instructions) = input.instructions {
+        let existing = db.get_skill_by_id(&id)?;
+        validate_skill_input(&existing.name, instructions)?;
+    }
+
+    db.update_skill(&id, input)
+}
+
+#[tauri::command]
+pub fn delete_skill(id: String, db: State<'_, Arc<Database>>) -> Result<()> {
+    db.delete_skill(&id)
+}
+
+#[tauri::command]
+pub fn get_mcp_status(mcp: State<'_, McpManager>) -> Result<McpStatus> {
+    mcp.status()
+}
+
+#[tauri::command]
+pub fn start_mcp_server(db: State<'_, Arc<Database>>, mcp: State<'_, McpManager>) -> Result<()> {
+    mcp.start(&db)
+}
+
+#[tauri::command]
+pub fn stop_mcp_server(mcp: State<'_, McpManager>) -> Result<()> {
+    mcp.stop()
+}
+
+#[tauri::command]
+pub fn restart_mcp_server(db: State<'_, Arc<Database>>, mcp: State<'_, McpManager>) -> Result<()> {
+    mcp.stop()?;
+    mcp.start(&db)
+}
+
+#[tauri::command]
+pub fn get_mcp_connection_instructions(
+    mcp: State<'_, McpManager>,
+) -> Result<McpConnectionInstructions> {
+    mcp.instructions()
+}
+
+#[tauri::command]
+pub fn get_mcp_logs(limit: Option<u32>, mcp: State<'_, McpManager>) -> Result<Vec<String>> {
+    mcp.logs(limit.unwrap_or(50) as usize)
+}
+
+#[tauri::command]
+pub fn get_execution_history(
+    limit: Option<u32>,
+    db: State<'_, Arc<Database>>,
+) -> Result<Vec<ExecutionLog>> {
+    db.get_execution_history(limit.unwrap_or(100))
 }
 
 #[tauri::command]
-pub fn sync_rules(db: State<'_, Database>) -> Result<SyncResult> {
+pub fn sync_rules(db: State<'_, Arc<Database>>) -> Result<SyncResult> {
     let rules = db.get_all_rules()?;
     let engine = SyncEngine::new(&db);
     Ok(engine.sync_all(rules))
 }
 
 #[tauri::command]
-pub fn preview_sync(db: State<'_, Database>) -> Result<SyncResult> {
+pub fn preview_sync(db: State<'_, Arc<Database>>) -> Result<SyncResult> {
     let rules = db.get_all_rules()?;
     let engine = SyncEngine::new(&db);
     Ok(engine.preview(rules))
@@ -113,7 +709,7 @@ pub fn preview_sync(db: State<'_, Database>) -> Result<SyncResult> {
 #[tauri::command]
 pub fn get_sync_history(
     limit: Option<u32>,
-    db: State<'_, Database>,
+    db: State<'_, Arc<Database>>,
 ) -> Result<Vec<SyncHistoryEntry>> {
     db.get_sync_history(limit.unwrap_or(50))
 }
@@ -129,7 +725,7 @@ pub fn read_file_content(path: String) -> Result<String> {
 pub fn resolve_conflict(
     file_path: String,
     resolution: String,
-    db: State<'_, Database>,
+    db: State<'_, Arc<Database>>,
 ) -> Result<()> {
     match resolution.as_str() {
         "overwrite" => {
@@ -158,17 +754,17 @@ pub fn get_app_version() -> String {
 }
 
 #[tauri::command]
-pub fn get_setting(key: String, db: State<'_, Database>) -> Result<Option<String>> {
+pub fn get_setting(key: String, db: State<'_, Arc<Database>>) -> Result<Option<String>> {
     db.get_setting(&key)
 }
 
 #[tauri::command]
-pub fn set_setting(key: String, value: String, db: State<'_, Database>) -> Result<()> {
+pub fn set_setting(key: String, value: String, db: State<'_, Arc<Database>>) -> Result<()> {
     db.set_setting(&key, &value)
 }
 
 #[tauri::command]
-pub fn get_all_settings(db: State<'_, Database>) -> Result<HashMap<String, String>> {
+pub fn get_all_settings(db: State<'_, Arc<Database>>) -> Result<HashMap<String, String>> {
     db.get_all_settings()
 }
 
diff --git a/src-tauri/src/database/mod.rs b/src-tauri/src/database/mod.rs
index e532d12..2cec687 100644
--- a/src-tauri/src/database/mod.rs
+++ b/src-tauri/src/database/mod.rs
@@ -6,7 +6,12 @@ use rusqlite::{params, Connection, OptionalExtension};
 use tauri::Manager;
 
 use crate::error::{AppError, Result};
-use crate::models::{AdapterType, CreateRuleInput, Rule, Scope, SyncHistoryEntry, UpdateRuleInput};
+use crate::file_storage::StorageLocation;
+use crate::models::{
+    AdapterType, Command, CommandArgument, CreateCommandInput, CreateRuleInput, CreateSkillInput,
+    ExecutionLog, Rule, Scope, Skill, SyncHistoryEntry, UpdateCommandInput, UpdateRuleInput,
+    UpdateSkillInput,
+};
 
 fn parse_timestamp_or_now(timestamp: i64) -> DateTime<Utc> {
     chrono::Utc
@@ -17,21 +22,47 @@ fn parse_timestamp_or_now(timestamp: i64) -> DateTime<Utc> {
 
 pub struct Database(Mutex<Connection>);
 
+impl std::fmt::Debug for Database {
+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
+        f.debug_struct("Database").finish_non_exhaustive()
+    }
+}
+
+pub struct ExecutionLogInput<'a> {
+    pub command_id: &'a str,
+    pub command_name: &'a str,
+    pub arguments_json: &'a str,
+    pub stdout: &'a str,
+    pub stderr: &'a str,
+    pub exit_code: i32,
+    pub duration_ms: u64,
+    pub triggered_by: &'a str,
+}
+
 impl Database {
+    fn new_with_db_path(db_path: PathBuf) -> Result<Self> {
+        if let Some(parent) = db_path.parent() {
+            std::fs::create_dir_all(parent)?;
+        }
+
+        let conn = Connection::open(&db_path)?;
+        run_migrations(&conn)?;
+        Ok(Self(Mutex::new(conn)))
+    }
+
     pub fn new(app_handle: &tauri::AppHandle) -> Result<Self> {
         let app_data_dir = app_handle
             .path()
             .app_data_dir()
             .map_err(|e| AppError::Path(e.to_string()))?;
-
-        std::fs::create_dir_all(&app_data_dir)?;
-
         let db_path = app_data_dir.join("ruleweaver.db");
-        let conn = Connection::open(&db_path)?;
-
-        run_migrations(&conn)?;
+        Self::new_with_db_path(db_path)
+    }
 
-        Ok(Self(Mutex::new(conn)))
+    pub fn new_for_cli() -> Result<Self> {
+        let app_data_dir = default_app_data_dir()?;
+        let db_path = app_data_dir.join("ruleweaver.db");
+        Self::new_with_db_path(db_path)
     }
 
     pub fn get_all_rules(&self) -> Result<Vec<Rule>> {
@@ -216,6 +247,311 @@ impl Database {
         self.get_rule_by_id(id)
     }
 
+    pub fn get_all_commands(&self) -> Result<Vec<Command>> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        let mut stmt = conn.prepare(
+            "SELECT id, name, description, script, arguments, expose_via_mcp, created_at, updated_at
+             FROM commands
+             ORDER BY updated_at DESC",
+        )?;
+
+        let commands = stmt
+            .query_map([], |row| {
+                let id: String = row.get(0)?;
+                let name: String = row.get(1)?;
+                let description: String = row.get(2)?;
+                let script: String = row.get(3)?;
+                let arguments_json: String = row.get(4)?;
+                let expose_via_mcp: bool = row.get(5)?;
+                let created_at: i64 = row.get(6)?;
+                let updated_at: i64 = row.get(7)?;
+
+                let arguments: Vec<CommandArgument> =
+                    serde_json::from_str(&arguments_json).unwrap_or_default();
+
+                Ok(Command {
+                    id,
+                    name,
+                    description,
+                    script,
+                    arguments,
+                    expose_via_mcp,
+                    created_at: parse_timestamp_or_now(created_at),
+                    updated_at: parse_timestamp_or_now(updated_at),
+                })
+            })?
+            .collect::<std::result::Result<Vec<_>, _>>()?;
+
+        Ok(commands)
+    }
+
+    pub fn get_command_by_id(&self, id: &str) -> Result<Command> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        let mut stmt = conn.prepare(
+            "SELECT id, name, description, script, arguments, expose_via_mcp, created_at, updated_at
+             FROM commands
+             WHERE id = ?",
+        )?;
+
+        let command = stmt
+            .query_row(params![id], |row| {
+                let id: String = row.get(0)?;
+                let name: String = row.get(1)?;
+                let description: String = row.get(2)?;
+                let script: String = row.get(3)?;
+                let arguments_json: String = row.get(4)?;
+                let expose_via_mcp: bool = row.get(5)?;
+                let created_at: i64 = row.get(6)?;
+                let updated_at: i64 = row.get(7)?;
+
+                let arguments: Vec<CommandArgument> =
+                    serde_json::from_str(&arguments_json).unwrap_or_default();
+
+                Ok(Command {
+                    id,
+                    name,
+                    description,
+                    script,
+                    arguments,
+                    expose_via_mcp,
+                    created_at: parse_timestamp_or_now(created_at),
+                    updated_at: parse_timestamp_or_now(updated_at),
+                })
+            })
+            .map_err(|e| match e {
+                rusqlite::Error::QueryReturnedNoRows => AppError::CommandNotFound { id: id.to_string() },
+                _ => AppError::Database(e),
+            })?;
+
+        Ok(command)
+    }
+
+    pub fn create_command(&self, input: CreateCommandInput) -> Result<Command> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        let now = chrono::Utc::now().timestamp();
+        let id = uuid::Uuid::new_v4().to_string();
+        let arguments_json = serde_json::to_string(&input.arguments)?;
+
+        conn.execute(
+            "INSERT INTO commands (id, name, description, script, arguments, expose_via_mcp, created_at, updated_at)
+             VALUES (?, ?, ?, ?, ?, ?, ?, ?)",
+            params![
+                id,
+                input.name,
+                input.description,
+                input.script,
+                arguments_json,
+                input.expose_via_mcp,
+                now,
+                now
+            ],
+        )?;
+
+        self.get_command_by_id(&id)
+    }
+
+    pub fn update_command(&self, id: &str, input: UpdateCommandInput) -> Result<Command> {
+        let existing = self.get_command_by_id(id)?;
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+
+        let name = input.name.unwrap_or(existing.name);
+        let description = input.description.unwrap_or(existing.description);
+        let script = input.script.unwrap_or(existing.script);
+        let arguments = input.arguments.unwrap_or(existing.arguments);
+        let expose_via_mcp = input.expose_via_mcp.unwrap_or(existing.expose_via_mcp);
+        let now = chrono::Utc::now().timestamp();
+        let arguments_json = serde_json::to_string(&arguments)?;
+
+        conn.execute(
+            "UPDATE commands SET name = ?, description = ?, script = ?, arguments = ?, expose_via_mcp = ?, updated_at = ?
+             WHERE id = ?",
+            params![
+                name,
+                description,
+                script,
+                arguments_json,
+                expose_via_mcp,
+                now,
+                id
+            ],
+        )?;
+
+        drop(conn);
+        self.get_command_by_id(id)
+    }
+
+    pub fn delete_command(&self, id: &str) -> Result<()> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        conn.execute("DELETE FROM commands WHERE id = ?", params![id])?;
+        Ok(())
+    }
+
+    pub fn get_all_skills(&self) -> Result<Vec<Skill>> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        let mut stmt = conn.prepare(
+            "SELECT id, name, description, instructions, input_schema, enabled, created_at, updated_at
+             FROM skills
+             ORDER BY updated_at DESC",
+        )?;
+
+        let skills = stmt
+            .query_map([], |row| {
+                Ok(Skill {
+                    id: row.get(0)?,
+                    name: row.get(1)?,
+                    description: row.get(2)?,
+                    instructions: row.get(3)?,
+                    input_schema: {
+                        let raw: String = row.get(4)?;
+                        serde_json::from_str(&raw).unwrap_or_default()
+                    },
+                    enabled: row.get(5)?,
+                    created_at: parse_timestamp_or_now(row.get(6)?),
+                    updated_at: parse_timestamp_or_now(row.get(7)?),
+                })
+            })?
+            .collect::<std::result::Result<Vec<_>, _>>()?;
+
+        Ok(skills)
+    }
+
+    pub fn get_skill_by_id(&self, id: &str) -> Result<Skill> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        let mut stmt = conn.prepare(
+            "SELECT id, name, description, instructions, input_schema, enabled, created_at, updated_at
+             FROM skills WHERE id = ?",
+        )?;
+
+        let skill = stmt
+            .query_row(params![id], |row| {
+                Ok(Skill {
+                    id: row.get(0)?,
+                    name: row.get(1)?,
+                    description: row.get(2)?,
+                    instructions: row.get(3)?,
+                    input_schema: {
+                        let raw: String = row.get(4)?;
+                        serde_json::from_str(&raw).unwrap_or_default()
+                    },
+                    enabled: row.get(5)?,
+                    created_at: parse_timestamp_or_now(row.get(6)?),
+                    updated_at: parse_timestamp_or_now(row.get(7)?),
+                })
+            })
+            .map_err(|e| match e {
+                rusqlite::Error::QueryReturnedNoRows => AppError::SkillNotFound { id: id.to_string() },
+                _ => AppError::Database(e),
+            })?;
+
+        Ok(skill)
+    }
+
+    pub fn create_skill(&self, input: CreateSkillInput) -> Result<Skill> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        let now = chrono::Utc::now().timestamp();
+        let id = uuid::Uuid::new_v4().to_string();
+        let input_schema_json = serde_json::to_string(&input.input_schema)?;
+
+        conn.execute(
+            "INSERT INTO skills (id, name, description, instructions, input_schema, enabled, created_at, updated_at)
+             VALUES (?, ?, ?, ?, ?, ?, ?, ?)",
+            params![
+                id,
+                input.name,
+                input.description,
+                input.instructions,
+                input_schema_json,
+                input.enabled,
+                now,
+                now
+            ],
+        )?;
+
+        self.get_skill_by_id(&id)
+    }
+
+    pub fn update_skill(&self, id: &str, input: UpdateSkillInput) -> Result<Skill> {
+        let existing = self.get_skill_by_id(id)?;
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+
+        let name = input.name.unwrap_or(existing.name);
+        let description = input.description.unwrap_or(existing.description);
+        let instructions = input.instructions.unwrap_or(existing.instructions);
+        let input_schema = input.input_schema.unwrap_or(existing.input_schema);
+        let enabled = input.enabled.unwrap_or(existing.enabled);
+        let now = chrono::Utc::now().timestamp();
+        let input_schema_json = serde_json::to_string(&input_schema)?;
+
+        conn.execute(
+            "UPDATE skills SET name = ?, description = ?, instructions = ?, input_schema = ?, enabled = ?, updated_at = ? WHERE id = ?",
+            params![name, description, instructions, input_schema_json, enabled, now, id],
+        )?;
+
+        drop(conn);
+        self.get_skill_by_id(id)
+    }
+
+    pub fn delete_skill(&self, id: &str) -> Result<()> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        conn.execute("DELETE FROM skills WHERE id = ?", params![id])?;
+        Ok(())
+    }
+
+    pub fn add_execution_log(&self, input: &ExecutionLogInput<'_>) -> Result<()> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        let id = uuid::Uuid::new_v4().to_string();
+        let now = chrono::Utc::now().timestamp();
+
+        conn.execute(
+            "INSERT INTO execution_logs (id, command_id, command_name, arguments, stdout, stderr, exit_code, duration_ms, executed_at, triggered_by)
+             VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
+            params![
+                id,
+                input.command_id,
+                input.command_name,
+                input.arguments_json,
+                input.stdout,
+                input.stderr,
+                input.exit_code,
+                input.duration_ms as i64,
+                now,
+                input.triggered_by
+            ],
+        )?;
+
+        Ok(())
+    }
+
+    pub fn get_execution_history(&self, limit: u32) -> Result<Vec<ExecutionLog>> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        let mut stmt = conn.prepare(
+            "SELECT id, command_id, command_name, arguments, stdout, stderr, exit_code, duration_ms, executed_at, triggered_by
+             FROM execution_logs
+             ORDER BY executed_at DESC
+             LIMIT ?",
+        )?;
+
+        let rows = stmt
+            .query_map(params![limit], |row| {
+                let timestamp: i64 = row.get(8)?;
+                Ok(ExecutionLog {
+                    id: row.get(0)?,
+                    command_id: row.get(1)?,
+                    command_name: row.get(2)?,
+                    arguments: row.get(3)?,
+                    stdout: row.get(4)?,
+                    stderr: row.get(5)?,
+                    exit_code: row.get(6)?,
+                    duration_ms: row.get::<_, i64>(7)? as u64,
+                    executed_at: parse_timestamp_or_now(timestamp),
+                    triggered_by: row.get(9)?,
+                })
+            })?
+            .collect::<std::result::Result<Vec<_>, _>>()?;
+
+        Ok(rows)
+    }
+
     pub fn get_file_hash(&self, file_path: &str) -> Result<Option<String>> {
         let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
         let result: Option<String> = conn
@@ -322,6 +658,61 @@ impl Database {
 
         Ok(settings)
     }
+
+    pub fn get_database_path(&self) -> Result<String> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        let path: String = conn.query_row("PRAGMA database_list", [], |row| row.get(2))?;
+        Ok(path)
+    }
+
+    pub fn update_rule_file_index(&self, rule_id: &str, location: &StorageLocation) -> Result<()> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        let file_path = match location {
+            StorageLocation::Global => crate::file_storage::get_global_rules_dir()?
+                .to_string_lossy()
+                .to_string(),
+            StorageLocation::Local(path) => path.to_string_lossy().to_string(),
+        };
+
+        conn.execute(
+            "INSERT OR REPLACE INTO rule_file_index (rule_id, file_path) VALUES (?, ?)",
+            params![rule_id, file_path],
+        )?;
+
+        Ok(())
+    }
+
+    #[allow(dead_code)]
+    pub fn get_rule_file_path(&self, rule_id: &str) -> Result<Option<String>> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        let result: Option<String> = conn
+            .query_row(
+                "SELECT file_path FROM rule_file_index WHERE rule_id = ?",
+                params![rule_id],
+                |row| row.get(0),
+            )
+            .optional()?;
+
+        Ok(result)
+    }
+
+    pub fn remove_rule_file_index(&self, rule_id: &str) -> Result<()> {
+        let conn = self.0.lock().map_err(|_| AppError::DatabasePoisoned)?;
+        conn.execute(
+            "DELETE FROM rule_file_index WHERE rule_id = ?",
+            params![rule_id],
+        )?;
+        Ok(())
+    }
+
+    pub fn get_storage_mode(&self) -> Result<String> {
+        let mode = self.get_setting("storage_mode")?;
+        Ok(mode.unwrap_or_else(|| "sqlite".to_string()))
+    }
+
+    pub fn set_storage_mode(&self, mode: &str) -> Result<()> {
+        self.set_setting("storage_mode", mode)
+    }
 }
 
 fn run_migrations(conn: &Connection) -> Result<()> {
@@ -390,6 +781,107 @@ fn run_migrations(conn: &Connection) -> Result<()> {
         conn.execute("PRAGMA user_version = 2", [])?;
     }
 
+    if current_version < 3 {
+        conn.execute(
+            "CREATE TABLE IF NOT EXISTS rule_file_index (
+                rule_id TEXT PRIMARY KEY NOT NULL,
+                file_path TEXT NOT NULL,
+                content_hash TEXT,
+                last_modified INTEGER
+            )",
+            [],
+        )?;
+
+        conn.execute(
+            "CREATE INDEX IF NOT EXISTS idx_rule_file_index_path ON rule_file_index(file_path)",
+            [],
+        )?;
+
+        conn.execute("PRAGMA user_version = 3", [])?;
+    }
+
+    if current_version < 4 {
+        conn.execute(
+            "CREATE TABLE IF NOT EXISTS commands (
+                id TEXT PRIMARY KEY NOT NULL,
+                name TEXT NOT NULL,
+                description TEXT NOT NULL,
+                script TEXT NOT NULL,
+                arguments TEXT NOT NULL,
+                expose_via_mcp INTEGER NOT NULL DEFAULT 1,
+                created_at INTEGER NOT NULL,
+                updated_at INTEGER NOT NULL
+            )",
+            [],
+        )?;
+
+        conn.execute(
+            "CREATE INDEX IF NOT EXISTS idx_commands_updated_at ON commands(updated_at)",
+            [],
+        )?;
+
+        conn.execute(
+            "CREATE TABLE IF NOT EXISTS execution_logs (
+                id TEXT PRIMARY KEY NOT NULL,
+                command_id TEXT NOT NULL,
+                command_name TEXT NOT NULL,
+                arguments TEXT NOT NULL,
+                stdout TEXT NOT NULL,
+                stderr TEXT NOT NULL,
+                exit_code INTEGER NOT NULL,
+                duration_ms INTEGER NOT NULL,
+                executed_at INTEGER NOT NULL,
+                triggered_by TEXT NOT NULL
+            )",
+            [],
+        )?;
+
+        conn.execute(
+            "CREATE INDEX IF NOT EXISTS idx_execution_logs_executed_at ON execution_logs(executed_at)",
+            [],
+        )?;
+
+        conn.execute("PRAGMA user_version = 4", [])?;
+    }
+
+    if current_version < 5 {
+        conn.execute(
+            "CREATE TABLE IF NOT EXISTS skills (
+                id TEXT PRIMARY KEY NOT NULL,
+                name TEXT NOT NULL,
+                description TEXT NOT NULL,
+                instructions TEXT NOT NULL,
+                enabled INTEGER NOT NULL DEFAULT 1,
+                created_at INTEGER NOT NULL,
+                updated_at INTEGER NOT NULL
+            )",
+            [],
+        )?;
+
+        conn.execute(
+            "CREATE INDEX IF NOT EXISTS idx_skills_updated_at ON skills(updated_at)",
+            [],
+        )?;
+
+        conn.execute("PRAGMA user_version = 5", [])?;
+    }
+
+    if current_version < 6 {
+        let mut stmt = conn.prepare("PRAGMA table_info(skills)")?;
+        let cols: Vec<String> = stmt
+            .query_map([], |row| row.get(1))?
+            .collect::<std::result::Result<Vec<_>, _>>()?;
+
+        if !cols.iter().any(|c| c == "input_schema") {
+            conn.execute(
+                "ALTER TABLE skills ADD COLUMN input_schema TEXT NOT NULL DEFAULT '[]'",
+                [],
+            )?;
+        }
+
+        conn.execute("PRAGMA user_version = 6", [])?;
+    }
+
     Ok(())
 }
 
@@ -399,3 +891,10 @@ pub fn get_app_data_path(app_handle: &tauri::AppHandle) -> Result<PathBuf> {
         .app_data_dir()
         .map_err(|e| AppError::Path(e.to_string()))
 }
+
+pub fn default_app_data_dir() -> Result<PathBuf> {
+    let base = dirs::data_local_dir()
+        .or_else(dirs::data_dir)
+        .ok_or_else(|| AppError::Path("Could not determine data directory".to_string()))?;
+    Ok(base.join("RuleWeaver"))
+}
diff --git a/src-tauri/src/error.rs b/src-tauri/src/error.rs
index 0f438ca..46e05f8 100644
--- a/src-tauri/src/error.rs
+++ b/src-tauri/src/error.rs
@@ -14,6 +14,12 @@ pub enum AppError {
     #[error("Rule not found: {id}")]
     RuleNotFound { id: String },
 
+    #[error("Command not found: {id}")]
+    CommandNotFound { id: String },
+
+    #[error("Skill not found: {id}")]
+    SkillNotFound { id: String },
+
     #[error("Sync conflict detected in: {file_path}")]
     SyncConflict { file_path: String },
 
@@ -28,6 +34,18 @@ pub enum AppError {
 
     #[error("Database lock poisoned")]
     DatabasePoisoned,
+
+    #[error("Lock error")]
+    LockError,
+
+    #[error("YAML parsing error: {0}")]
+    Yaml(String),
+
+    #[error("Migration error: {0}")]
+    Migration(String),
+
+    #[error("File watcher error: {0}")]
+    Watcher(String),
 }
 
 impl<T> From<PoisonError<T>> for AppError {
diff --git a/src-tauri/src/execution.rs b/src-tauri/src/execution.rs
new file mode 100644
index 0000000..42b50f4
--- /dev/null
+++ b/src-tauri/src/execution.rs
@@ -0,0 +1,192 @@
+use std::time::Duration;
+use tokio::process::Command as TokioCommand;
+use tokio::time::timeout;
+
+use crate::error::{AppError, Result};
+
+const MAX_ARG_LENGTH: usize = 2000;
+const MAX_SCRIPT_LENGTH: usize = 20000;
+
+pub fn template_token(arg_name: &str) -> String {
+    format!("{{{{{}}}}}", arg_name)
+}
+
+pub fn argument_env_var_name(arg_name: &str) -> String {
+    let mut slug = slugify(arg_name);
+    if slug.is_empty() {
+        slug = "arg".to_string();
+    }
+    format!("RW_ARG_{}", slug.replace('-', "_").to_uppercase())
+}
+
+pub fn replace_template_with_env_ref(script: &str, arg_name: &str) -> String {
+    let token = template_token(arg_name);
+    let env_name = argument_env_var_name(arg_name);
+
+    #[cfg(target_os = "windows")]
+    let reference = format!("%{}%", env_name);
+
+    #[cfg(not(target_os = "windows"))]
+    let reference = format!("${}", env_name);
+
+    script.replace(&token, &reference)
+}
+
+pub fn slugify(input: &str) -> String {
+    let mut out = String::new();
+    for ch in input.chars() {
+        if ch.is_ascii_alphanumeric() {
+            out.push(ch.to_ascii_lowercase());
+        } else if ch.is_whitespace() || ch == '-' || ch == '_' {
+            out.push('-');
+        }
+    }
+    while out.contains("--") {
+        out = out.replace("--", "-");
+    }
+    out.trim_matches('-').to_string()
+}
+
+pub fn sanitize_argument_value(value: &str) -> Result<String> {
+    if value.len() > MAX_ARG_LENGTH {
+        return Err(AppError::InvalidInput {
+            message: format!("Argument too long (max {} chars)", MAX_ARG_LENGTH),
+        });
+    }
+
+    if value.contains('\n') || value.contains('\r') || value.contains('\t') {
+        return Err(AppError::InvalidInput {
+            message: "Argument contains forbidden control characters".to_string(),
+        });
+    }
+
+    // Use regex to catch dangerous tokens even with internal whitespace (e.g. $( pwd ))
+    // We use \b for eval and exec to avoid catching words like "evaluation"
+    static RE: std::sync::OnceLock<regex::Regex> = std::sync::OnceLock::new();
+    let re = RE.get_or_init(|| {
+        regex::Regex::new(r"(?i);|&&|&|\|\||\||`|\$\s*\(|\)|<|>|<<|<&|>&|\beval\b|\bexec\b")
+            .expect("Invalid dangerous tokens regex")
+    });
+
+    if let Some(m) = re.find(value) {
+        return Err(AppError::InvalidInput {
+            message: format!("Argument contains forbidden token: {}", m.as_str()),
+        });
+    }
+
+    Ok(value.to_string())
+}
+
+pub fn contains_disallowed_pattern(script: &str) -> Option<&'static str> {
+    let lower = script.to_lowercase();
+    let patterns: [(&str, &str); 15] = [
+        ("rm -rf", "rm -rf"),
+        ("del /f", "del /f"),
+        ("format ", "format"),
+        ("mkfs", "mkfs"),
+        ("shutdown", "shutdown"),
+        ("reboot", "reboot"),
+        ("curl |", "curl pipe"),
+        ("wget |", "wget pipe"),
+        ("`", "backticks"),
+        ("$(", "command substitution"),
+        ("eval ", "eval"),
+        ("exec ", "exec"),
+        ("<(", "process substitution"),
+        (">(", "process substitution"),
+        ("<<", "heredoc"),
+    ];
+
+    for (needle, name) in patterns {
+        if lower.contains(needle) {
+            return Some(name);
+        }
+    }
+
+    None
+}
+
+pub async fn execute_shell_with_timeout(
+    script: &str,
+    timeout_dur: Duration,
+) -> Result<(i32, String, String)> {
+    if script.trim().is_empty() {
+        return Err(AppError::InvalidInput {
+            message: "Cannot execute empty script".to_string(),
+        });
+    }
+
+    if script.len() > MAX_SCRIPT_LENGTH {
+        return Err(AppError::InvalidInput {
+            message: format!("Script too long (max {} chars)", MAX_SCRIPT_LENGTH),
+        });
+    }
+
+    #[cfg(target_os = "windows")]
+    let mut cmd = TokioCommand::new("cmd");
+    #[cfg(target_os = "windows")]
+    cmd.args(["/C", script]);
+
+    #[cfg(not(target_os = "windows"))]
+    let mut cmd = TokioCommand::new("sh");
+    #[cfg(not(target_os = "windows"))]
+    cmd.args(["-c", script]);
+
+    let future = cmd.output();
+
+    match timeout(timeout_dur, future).await {
+        Ok(Ok(output)) => {
+            let stdout = String::from_utf8_lossy(&output.stdout).to_string();
+            let stderr = String::from_utf8_lossy(&output.stderr).to_string();
+            Ok((output.status.code().unwrap_or(-1), stdout, stderr))
+        }
+        Ok(Err(e)) => Err(AppError::Io(e)),
+        Err(_) => Err(AppError::InvalidInput {
+            message: format!("Execution timed out after {}s", timeout_dur.as_secs()),
+        }),
+    }
+}
+
+pub async fn execute_shell_with_timeout_env(
+    script: &str,
+    timeout_dur: Duration,
+    envs: &[(String, String)],
+) -> Result<(i32, String, String)> {
+    if script.trim().is_empty() {
+        return Err(AppError::InvalidInput {
+            message: "Cannot execute empty script".to_string(),
+        });
+    }
+
+    if script.len() > MAX_SCRIPT_LENGTH {
+        return Err(AppError::InvalidInput {
+            message: format!("Script too long (max {} chars)", MAX_SCRIPT_LENGTH),
+        });
+    }
+
+    #[cfg(target_os = "windows")]
+    let mut cmd = TokioCommand::new("cmd");
+    #[cfg(target_os = "windows")]
+    cmd.args(["/C", script]);
+
+    #[cfg(not(target_os = "windows"))]
+    let mut cmd = TokioCommand::new("sh");
+    #[cfg(not(target_os = "windows"))]
+    cmd.args(["-c", script]);
+
+    cmd.envs(envs.iter().cloned());
+
+    let future = cmd.output();
+
+    match timeout(timeout_dur, future).await {
+        Ok(Ok(output)) => {
+            let stdout = String::from_utf8_lossy(&output.stdout).to_string();
+            let stderr = String::from_utf8_lossy(&output.stderr).to_string();
+            Ok((output.status.code().unwrap_or(-1), stdout, stderr))
+        }
+        Ok(Err(e)) => Err(AppError::Io(e)),
+        Err(_) => Err(AppError::InvalidInput {
+            message: format!("Execution timed out after {}s", timeout_dur.as_secs()),
+        }),
+    }
+}
diff --git a/src-tauri/src/file_storage/migration.rs b/src-tauri/src/file_storage/migration.rs
new file mode 100644
index 0000000..23ec384
--- /dev/null
+++ b/src-tauri/src/file_storage/migration.rs
@@ -0,0 +1,304 @@
+use std::fs;
+use std::path::PathBuf;
+use std::sync::atomic::{AtomicU32, Ordering};
+use std::sync::{Mutex, OnceLock};
+
+use crate::database::Database;
+use crate::error::{AppError, Result};
+use crate::file_storage::{save_rule_to_disk, StorageLocation};
+
+static MIGRATION_PROGRESS: AtomicU32 = AtomicU32::new(0);
+static MIGRATION_TOTAL: AtomicU32 = AtomicU32::new(0);
+static MIGRATION_STATE: OnceLock<Mutex<MigrationState>> = OnceLock::new();
+
+#[derive(Debug, Clone)]
+struct MigrationState {
+    current_rule: Option<String>,
+    status: MigrationStatus,
+}
+
+fn migration_state() -> &'static Mutex<MigrationState> {
+    MIGRATION_STATE.get_or_init(|| {
+        Mutex::new(MigrationState {
+            current_rule: None,
+            status: MigrationStatus::NotStarted,
+        })
+    })
+}
+
+#[allow(dead_code)]
+#[derive(Debug, Clone, serde::Serialize)]
+pub struct MigrationProgress {
+    pub total: u32,
+    pub migrated: u32,
+    pub current_rule: Option<String>,
+    pub status: MigrationStatus,
+}
+
+#[allow(dead_code)]
+#[derive(Debug, Clone, serde::Serialize, PartialEq)]
+pub enum MigrationStatus {
+    NotStarted,
+    InProgress,
+    Completed,
+    Failed,
+    RolledBack,
+}
+
+#[derive(Debug, Clone, serde::Serialize)]
+pub struct MigrationResult {
+    pub success: bool,
+    pub rules_migrated: u32,
+    pub rules_skipped: u32,
+    pub errors: Vec<MigrationError>,
+    pub backup_path: Option<String>,
+    pub storage_dir: String,
+}
+
+#[derive(Debug, Clone, serde::Serialize)]
+pub struct MigrationError {
+    pub rule_id: String,
+    pub rule_name: String,
+    pub error: String,
+}
+
+pub fn migrate_to_file_storage(db: &Database) -> Result<MigrationResult> {
+    MIGRATION_PROGRESS.store(0, Ordering::SeqCst);
+    MIGRATION_TOTAL.store(0, Ordering::SeqCst);
+    if let Ok(mut state) = migration_state().lock() {
+        state.current_rule = None;
+        state.status = MigrationStatus::InProgress;
+    }
+
+    let rules = db.get_all_rules()?;
+    let total = rules.len() as u32;
+    MIGRATION_TOTAL.store(total, Ordering::SeqCst);
+
+    if total == 0 {
+        if let Ok(mut state) = migration_state().lock() {
+            state.status = MigrationStatus::Completed;
+        }
+        return Ok(MigrationResult {
+            success: true,
+            rules_migrated: 0,
+            rules_skipped: 0,
+            errors: Vec::new(),
+            backup_path: None,
+            storage_dir: crate::file_storage::get_global_rules_dir()?
+                .to_string_lossy()
+                .to_string(),
+        });
+    }
+
+    let backup_path = create_backup(db)?;
+
+    let storage_dir = crate::file_storage::get_global_rules_dir()?;
+    fs::create_dir_all(&storage_dir)?;
+
+    let mut rules_migrated = 0u32;
+    let mut rules_skipped = 0u32;
+    let mut errors = Vec::new();
+    let mut local_rule_paths: Vec<String> = Vec::new();
+
+    for rule in &rules {
+        if let Ok(mut state) = migration_state().lock() {
+            state.current_rule = Some(rule.name.clone());
+        }
+        MIGRATION_PROGRESS.fetch_add(1, Ordering::SeqCst);
+
+        let location = match rule.scope {
+            crate::models::Scope::Global => StorageLocation::Global,
+            crate::models::Scope::Local => {
+                if let Some(ref paths) = rule.target_paths {
+                    if let Some(first_path) = paths.first() {
+                        StorageLocation::Local(PathBuf::from(first_path))
+                    } else {
+                        StorageLocation::Global
+                    }
+                } else {
+                    StorageLocation::Global
+                }
+            }
+        };
+
+        match save_rule_to_disk(rule, &location) {
+            Ok(_) => {
+                rules_migrated += 1;
+                if let Some(paths) = &rule.target_paths {
+                    for path in paths {
+                        if !local_rule_paths.iter().any(|p| p == path) {
+                            local_rule_paths.push(path.clone());
+                        }
+                    }
+                }
+                if let Err(e) = db.update_rule_file_index(&rule.id, &location) {
+                    errors.push(MigrationError {
+                        rule_id: rule.id.clone(),
+                        rule_name: rule.name.clone(),
+                        error: format!("Failed to update index: {}", e),
+                    });
+                }
+            }
+            Err(e) => {
+                rules_skipped += 1;
+                errors.push(MigrationError {
+                    rule_id: rule.id.clone(),
+                    rule_name: rule.name.clone(),
+                    error: e.to_string(),
+                });
+            }
+        }
+    }
+
+    let success = errors.is_empty();
+    if success {
+        let local_paths_json = serde_json::to_string(&local_rule_paths)?;
+        let _ = db.set_setting("local_rule_paths", &local_paths_json);
+    }
+    if let Ok(mut state) = migration_state().lock() {
+        state.current_rule = None;
+        state.status = if success {
+            MigrationStatus::Completed
+        } else {
+            MigrationStatus::Failed
+        };
+    }
+
+    Ok(MigrationResult {
+        success,
+        rules_migrated,
+        rules_skipped,
+        errors,
+        backup_path: Some(backup_path),
+        storage_dir: storage_dir.to_string_lossy().to_string(),
+    })
+}
+
+fn create_backup(db: &Database) -> Result<String> {
+    let db_path = db.get_database_path()?;
+    let now = chrono::Local::now().format("%Y%m%d%H%M%S");
+    let backup_path = format!("{}.{}.migration-backup", db_path, now);
+
+    fs::copy(&db_path, &backup_path).map_err(|e| AppError::InvalidInput {
+        message: format!("Failed to create database backup: {}", e),
+    })?;
+
+    Ok(backup_path)
+}
+
+pub fn rollback_migration(backup_path: &str) -> Result<()> {
+    // backup_path: /path/to/db.timestamp.migration-backup
+    let db_path = if let Some(stripped) = backup_path.strip_suffix(".migration-backup") {
+        if let Some(last_dot_idx) = stripped.rfind('.') {
+            &stripped[..last_dot_idx]
+        } else {
+            stripped
+        }
+    } else {
+        backup_path
+    };
+
+    if !PathBuf::from(backup_path).exists() {
+        return Err(AppError::InvalidInput {
+            message: "Backup file not found".to_string(),
+        });
+    }
+
+    fs::copy(backup_path, db_path).map_err(|e| AppError::InvalidInput {
+        message: format!("Failed to restore database from backup: {}", e),
+    })?;
+
+    fs::remove_file(backup_path).ok();
+
+    let storage_dir = crate::file_storage::get_global_rules_dir()?;
+    if storage_dir.exists() {
+        fs::remove_dir_all(&storage_dir).map_err(|e| AppError::InvalidInput {
+            message: format!("Failed to remove storage directory: {}", e),
+        })?;
+    }
+
+    if let Ok(mut state) = migration_state().lock() {
+        state.current_rule = None;
+        state.status = MigrationStatus::RolledBack;
+    }
+
+    Ok(())
+}
+
+#[allow(dead_code)]
+pub fn get_migration_progress() -> MigrationProgress {
+    let migrated = MIGRATION_PROGRESS.load(Ordering::SeqCst);
+    let total = MIGRATION_TOTAL.load(Ordering::SeqCst);
+    let (current_rule, status) = migration_state()
+        .lock()
+        .map(|s| (s.current_rule.clone(), s.status.clone()))
+        .unwrap_or((None, MigrationStatus::NotStarted));
+
+    MigrationProgress {
+        total,
+        migrated,
+        current_rule,
+        status,
+    }
+}
+
+pub fn verify_migration(db: &Database) -> Result<VerificationResult> {
+    let db_rules = db.get_all_rules()?;
+
+    let load_result = crate::file_storage::load_rules_from_disk()?;
+
+    let mut missing_rules = Vec::new();
+    let mut extra_rules = Vec::new();
+    let mut mismatched_rules = Vec::new();
+
+    for db_rule in &db_rules {
+        let found = load_result.rules.iter().find(|r| r.id == db_rule.id);
+        if found.is_none() {
+            missing_rules.push(db_rule.id.clone());
+        } else if let Some(file_rule) = found {
+            if file_rule.name != db_rule.name || file_rule.content != db_rule.content {
+                mismatched_rules.push(db_rule.id.clone());
+            }
+        }
+    }
+
+    for file_rule in &load_result.rules {
+        let found = db_rules.iter().find(|r| r.id == file_rule.id);
+        if found.is_none() {
+            extra_rules.push(file_rule.id.clone());
+        }
+    }
+
+    Ok(VerificationResult {
+        is_valid: missing_rules.is_empty() && mismatched_rules.is_empty(),
+        db_rule_count: db_rules.len() as u32,
+        file_rule_count: load_result.rules.len() as u32,
+        missing_rules,
+        extra_rules,
+        mismatched_rules,
+        load_errors: load_result.errors.len() as u32,
+    })
+}
+
+#[derive(Debug, Clone, serde::Serialize)]
+pub struct VerificationResult {
+    pub is_valid: bool,
+    pub db_rule_count: u32,
+    pub file_rule_count: u32,
+    pub missing_rules: Vec<String>,
+    pub extra_rules: Vec<String>,
+    pub mismatched_rules: Vec<String>,
+    pub load_errors: u32,
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn test_migration_status_default() {
+        let progress = get_migration_progress();
+        assert_eq!(progress.migrated, 0);
+        assert_eq!(progress.status, MigrationStatus::NotStarted);
+    }
+}
diff --git a/src-tauri/src/file_storage/mod.rs b/src-tauri/src/file_storage/mod.rs
new file mode 100644
index 0000000..41e6766
--- /dev/null
+++ b/src-tauri/src/file_storage/mod.rs
@@ -0,0 +1,518 @@
+mod migration;
+mod parser;
+mod serializer;
+pub mod watcher;
+
+#[allow(unused_imports)]
+pub use migration::{
+    get_migration_progress, migrate_to_file_storage, rollback_migration, verify_migration,
+    MigrationError, MigrationProgress, MigrationResult, MigrationStatus, VerificationResult,
+};
+#[allow(unused_imports)]
+pub use parser::{parse_rule_file, ParsedRuleFile, RuleFrontmatter};
+#[allow(unused_imports)]
+pub use serializer::{generate_filename, generate_rule_file_path, serialize_rule_to_file_content};
+#[allow(unused_imports)]
+pub use watcher::{FileChangeEvent, RuleFileWatcher};
+
+use std::fs;
+use std::io::Write;
+use std::path::{Path, PathBuf};
+
+use walkdir::WalkDir;
+
+use crate::error::{AppError, Result};
+use crate::models::Rule;
+
+pub const RULES_DIR_NAME: &str = "rules";
+pub const RULEWEAVER_DIR_NAME: &str = ".ruleweaver";
+
+pub fn get_global_rules_dir() -> Result<PathBuf> {
+    let home = dirs::home_dir()
+        .ok_or_else(|| AppError::Path("Could not determine home directory".to_string()))?;
+    Ok(home.join(RULEWEAVER_DIR_NAME).join(RULES_DIR_NAME))
+}
+
+pub fn get_local_rules_dir(project_path: &Path) -> PathBuf {
+    project_path.join(RULEWEAVER_DIR_NAME).join(RULES_DIR_NAME)
+}
+
+#[allow(dead_code)]
+#[derive(Debug, Clone)]
+pub struct RuleLoadResult {
+    pub rules: Vec<Rule>,
+    pub errors: Vec<RuleLoadError>,
+    pub files_scanned: u32,
+}
+
+#[allow(dead_code)]
+#[derive(Debug, Clone)]
+pub struct RuleLoadError {
+    pub file_path: String,
+    pub error: String,
+}
+
+#[derive(Debug, Clone)]
+pub enum StorageLocation {
+    Global,
+    Local(PathBuf),
+}
+
+pub fn load_rules_from_disk() -> Result<RuleLoadResult> {
+    load_rules_from_locations(&[])
+}
+
+pub fn load_rules_from_locations(local_roots: &[PathBuf]) -> Result<RuleLoadResult> {
+    let mut all_rules = Vec::new();
+    let mut all_errors = Vec::new();
+    let mut files_scanned = 0u32;
+
+    let global_dir = get_global_rules_dir()?;
+    if global_dir.exists() {
+        let (rules, errors, count) = load_rules_from_directory(&global_dir)?;
+        all_rules.extend(rules);
+        all_errors.extend(errors);
+        files_scanned += count;
+    }
+
+    for root in local_roots {
+        let local_dir = get_local_rules_dir(root);
+        if local_dir.exists() {
+            let (rules, errors, count) = load_rules_from_directory(&local_dir)?;
+            all_rules.extend(rules);
+            all_errors.extend(errors);
+            files_scanned += count;
+        }
+    }
+
+    let result = RuleLoadResult {
+        rules: all_rules,
+        errors: all_errors,
+        files_scanned,
+    };
+
+    Ok(result)
+}
+
+pub fn load_rules_from_directory(dir: &Path) -> Result<(Vec<Rule>, Vec<RuleLoadError>, u32)> {
+    let mut rules = Vec::new();
+    let mut errors = Vec::new();
+    let mut files_scanned = 0u32;
+
+    if !dir.exists() {
+        return Ok((rules, errors, files_scanned));
+    }
+
+    for entry in WalkDir::new(dir)
+        .follow_links(true)
+        .into_iter()
+        .filter_map(|e| e.ok())
+    {
+        let path = entry.path();
+
+        if !path.is_file() {
+            continue;
+        }
+
+        let extension = path.extension().and_then(|e| e.to_str());
+        if extension != Some("md") {
+            continue;
+        }
+
+        files_scanned += 1;
+
+        match load_rule_from_file(path) {
+            Ok(rule) => rules.push(rule),
+            Err(e) => errors.push(RuleLoadError {
+                file_path: path.to_string_lossy().to_string(),
+                error: e.to_string(),
+            }),
+        }
+    }
+
+    Ok((rules, errors, files_scanned))
+}
+
+pub fn load_rule_from_file(path: &Path) -> Result<Rule> {
+    let content = fs::read_to_string(path).map_err(|e| AppError::InvalidInput {
+        message: format!("Failed to read file '{}': {}", path.display(), e),
+    })?;
+
+    let parsed = parse_rule_file(path, &content)?;
+    parsed.to_rule()
+}
+
+pub fn save_rule_to_disk(rule: &Rule, location: &StorageLocation) -> Result<PathBuf> {
+    let base_dir = match location {
+        StorageLocation::Global => get_global_rules_dir()?,
+        StorageLocation::Local(project_path) => get_local_rules_dir(project_path),
+    };
+
+    fs::create_dir_all(&base_dir)?;
+
+    let file_content = serialize_rule_to_file_content(rule)?;
+
+    let file_path = find_or_create_rule_file(&base_dir, rule)?;
+
+    let temp_path = file_path.with_extension("md.tmp");
+    {
+        let mut file = fs::File::create(&temp_path)?;
+        file.write_all(file_content.as_bytes())?;
+        file.sync_all()?;
+    }
+
+    fs::rename(&temp_path, &file_path)?;
+
+    Ok(file_path)
+}
+
+fn find_or_create_rule_file(base_dir: &Path, rule: &Rule) -> Result<PathBuf> {
+    for entry in WalkDir::new(base_dir).into_iter().filter_map(|e| e.ok()) {
+        let path = entry.path();
+        if !path.is_file() {
+            continue;
+        }
+
+        if path.extension().and_then(|e| e.to_str()) != Some("md") {
+            continue;
+        }
+
+        match fs::read_to_string(path) {
+            Ok(content) => {
+                if let Ok(parsed) = parse_rule_file(path, &content) {
+                    if parsed.frontmatter.id == rule.id {
+                        return Ok(path.to_path_buf());
+                    }
+                }
+            }
+            Err(_) => continue,
+        }
+    }
+
+    Ok(generate_rule_file_path(base_dir, rule))
+}
+
+pub fn delete_rule_file(rule_id: &str, location: &StorageLocation) -> Result<bool> {
+    let base_dir = match location {
+        StorageLocation::Global => get_global_rules_dir()?,
+        StorageLocation::Local(project_path) => get_local_rules_dir(project_path),
+    };
+
+    if !base_dir.exists() {
+        return Ok(false);
+    }
+
+    for entry in WalkDir::new(&base_dir).into_iter().filter_map(|e| e.ok()) {
+        let path = entry.path();
+        if !path.is_file() {
+            continue;
+        }
+
+        if path.extension().and_then(|e| e.to_str()) != Some("md") {
+            continue;
+        }
+
+        match fs::read_to_string(path) {
+            Ok(content) => {
+                if let Ok(parsed) = parse_rule_file(path, &content) {
+                    if parsed.frontmatter.id == rule_id {
+                        fs::remove_file(path)?;
+                        return Ok(true);
+                    }
+                }
+            }
+            Err(_) => continue,
+        }
+    }
+
+    Ok(false)
+}
+
+#[allow(dead_code)]
+pub fn get_rule_file_path(rule_id: &str, location: &StorageLocation) -> Result<Option<PathBuf>> {
+    let base_dir = match location {
+        StorageLocation::Global => get_global_rules_dir()?,
+        StorageLocation::Local(project_path) => get_local_rules_dir(project_path),
+    };
+
+    if !base_dir.exists() {
+        return Ok(None);
+    }
+
+    for entry in WalkDir::new(&base_dir).into_iter().filter_map(|e| e.ok()) {
+        let path = entry.path();
+        if !path.is_file() {
+            continue;
+        }
+
+        if path.extension().and_then(|e| e.to_str()) != Some("md") {
+            continue;
+        }
+
+        match fs::read_to_string(path) {
+            Ok(content) => {
+                if let Ok(parsed) = parse_rule_file(path, &content) {
+                    if parsed.frontmatter.id == rule_id {
+                        return Ok(Some(path.to_path_buf()));
+                    }
+                }
+            }
+            Err(_) => continue,
+        }
+    }
+
+    Ok(None)
+}
+
+#[allow(dead_code)]
+pub fn storage_exists() -> bool {
+    get_global_rules_dir()
+        .map(|dir| dir.exists())
+        .unwrap_or(false)
+}
+
+pub fn get_storage_info() -> Result<StorageInfo> {
+    let global_dir = get_global_rules_dir()?;
+
+    let exists = global_dir.exists();
+    let mut rule_count = 0u32;
+    let mut total_size = 0u64;
+
+    if exists {
+        for entry in WalkDir::new(&global_dir).into_iter().filter_map(|e| e.ok()) {
+            let path = entry.path();
+            if path.is_file() && path.extension().and_then(|e| e.to_str()) == Some("md") {
+                rule_count += 1;
+                if let Ok(metadata) = fs::metadata(path) {
+                    total_size += metadata.len();
+                }
+            }
+        }
+    }
+
+    Ok(StorageInfo {
+        global_dir,
+        exists,
+        rule_count,
+        total_size_bytes: total_size,
+    })
+}
+
+#[allow(dead_code)]
+#[derive(Debug, Clone)]
+pub struct StorageInfo {
+    pub global_dir: PathBuf,
+    pub exists: bool,
+    pub rule_count: u32,
+    pub total_size_bytes: u64,
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use crate::models::Scope;
+    use std::fs;
+    use std::path::PathBuf;
+
+    fn create_temp_test_dir() -> PathBuf {
+        let temp_dir =
+            std::env::temp_dir().join(format!("ruleweaver_test_{}", uuid::Uuid::new_v4()));
+        fs::create_dir_all(&temp_dir).expect("Failed to create temp dir");
+        temp_dir
+    }
+
+    fn cleanup_temp_dir(dir: &Path) {
+        let _ = fs::remove_dir_all(dir);
+    }
+
+    fn create_test_rule_content(id: &str, name: &str, body: &str) -> String {
+        format!(
+            "---\nid: {}\nname: {}\nscope: global\nenabledAdapters: [gemini]\ncreatedAt: 2024-01-15T10:30:00Z\nupdatedAt: 2024-01-15T10:30:00Z\n---\n{}\n",
+            id, name, body
+        )
+    }
+
+    #[test]
+    fn test_load_rules_from_empty_directory() {
+        let temp_dir = create_temp_test_dir();
+        let rules_dir = temp_dir.join(".ruleweaver").join("rules");
+        fs::create_dir_all(&rules_dir).expect("Failed to create rules dir");
+
+        let (rules, errors, count) = load_rules_from_directory(&rules_dir).unwrap();
+
+        assert!(rules.is_empty());
+        assert!(errors.is_empty());
+        assert_eq!(count, 0);
+
+        cleanup_temp_dir(&temp_dir);
+    }
+
+    #[test]
+    fn test_load_rules_from_directory_with_valid_files() {
+        let temp_dir = create_temp_test_dir();
+        let rules_dir = temp_dir.join(".ruleweaver").join("rules");
+        fs::create_dir_all(&rules_dir).expect("Failed to create rules dir");
+
+        let rule1_content = create_test_rule_content("rule-1", "First Rule", "Content 1");
+        let rule2_content = create_test_rule_content("rule-2", "Second Rule", "Content 2");
+
+        fs::write(rules_dir.join("rule1.md"), &rule1_content).expect("Failed to write rule1");
+        fs::write(rules_dir.join("rule2.md"), &rule2_content).expect("Failed to write rule2");
+
+        let (rules, errors, count) = load_rules_from_directory(&rules_dir).unwrap();
+
+        assert_eq!(rules.len(), 2);
+        assert!(errors.is_empty());
+        assert_eq!(count, 2);
+
+        let ids: Vec<&str> = rules.iter().map(|r| r.id.as_str()).collect();
+        assert!(ids.contains(&"rule-1"));
+        assert!(ids.contains(&"rule-2"));
+
+        cleanup_temp_dir(&temp_dir);
+    }
+
+    #[test]
+    fn test_load_rules_from_directory_with_invalid_file() {
+        let temp_dir = create_temp_test_dir();
+        let rules_dir = temp_dir.join(".ruleweaver").join("rules");
+        fs::create_dir_all(&rules_dir).expect("Failed to create rules dir");
+
+        let valid_content = create_test_rule_content("valid-rule", "Valid Rule", "Valid content");
+        let invalid_content = "This is not valid frontmatter";
+
+        fs::write(rules_dir.join("valid.md"), &valid_content).expect("Failed to write valid");
+        fs::write(rules_dir.join("invalid.md"), invalid_content).expect("Failed to write invalid");
+
+        let (rules, errors, count) = load_rules_from_directory(&rules_dir).unwrap();
+
+        assert_eq!(rules.len(), 1);
+        assert_eq!(errors.len(), 1);
+        assert_eq!(count, 2);
+        assert_eq!(rules[0].id, "valid-rule");
+        assert!(errors[0].file_path.contains("invalid.md"));
+
+        cleanup_temp_dir(&temp_dir);
+    }
+
+    #[test]
+    fn test_load_rules_ignores_non_markdown_files() {
+        let temp_dir = create_temp_test_dir();
+        let rules_dir = temp_dir.join(".ruleweaver").join("rules");
+        fs::create_dir_all(&rules_dir).expect("Failed to create rules dir");
+
+        let rule_content = create_test_rule_content("only-rule", "Only Rule", "Content");
+
+        fs::write(rules_dir.join("rule.md"), &rule_content).expect("Failed to write rule");
+        fs::write(rules_dir.join("readme.txt"), "Not a rule file").expect("Failed to write txt");
+        fs::write(rules_dir.join("data.json"), "{}").expect("Failed to write json");
+
+        let (rules, errors, count) = load_rules_from_directory(&rules_dir).unwrap();
+
+        assert_eq!(rules.len(), 1);
+        assert!(errors.is_empty());
+        assert_eq!(count, 1);
+
+        cleanup_temp_dir(&temp_dir);
+    }
+
+    #[test]
+    fn test_save_rule_creates_new_file() {
+        let temp_dir = create_temp_test_dir();
+
+        let rule = Rule {
+            id: "new-rule-id".to_string(),
+            name: "New Test Rule".to_string(),
+            content: "New content".to_string(),
+            scope: Scope::Global,
+            target_paths: None,
+            enabled_adapters: vec![crate::models::AdapterType::Gemini],
+            enabled: true,
+            created_at: chrono::Utc::now(),
+            updated_at: chrono::Utc::now(),
+        };
+
+        let result = save_rule_to_disk(&rule, &StorageLocation::Local(temp_dir.clone()));
+
+        assert!(result.is_ok());
+        let saved_path = result.unwrap();
+        assert!(saved_path.exists());
+        assert!(saved_path.to_string_lossy().ends_with(".md"));
+
+        let loaded = load_rule_from_file(&saved_path).unwrap();
+        assert_eq!(loaded.id, "new-rule-id");
+        assert_eq!(loaded.name, "New Test Rule");
+
+        cleanup_temp_dir(&temp_dir);
+    }
+
+    #[test]
+    fn test_delete_rule_file() {
+        let temp_dir = create_temp_test_dir();
+        let rules_dir = temp_dir.join(".ruleweaver").join("rules");
+        fs::create_dir_all(&rules_dir).expect("Failed to create rules dir");
+
+        let rule_content = create_test_rule_content("to-delete", "Rule to Delete", "Content");
+        let rule_path = rules_dir.join("delete-me.md");
+        fs::write(&rule_path, &rule_content).expect("Failed to write rule");
+
+        assert!(rule_path.exists());
+
+        let deleted =
+            delete_rule_file("to-delete", &StorageLocation::Local(temp_dir.clone())).unwrap();
+        assert!(deleted);
+        assert!(!rule_path.exists());
+
+        cleanup_temp_dir(&temp_dir);
+    }
+
+    #[test]
+    fn test_delete_rule_file_not_found() {
+        let temp_dir = create_temp_test_dir();
+        let result =
+            delete_rule_file("nonexistent", &StorageLocation::Local(temp_dir.clone())).unwrap();
+        assert!(!result);
+        cleanup_temp_dir(&temp_dir);
+    }
+
+    #[test]
+    fn test_generate_filename_sanitization() {
+        let rule = Rule {
+            id: "test".to_string(),
+            name: "Test @#$% Rule!!!".to_string(),
+            content: String::new(),
+            scope: Scope::Global,
+            target_paths: None,
+            enabled_adapters: vec![crate::models::AdapterType::Gemini],
+            enabled: true,
+            created_at: chrono::Utc::now(),
+            updated_at: chrono::Utc::now(),
+        };
+
+        let filename = generate_filename(&rule);
+        assert!(!filename.contains('@'));
+        assert!(!filename.contains('#'));
+        assert!(!filename.contains('!'));
+        assert!(filename.ends_with(".md"));
+    }
+
+    #[test]
+    fn test_load_rules_from_locations_includes_local_roots() {
+        let temp_dir = create_temp_test_dir();
+        let local_root = temp_dir.join("repo-a");
+        let local_rules_dir = local_root.join(".ruleweaver").join("rules");
+        fs::create_dir_all(&local_rules_dir).expect("Failed to create local rules dir");
+
+        let local_rule_content =
+            create_test_rule_content("local-rule-1", "Local Rule", "Local Content");
+        fs::write(local_rules_dir.join("local-rule.md"), &local_rule_content)
+            .expect("Failed to write local rule");
+
+        let result = load_rules_from_locations(&[local_root.clone()]).unwrap();
+
+        assert!(result.rules.iter().any(|r| r.id == "local-rule-1"));
+        assert!(result.files_scanned >= 1);
+
+        cleanup_temp_dir(&temp_dir);
+    }
+}
diff --git a/src-tauri/src/file_storage/parser.rs b/src-tauri/src/file_storage/parser.rs
new file mode 100644
index 0000000..276c574
--- /dev/null
+++ b/src-tauri/src/file_storage/parser.rs
@@ -0,0 +1,361 @@
+use chrono::{DateTime, Utc};
+use regex::Regex;
+use serde::Deserialize;
+use std::path::Path;
+use std::sync::OnceLock;
+
+use crate::error::{AppError, Result};
+use crate::models::{AdapterType, Rule, Scope};
+
+const FRONTMATTER_DELIMITER: &str = "---";
+
+#[derive(Debug, Clone, Deserialize)]
+pub struct RuleFrontmatter {
+    pub id: String,
+    pub name: String,
+    #[serde(default)]
+    pub scope: String,
+    #[serde(default, rename = "targetPaths")]
+    pub target_paths: Option<Vec<String>>,
+    #[serde(default, rename = "enabledAdapters")]
+    pub enabled_adapters: Vec<String>,
+    #[serde(default = "default_true")]
+    pub enabled: bool,
+    #[serde(rename = "createdAt")]
+    pub created_at: String,
+    #[serde(rename = "updatedAt")]
+    pub updated_at: String,
+}
+
+fn default_true() -> bool {
+    true
+}
+
+#[allow(dead_code)]
+#[derive(Debug, Clone)]
+pub struct ParsedRuleFile {
+    pub frontmatter: RuleFrontmatter,
+    pub content: String,
+    pub file_path: String,
+}
+
+impl ParsedRuleFile {
+    pub fn to_rule(&self) -> Result<Rule> {
+        let scope = Scope::from_str(&self.frontmatter.scope).unwrap_or(Scope::Global);
+
+        let enabled_adapters: Vec<AdapterType> = self
+            .frontmatter
+            .enabled_adapters
+            .iter()
+            .filter_map(|s| AdapterType::from_str(s))
+            .collect();
+
+        if enabled_adapters.is_empty() {
+            return Err(AppError::InvalidInput {
+                message: format!(
+                    "Rule '{}' has no valid enabled adapters",
+                    self.frontmatter.name
+                ),
+            });
+        }
+
+        let created_at = parse_iso_datetime(&self.frontmatter.created_at)?;
+        let updated_at = parse_iso_datetime(&self.frontmatter.updated_at)?;
+
+        Ok(Rule {
+            id: self.frontmatter.id.clone(),
+            name: self.frontmatter.name.clone(),
+            content: self.content.clone(),
+            scope,
+            target_paths: self.frontmatter.target_paths.clone(),
+            enabled_adapters,
+            enabled: self.frontmatter.enabled,
+            created_at,
+            updated_at,
+        })
+    }
+}
+
+fn parse_iso_datetime(s: &str) -> Result<DateTime<Utc>> {
+    DateTime::parse_from_rfc3339(s)
+        .map(|dt| dt.with_timezone(&Utc))
+        .or_else(|_| {
+            chrono::NaiveDateTime::parse_from_str(s, "%Y-%m-%dT%H:%M:%S")
+                .map(|dt| DateTime::from_naive_utc_and_offset(dt, Utc))
+        })
+        .or_else(|_| {
+            chrono::NaiveDateTime::parse_from_str(s, "%Y-%m-%d %H:%M:%S")
+                .map(|dt| DateTime::from_naive_utc_and_offset(dt, Utc))
+        })
+        .or_else(|_| {
+            chrono::NaiveDate::parse_from_str(s, "%Y-%m-%d")
+                .map(|d| d.and_hms_opt(0, 0, 0).unwrap_or_default())
+                .map(|dt| DateTime::from_naive_utc_and_offset(dt, Utc))
+        })
+        .map_err(|e| AppError::InvalidInput {
+            message: format!("Invalid datetime format '{}': {}", s, e),
+        })
+}
+
+pub fn parse_rule_file(file_path: &Path, raw_content: &str) -> Result<ParsedRuleFile> {
+    let content = raw_content.trim_start();
+
+    if !content.starts_with(FRONTMATTER_DELIMITER) {
+        return Err(AppError::InvalidInput {
+            message: format!(
+                "File '{}' does not contain valid YAML frontmatter (missing opening ---)",
+                file_path.display()
+            ),
+        });
+    }
+
+    static RE: OnceLock<Regex> = OnceLock::new();
+    let re = RE.get_or_init(|| {
+        Regex::new(r"^---\s*\n([\s\S]*?)\n---\s*\n?([\s\S]*)$").expect("Invalid rule regex")
+    });
+
+    let caps = re.captures(content).ok_or_else(|| AppError::InvalidInput {
+        message: format!(
+            "File '{}' has invalid frontmatter format (missing closing --- or malformed structure)",
+            file_path.display()
+        ),
+    })?;
+
+    let yaml_str = caps.get(1).map(|m| m.as_str()).unwrap_or("");
+    let body = caps.get(2).map(|m| m.as_str()).unwrap_or("").to_string();
+
+    let frontmatter: RuleFrontmatter = serde_yaml::from_str(yaml_str).map_err(|e| {
+        let error_msg = match e.location() {
+            Some(loc) => format!(" at line {}, column {}", loc.line(), loc.column()),
+            None => String::new(),
+        };
+        AppError::InvalidInput {
+            message: format!(
+                "Failed to parse YAML frontmatter in '{}'{}: {}",
+                file_path.display(),
+                error_msg,
+                e
+            ),
+        }
+    })?;
+
+    validate_frontmatter(&frontmatter, file_path)?;
+
+    Ok(ParsedRuleFile {
+        frontmatter,
+        content: body,
+        file_path: file_path.to_string_lossy().to_string(),
+    })
+}
+
+fn validate_frontmatter(fm: &RuleFrontmatter, file_path: &Path) -> Result<()> {
+    if fm.id.trim().is_empty() {
+        return Err(AppError::InvalidInput {
+            message: format!(
+                "Rule in '{}' has empty or missing 'id' field",
+                file_path.display()
+            ),
+        });
+    }
+
+    if fm.name.trim().is_empty() {
+        return Err(AppError::InvalidInput {
+            message: format!(
+                "Rule in '{}' has empty or missing 'name' field",
+                file_path.display()
+            ),
+        });
+    }
+
+    if fm.created_at.trim().is_empty() {
+        return Err(AppError::InvalidInput {
+            message: format!(
+                "Rule in '{}' has empty or missing 'createdAt' field",
+                file_path.display()
+            ),
+        });
+    }
+
+    if fm.updated_at.trim().is_empty() {
+        return Err(AppError::InvalidInput {
+            message: format!(
+                "Rule in '{}' has empty or missing 'updatedAt' field",
+                file_path.display()
+            ),
+        });
+    }
+
+    Ok(())
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use std::path::PathBuf;
+
+    fn create_test_path(name: &str) -> PathBuf {
+        PathBuf::from(format!("/test/{}.md", name))
+    }
+
+    #[test]
+    fn test_parse_rule_file_success() {
+        let content = r#"---
+id: test-123
+name: "Test Rule"
+scope: global
+targetPaths: null
+enabledAdapters: [gemini, opencode]
+enabled: true
+createdAt: 2024-01-15T10:30:00Z
+updatedAt: 2024-01-15T10:30:00Z
+---
+
+# Test Rule Content
+
+This is the rule body.
+"#;
+
+        let result = parse_rule_file(&create_test_path("test"), content);
+        assert!(result.is_ok());
+
+        let parsed = result.unwrap();
+        assert_eq!(parsed.frontmatter.id, "test-123");
+        assert_eq!(parsed.frontmatter.name, "Test Rule");
+        assert!(parsed.content.contains("Test Rule Content"));
+    }
+
+    #[test]
+    fn test_parse_rule_file_missing_frontmatter() {
+        let content = "# Just markdown\nNo frontmatter here.";
+
+        let result = parse_rule_file(&create_test_path("test"), content);
+        assert!(result.is_err());
+        assert!(result
+            .unwrap_err()
+            .to_string()
+            .contains("missing opening ---"));
+    }
+
+    #[test]
+    fn test_parse_rule_file_invalid_yaml() {
+        let content = "---\nid: [invalid yaml\n---\nContent";
+
+        let result = parse_rule_file(&create_test_path("test"), content);
+        assert!(result.is_err());
+    }
+
+    #[test]
+    fn test_parse_rule_file_missing_required_field() {
+        let content = "---\nname: Test\n---\nContent";
+
+        let result = parse_rule_file(&create_test_path("test"), content);
+        assert!(result.is_err());
+    }
+
+    #[test]
+    fn test_parse_rule_file_missing_closing_delimiter() {
+        let content = "---\nid: test-123\nname: Test\n\nNo closing delimiter";
+
+        let result = parse_rule_file(&create_test_path("test"), content);
+        assert!(result.is_err());
+        assert!(result
+            .unwrap_err()
+            .to_string()
+            .contains("missing closing ---"));
+    }
+
+    #[test]
+    fn test_to_rule_conversion() {
+        let content = r#"---
+id: test-456
+name: "Conversion Test"
+scope: local
+targetPaths: ["/src"]
+enabledAdapters: [gemini, cline]
+enabled: false
+createdAt: 2024-01-15T10:30:00Z
+updatedAt: 2024-01-16T14:20:00Z
+---
+
+Test body.
+"#;
+
+        let parsed = parse_rule_file(&create_test_path("test"), content).unwrap();
+        let rule = parsed.to_rule().unwrap();
+
+        assert_eq!(rule.id, "test-456");
+        assert_eq!(rule.name, "Conversion Test");
+        assert!(matches!(rule.scope, Scope::Local));
+        assert_eq!(rule.target_paths, Some(vec!["/src".to_string()]));
+        assert_eq!(rule.enabled_adapters.len(), 2);
+        assert!(!rule.enabled);
+    }
+
+    #[test]
+    fn test_to_rule_no_valid_adapters() {
+        let content = r#"---
+id: test-789
+name: "Invalid Adapters"
+scope: global
+enabledAdapters: [invalid, unknown]
+createdAt: 2024-01-15T10:30:00Z
+updatedAt: 2024-01-15T10:30:00Z
+---
+Content
+"#;
+
+        let parsed = parse_rule_file(&create_test_path("test"), content).unwrap();
+        let result = parsed.to_rule();
+        assert!(result.is_err());
+        assert!(result
+            .unwrap_err()
+            .to_string()
+            .contains("no valid enabled adapters"));
+    }
+
+    #[test]
+    fn test_parse_datetime_formats() {
+        let iso_result = parse_iso_datetime("2024-01-15T10:30:00Z");
+        assert!(iso_result.is_ok());
+
+        let no_tz_result = parse_iso_datetime("2024-01-15T10:30:00");
+        assert!(no_tz_result.is_ok());
+
+        let date_only_result = parse_iso_datetime("2024-01-15");
+        assert!(date_only_result.is_ok());
+
+        let space_format_result = parse_iso_datetime("2024-01-15 10:30:00");
+        assert!(space_format_result.is_ok());
+    }
+
+    #[test]
+    fn test_parse_rule_file_empty_body() {
+        let content = "---\nid: test-empty\nname: Empty\nscope: global\nenabledAdapters: [gemini]\ncreatedAt: 2024-01-15T10:30:00Z\nupdatedAt: 2024-01-15T10:30:00Z\n---\n";
+
+        let result = parse_rule_file(&create_test_path("test"), content);
+        assert!(result.is_ok());
+
+        let parsed = result.unwrap();
+        assert_eq!(parsed.content, "");
+    }
+
+    #[test]
+    fn test_parse_rule_file_whitespace_handling() {
+        let content = "   \n  ---\nid: test-ws\nname: Whitespace Test\nscope: global\nenabledAdapters: [gemini]\ncreatedAt: 2024-01-15T10:30:00Z\nupdatedAt: 2024-01-15T10:30:00Z\n---\n  \n  Body content  \n";
+
+        let result = parse_rule_file(&create_test_path("test"), content);
+        assert!(result.is_ok());
+    }
+
+    #[test]
+    fn test_parse_rule_file_default_values() {
+        let content = "---\nid: test-defaults\nname: Defaults Test\nenabledAdapters: [gemini]\ncreatedAt: 2024-01-15T10:30:00Z\nupdatedAt: 2024-01-15T10:30:00Z\n---\nBody";
+
+        let parsed = parse_rule_file(&create_test_path("test"), content).unwrap();
+        let rule = parsed.to_rule().unwrap();
+
+        assert!(matches!(rule.scope, Scope::Global));
+        assert!(rule.enabled);
+        assert!(rule.target_paths.is_none());
+    }
+}
diff --git a/src-tauri/src/file_storage/serializer.rs b/src-tauri/src/file_storage/serializer.rs
new file mode 100644
index 0000000..81372d0
--- /dev/null
+++ b/src-tauri/src/file_storage/serializer.rs
@@ -0,0 +1,247 @@
+use chrono::{DateTime, Utc};
+use serde::Serialize;
+use std::path::Path;
+
+use crate::error::Result;
+use crate::models::Rule;
+
+#[derive(Debug, Clone, Serialize)]
+pub struct RuleFrontmatter {
+    pub id: String,
+    pub name: String,
+    pub scope: String,
+    #[serde(skip_serializing_if = "Option::is_none", rename = "targetPaths")]
+    pub target_paths: Option<Vec<String>>,
+    #[serde(rename = "enabledAdapters")]
+    pub enabled_adapters: Vec<String>,
+    pub enabled: bool,
+    #[serde(rename = "createdAt")]
+    pub created_at: String,
+    #[serde(rename = "updatedAt")]
+    pub updated_at: String,
+}
+
+impl From<&Rule> for RuleFrontmatter {
+    fn from(rule: &Rule) -> Self {
+        Self {
+            id: rule.id.clone(),
+            name: rule.name.clone(),
+            scope: rule.scope.as_str().to_string(),
+            target_paths: rule.target_paths.clone(),
+            enabled_adapters: rule
+                .enabled_adapters
+                .iter()
+                .map(|a| a.as_str().to_string())
+                .collect(),
+            enabled: rule.enabled,
+            created_at: format_datetime(rule.created_at),
+            updated_at: format_datetime(rule.updated_at),
+        }
+    }
+}
+
+fn format_datetime(dt: DateTime<Utc>) -> String {
+    dt.format("%Y-%m-%dT%H:%M:%SZ").to_string()
+}
+
+pub fn serialize_rule_to_file_content(rule: &Rule) -> Result<String> {
+    let frontmatter = RuleFrontmatter::from(rule);
+    let yaml =
+        serde_yaml::to_string(&frontmatter).map_err(|e| crate::error::AppError::InvalidInput {
+            message: format!("Failed to serialize rule to YAML: {}", e),
+        })?;
+
+    let content = rule.content.trim();
+
+    Ok(format!(
+        "---\n{}---\n{}{}\n",
+        yaml,
+        content,
+        if content.is_empty() { "" } else { "\n" }
+    ))
+}
+
+pub fn generate_filename(rule: &Rule) -> String {
+    let safe_name = sanitize_filename(&rule.name);
+    let prefix = match rule.scope {
+        crate::models::Scope::Global => "",
+        crate::models::Scope::Local => "local-",
+    };
+    format!("{}{}.md", prefix, safe_name)
+}
+
+fn sanitize_filename(name: &str) -> String {
+    let mut result = String::new();
+    for c in name.chars() {
+        match c {
+            'a'..='z' | 'A'..='Z' | '0'..='9' | '-' | '_' => result.push(c.to_ascii_lowercase()),
+            ' ' | '.' | ',' | ':' | ';' | '!' | '?' | '(' | ')' | '[' | ']' | '{' | '}' => {
+                result.push('-')
+            }
+            _ => {
+                let id_char = format!("-{:x}-", c as u32);
+                result.push_str(&id_char);
+            }
+        }
+    }
+
+    while result.contains("--") {
+        result = result.replace("--", "-");
+    }
+
+    let trimmed = result.trim_matches('-').to_string();
+    if trimmed.is_empty() {
+        "unnamed-rule".to_string()
+    } else {
+        trimmed
+    }
+}
+
+pub fn generate_rule_file_path(base_dir: &Path, rule: &Rule) -> std::path::PathBuf {
+    base_dir.join(generate_filename(rule))
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use crate::models::AdapterType;
+    use crate::models::Scope;
+
+    fn create_test_rule(name: &str, scope: Scope) -> Rule {
+        Rule {
+            id: "test-id-123".to_string(),
+            name: name.to_string(),
+            content: "Test content".to_string(),
+            scope,
+            target_paths: None,
+            enabled_adapters: vec![AdapterType::Gemini],
+            enabled: true,
+            created_at: Utc::now(),
+            updated_at: Utc::now(),
+        }
+    }
+
+    #[test]
+    fn test_serialize_rule_basic() {
+        let rule = create_test_rule("Test Rule", Scope::Global);
+        let result = serialize_rule_to_file_content(&rule);
+        assert!(result.is_ok());
+
+        let content = result.unwrap();
+        assert!(content.starts_with("---\n"));
+        assert!(content.contains("id: test-id-123"));
+        assert!(content.contains("name: Test Rule"));
+        assert!(content.contains("scope: global"));
+        assert!(content.contains("---\nTest content"));
+    }
+
+    #[test]
+    fn test_serialize_rule_with_target_paths() {
+        let mut rule = create_test_rule("Local Rule", Scope::Local);
+        rule.target_paths = Some(vec!["/path/to/project".to_string()]);
+
+        let content = serialize_rule_to_file_content(&rule).unwrap();
+        assert!(content.contains("targetPaths:"));
+        assert!(content.contains("/path/to/project"));
+    }
+
+    #[test]
+    fn test_serialize_rule_empty_content() {
+        let mut rule = create_test_rule("Empty", Scope::Global);
+        rule.content = String::new();
+
+        let content = serialize_rule_to_file_content(&rule).unwrap();
+        assert!(content.ends_with("---\n\n"));
+    }
+
+    #[test]
+    fn test_sanitize_filename_simple() {
+        assert_eq!(sanitize_filename("Simple Name"), "simple-name");
+        assert_eq!(sanitize_filename("AnotherTest"), "anothertest");
+        assert_eq!(sanitize_filename("Test 123"), "test-123");
+    }
+
+    #[test]
+    fn test_sanitize_filename_special_chars() {
+        assert_eq!(sanitize_filename("Test (Copy)"), "test-copy");
+        assert_eq!(sanitize_filename("Hello! World?"), "hello-world");
+        assert_eq!(sanitize_filename("A & B"), "a-26-b");
+    }
+
+    #[test]
+    fn test_sanitize_filename_unicode() {
+        let result = sanitize_filename("æ—¥æœ¬èªãƒ«ãƒ¼ãƒ«");
+        assert!(!result.is_empty());
+        assert!(!result.contains("æ—¥æœ¬èª"));
+    }
+
+    #[test]
+    fn test_sanitize_filename_multiple_spaces() {
+        assert_eq!(
+            sanitize_filename("Test   Multiple   Spaces"),
+            "test-multiple-spaces"
+        );
+    }
+
+    #[test]
+    fn test_sanitize_filename_leading_trailing_dashes() {
+        assert_eq!(sanitize_filename("---Test---"), "test");
+        assert_eq!(sanitize_filename("- - Test - -"), "test");
+    }
+
+    #[test]
+    fn test_sanitize_filename_empty() {
+        assert_eq!(sanitize_filename(""), "unnamed-rule");
+        assert_eq!(sanitize_filename("   "), "unnamed-rule");
+        assert_eq!(sanitize_filename("---"), "unnamed-rule");
+    }
+
+    #[test]
+    fn test_generate_filename_global() {
+        let rule = create_test_rule("My Global Rule", Scope::Global);
+        let filename = generate_filename(&rule);
+        assert_eq!(filename, "my-global-rule.md");
+    }
+
+    #[test]
+    fn test_generate_filename_local() {
+        let rule = create_test_rule("My Local Rule", Scope::Local);
+        let filename = generate_filename(&rule);
+        assert_eq!(filename, "local-my-local-rule.md");
+    }
+
+    #[test]
+    fn test_roundtrip_parse_serialize() {
+        let original_content = "---\nid: roundtrip-123\nname: Roundtrip Test\nscope: global\nenabledAdapters:\n- gemini\n- opencode\nenabled: true\ntargetPaths:\n- /src\ncreatedAt: 2024-01-15T10:30:00Z\nupdatedAt: 2024-01-16T14:20:00Z\n---\n\nThis is the body content.\n";
+
+        let parsed = crate::file_storage::parser::parse_rule_file(
+            std::path::Path::new("test.md"),
+            original_content,
+        )
+        .unwrap();
+        let rule = parsed.to_rule().unwrap();
+
+        let serialized = serialize_rule_to_file_content(&rule).unwrap();
+
+        let reparsed = crate::file_storage::parser::parse_rule_file(
+            std::path::Path::new("test.md"),
+            &serialized,
+        )
+        .unwrap();
+        let rerule = reparsed.to_rule().unwrap();
+
+        assert_eq!(rule.id, rerule.id);
+        assert_eq!(rule.name, rerule.name);
+        assert_eq!(rule.scope, rerule.scope);
+        assert_eq!(rule.content.trim(), rerule.content.trim());
+    }
+
+    #[test]
+    fn test_format_datetime() {
+        let dt = DateTime::parse_from_rfc3339("2024-01-15T10:30:00Z")
+            .unwrap()
+            .with_timezone(&Utc);
+        let formatted = format_datetime(dt);
+        assert_eq!(formatted, "2024-01-15T10:30:00Z");
+    }
+}
diff --git a/src-tauri/src/file_storage/watcher.rs b/src-tauri/src/file_storage/watcher.rs
new file mode 100644
index 0000000..c8d8568
--- /dev/null
+++ b/src-tauri/src/file_storage/watcher.rs
@@ -0,0 +1,209 @@
+#![allow(dead_code)]
+
+use std::path::PathBuf;
+use std::sync::mpsc::{channel, Receiver, Sender};
+use std::sync::{Arc, Mutex};
+use std::thread;
+use std::time::Duration;
+
+use notify::{Config, Event, RecommendedWatcher, RecursiveMode, Watcher};
+
+use crate::error::{AppError, Result};
+
+pub type FileChangeCallback = Box<dyn Fn(FileChangeEvent) + Send + 'static>;
+
+#[derive(Debug, Clone)]
+pub enum FileChangeEvent {
+    Created(PathBuf),
+    Modified(PathBuf),
+    Deleted(PathBuf),
+}
+
+#[derive(Debug, Clone)]
+pub struct RuleFileWatcher {
+    watcher: Arc<Mutex<Option<RecommendedWatcher>>>,
+    is_running: Arc<Mutex<bool>>,
+    watched_paths: Arc<Mutex<Vec<PathBuf>>>,
+}
+
+impl RuleFileWatcher {
+    pub fn new() -> Self {
+        Self {
+            watcher: Arc::new(Mutex::new(None)),
+            is_running: Arc::new(Mutex::new(false)),
+            watched_paths: Arc::new(Mutex::new(Vec::new())),
+        }
+    }
+
+    pub fn start(&self, path: &std::path::Path, callback: FileChangeCallback) -> Result<()> {
+        let mut is_running = self.is_running.lock().map_err(|_| AppError::LockError)?;
+        if *is_running {
+            return Ok(());
+        }
+
+        let (tx, rx): (
+            Sender<Result<FileChangeEvent>>,
+            Receiver<Result<FileChangeEvent>>,
+        ) = channel();
+
+        let event_callback = callback;
+        let callback_arc = Arc::new(Mutex::new(event_callback));
+
+        let mut watcher = RecommendedWatcher::new(
+            move |res: notify::Result<Event>| {
+                let event = match res {
+                    Ok(e) => e,
+                    Err(e) => {
+                        let _ = tx.send(Err(AppError::InvalidInput {
+                            message: format!("Watch error: {}", e),
+                        }));
+                        return;
+                    }
+                };
+
+                for path in &event.paths {
+                    if path.extension().and_then(|e| e.to_str()) != Some("md") {
+                        continue;
+                    }
+
+                    let file_event = if event.kind.is_create() {
+                        Some(FileChangeEvent::Created(path.clone()))
+                    } else if event.kind.is_modify() {
+                        Some(FileChangeEvent::Modified(path.clone()))
+                    } else if event.kind.is_remove() {
+                        Some(FileChangeEvent::Deleted(path.clone()))
+                    } else {
+                        None
+                    };
+
+                    if let Some(fe) = file_event {
+                        let _ = tx.send(Ok(fe));
+                    }
+                }
+            },
+            Config::default()
+                .with_poll_interval(Duration::from_millis(500))
+                .with_compare_contents(false),
+        )
+        .map_err(|e| AppError::InvalidInput {
+            message: format!("Failed to create file watcher: {}", e),
+        })?;
+
+        watcher
+            .watch(path, RecursiveMode::Recursive)
+            .map_err(|e| AppError::InvalidInput {
+                message: format!("Failed to watch path '{}': {}", path.display(), e),
+            })?;
+
+        {
+            let mut w = self.watcher.lock().map_err(|_| AppError::LockError)?;
+            *w = Some(watcher);
+        }
+
+        {
+            let mut watched = self.watched_paths.lock().map_err(|_| AppError::LockError)?;
+            watched.push(path.to_path_buf());
+        }
+
+        *is_running = true;
+        drop(is_running);
+
+        let is_running_clone = Arc::clone(&self.is_running);
+        let callback_clone = Arc::clone(&callback_arc);
+
+        thread::spawn(move || {
+            while let Ok(event_result) = rx.recv() {
+                let running = is_running_clone.lock().map(|g| *g).unwrap_or(false);
+                if !running {
+                    break;
+                }
+
+                if let Ok(event) = event_result {
+                    if let Ok(cb) = callback_clone.lock() {
+                        cb(event);
+                    }
+                }
+            }
+        });
+
+        Ok(())
+    }
+
+    pub fn stop(&self) -> Result<()> {
+        let mut is_running = self.is_running.lock().map_err(|_| AppError::LockError)?;
+        if !*is_running {
+            return Ok(());
+        }
+
+        let mut watcher_guard = self.watcher.lock().map_err(|_| AppError::LockError)?;
+
+        if let Some(mut watcher) = watcher_guard.take() {
+            let watched = self.watched_paths.lock().map_err(|_| AppError::LockError)?;
+            for path in watched.iter() {
+                let _ = watcher.unwatch(path);
+            }
+        }
+
+        *is_running = false;
+        Ok(())
+    }
+
+    pub fn is_running(&self) -> bool {
+        self.is_running.lock().map(|g| *g).unwrap_or(false)
+    }
+
+    pub fn watched_paths(&self) -> Vec<PathBuf> {
+        self.watched_paths
+            .lock()
+            .map(|g| g.clone())
+            .unwrap_or_default()
+    }
+}
+
+impl Default for RuleFileWatcher {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use std::fs;
+    use std::sync::atomic::{AtomicU32, Ordering};
+    use std::time::Duration;
+
+    #[test]
+    fn test_watcher_creation() {
+        let watcher = RuleFileWatcher::new();
+        assert!(!watcher.is_running());
+        assert!(watcher.watched_paths().is_empty());
+    }
+
+    #[test]
+    fn test_watcher_start_and_stop() {
+        let temp_dir = std::env::temp_dir().join(format!("watcher_test_{}", uuid::Uuid::new_v4()));
+        fs::create_dir_all(&temp_dir).expect("Failed to create temp dir");
+
+        let watcher = RuleFileWatcher::new();
+        let counter = Arc::new(AtomicU32::new(0));
+        let counter_clone = Arc::clone(&counter);
+
+        let callback = Box::new(move |_event: FileChangeEvent| {
+            counter_clone.fetch_add(1, Ordering::SeqCst);
+        });
+
+        let result = watcher.start(&temp_dir, callback);
+        assert!(result.is_ok());
+        assert!(watcher.is_running());
+        assert!(!watcher.watched_paths().is_empty());
+
+        thread::sleep(Duration::from_millis(100));
+
+        let result = watcher.stop();
+        assert!(result.is_ok());
+        assert!(!watcher.is_running());
+
+        let _ = fs::remove_dir_all(&temp_dir);
+    }
+}
diff --git a/src-tauri/src/lib.rs b/src-tauri/src/lib.rs
index 81fe81e..ba03e66 100644
--- a/src-tauri/src/lib.rs
+++ b/src-tauri/src/lib.rs
@@ -1,19 +1,125 @@
 mod commands;
 mod database;
 mod error;
+mod execution;
+mod file_storage;
+mod mcp;
 mod models;
 mod sync;
 
 use database::Database;
+use mcp::McpManager;
+use std::sync::Arc;
+use tauri::menu::{MenuBuilder, MenuItemBuilder};
+use tauri::tray::{MouseButton, MouseButtonState, TrayIconBuilder, TrayIconEvent};
 use tauri::Manager;
 
+const MINIMIZE_TO_TRAY_KEY: &str = "minimize_to_tray";
+
 #[cfg_attr(mobile, tauri::mobile_entry_point)]
 pub fn run() {
+    log::info!("RuleWeaver application initializing");
+    
     tauri::Builder::default()
         .plugin(tauri_plugin_opener::init())
         .setup(|app| {
-            let db = Database::new(app.handle())?;
-            app.manage(db);
+            let db = Arc::new(Database::new(app.handle())?);
+            let mcp_manager = McpManager::new(8080);
+
+            let auto_start_mcp = db
+                .get_setting("mcp_auto_start")
+                .ok()
+                .flatten()
+                .map(|v| v == "true")
+                .unwrap_or(false);
+
+            if auto_start_mcp {
+                let _ = mcp_manager.start(&db);
+            }
+
+            if db.get_setting(MINIMIZE_TO_TRAY_KEY)?.is_none() {
+                db.set_setting(MINIMIZE_TO_TRAY_KEY, "true")?;
+            }
+
+            let show = MenuItemBuilder::with_id("show", "Show RuleWeaver").build(app)?;
+            let hide = MenuItemBuilder::with_id("hide", "Hide to Tray").build(app)?;
+            let quit = MenuItemBuilder::with_id("quit", "Quit RuleWeaver").build(app)?;
+            let tray_menu = MenuBuilder::new(app)
+                .item(&show)
+                .item(&hide)
+                .separator()
+                .item(&quit)
+                .build()?;
+
+            let app_handle = app.handle().clone();
+            TrayIconBuilder::new()
+                .menu(&tray_menu)
+                .on_menu_event(move |app, event| match event.id().as_ref() {
+                    "show" => {
+                        if let Some(window) = app.get_webview_window("main") {
+                            let _ = window.show();
+                            let _ = window.unminimize();
+                            let _ = window.set_focus();
+                        }
+                    }
+                    "hide" => {
+                        if let Some(window) = app.get_webview_window("main") {
+                            let _ = window.hide();
+                        }
+                    }
+                    "quit" => {
+                        if let Some(mcp) = app.try_state::<McpManager>() {
+                            let _ = mcp.stop();
+                        }
+                        app.exit(0);
+                    }
+                    _ => {}
+                })
+                .on_tray_icon_event(move |tray, event| {
+                    if let TrayIconEvent::Click {
+                        button: MouseButton::Left,
+                        button_state: MouseButtonState::Up,
+                        ..
+                    } = event
+                    {
+                        let app = tray.app_handle();
+                        if let Some(window) = app.get_webview_window("main") {
+                            if window.is_visible().unwrap_or(true) {
+                                let _ = window.hide();
+                            } else {
+                                let _ = window.show();
+                                let _ = window.unminimize();
+                                let _ = window.set_focus();
+                            }
+                        }
+                    }
+                })
+                .build(app)?;
+
+            if let Some(window) = app_handle.get_webview_window("main") {
+                let app_for_events = app_handle.clone();
+                window.on_window_event(move |event| {
+                    if let tauri::WindowEvent::CloseRequested { api, .. } = event {
+                        let minimize_to_tray = app_for_events
+                            .try_state::<Database>()
+                            .and_then(|db| db.get_setting(MINIMIZE_TO_TRAY_KEY).ok().flatten())
+                            .map(|v| v == "true")
+                            .unwrap_or(true);
+
+                        if minimize_to_tray {
+                            api.prevent_close();
+                            if let Some(main) = app_for_events.get_webview_window("main") {
+                                let _ = main.hide();
+                            }
+                        } else if let Some(mcp) = app_for_events.try_state::<McpManager>() {
+                            let _ = mcp.stop();
+                        }
+                    }
+                });
+            }
+
+            app.manage(Arc::clone(&db));
+            app.manage(mcp_manager);
             Ok(())
         })
         .invoke_handler(tauri::generate_handler![
@@ -34,7 +140,50 @@ pub fn run() {
             commands::get_setting,
             commands::set_setting,
             commands::get_all_settings,
+            commands::migrate_to_file_storage,
+            commands::rollback_file_migration,
+            commands::verify_file_migration,
+            commands::get_file_migration_progress,
+            commands::get_storage_info,
+            commands::get_storage_mode,
+            commands::get_all_commands,
+            commands::get_command_by_id,
+            commands::create_command,
+            commands::update_command,
+            commands::delete_command,
+            commands::test_command,
+            commands::sync_commands,
+            commands::get_all_skills,
+            commands::get_skill_by_id,
+            commands::create_skill,
+            commands::update_skill,
+            commands::delete_skill,
+            commands::get_mcp_status,
+            commands::start_mcp_server,
+            commands::stop_mcp_server,
+            commands::restart_mcp_server,
+            commands::get_mcp_connection_instructions,
+            commands::get_mcp_logs,
+            commands::get_execution_history,
         ])
         .run(tauri::generate_context!())
         .expect("error while running tauri application");
 }
+
+pub fn run_mcp_cli(port: u16) -> std::result::Result<(), String> {
+    let db = Arc::new(Database::new_for_cli().map_err(|e| e.to_string())?);
+    let manager = McpManager::new(port);
+    manager.start(&db).map_err(|e| e.to_string())?;
+
+    let rt = tokio::runtime::Runtime::new().map_err(|e| e.to_string())?;
+    rt.block_on(async {
+        loop {
+            tokio::time::sleep(std::time::Duration::from_secs(1)).await;
+            let status = manager.status().map_err(|e| e.to_string())?;
+            if !status.running {
+                break;
+            }
+        }
+        Ok(())
+    })
+}
diff --git a/src-tauri/src/main.rs b/src-tauri/src/main.rs
index f33d856..657f2eb 100644
--- a/src-tauri/src/main.rs
+++ b/src-tauri/src/main.rs
@@ -1,5 +1,7 @@
 #![cfg_attr(not(debug_assertions), windows_subsystem = "windows")]
 
 fn main() {
+    env_logger::init();
+    log::info!("RuleWeaver GUI starting up");
     ruleweaver_lib::run()
 }
diff --git a/src-tauri/src/mcp/mod.rs b/src-tauri/src/mcp/mod.rs
new file mode 100644
index 0000000..1fbbd82
--- /dev/null
+++ b/src-tauri/src/mcp/mod.rs
@@ -0,0 +1,687 @@
+use axum::{
+    extract::{State},
+    routing::post,
+    Json, Router,
+};
+use std::sync::{Arc, Mutex};
+use std::time::{Duration, Instant};
+use tower_http::cors::CorsLayer;
+
+use regex::Regex;
+use serde::{Deserialize, Serialize};
+use serde_json::json;
+use tokio::sync::broadcast;
+
+use crate::database::{Database, ExecutionLogInput};
+use crate::error::{AppError, Result};
+use crate::execution::{
+    argument_env_var_name, contains_disallowed_pattern, execute_shell_with_timeout,
+    execute_shell_with_timeout_env, replace_template_with_env_ref, sanitize_argument_value,
+    slugify,
+};
+use crate::models::{Command, Skill};
+
+const MAX_SKILL_STEPS: usize = 10;
+const MAX_STEP_LENGTH: usize = 4000;
+const CMD_EXEC_TIMEOUT_SECS: u64 = 60;
+const SKILL_EXEC_TIMEOUT_SECS: u64 = 60;
+const MCP_RATE_LIMIT_WINDOW_SECS: u64 = 10;
+const MCP_RATE_LIMIT_MAX_CALLS: usize = 30;
+
+#[derive(Debug, Clone, Serialize)]
+pub struct McpStatus {
+    pub running: bool,
+    pub port: u16,
+    pub uptime_seconds: u64,
+}
+
+#[derive(Debug, Clone, Serialize)]
+pub struct McpConnectionInstructions {
+    pub claude_code_json: String,
+    pub opencode_json: String,
+    pub standalone_command: String,
+}
+
+#[derive(Debug)]
+struct McpRuntime {
+    running: bool,
+    port: u16,
+    started_at: Option<Instant>,
+    logs: Vec<String>,
+    stop_tx: Option<broadcast::Sender<()>>,
+    commands: Vec<Command>,
+    skills: Vec<Skill>,
+    invocation_timestamps: Vec<Instant>,
+    db: Option<Arc<Database>>,
+}
+
+#[derive(Clone, Debug)]
+pub struct McpManager {
+    inner: Arc<Mutex<McpRuntime>>,
+}
+
+pub struct McpSnapshot {
+    pub commands: Vec<Command>,
+    pub skills: Vec<Skill>,
+    pub db: Option<Arc<Database>>,
+}
+
+impl McpManager {
+    pub fn new(port: u16) -> Self {
+        Self {
+            inner: Arc::new(Mutex::new(McpRuntime {
+                running: false,
+                port,
+                started_at: None,
+                logs: Vec::new(),
+                stop_tx: None,
+                commands: Vec::new(),
+                skills: Vec::new(),
+                invocation_timestamps: Vec::new(),
+                db: None,
+            })),
+        }
+    }
+
+    pub fn refresh_commands(&self, db: &Database) -> Result<()> {
+        let commands = db.get_all_commands()?;
+        let skills = db.get_all_skills()?;
+        let mut state = self.inner.lock().map_err(|_| AppError::LockError)?;
+        state.commands = commands;
+        state.skills = skills;
+        Ok(())
+    }
+
+    fn snapshot(&self) -> Result<McpSnapshot> {
+        let state = self.inner.lock().map_err(|_| AppError::LockError)?;
+        Ok(McpSnapshot {
+            commands: state.commands.clone(),
+            skills: state.skills.clone(),
+            db: state.db.clone(),
+        })
+    }
+
+    pub fn start(&self, db: &Arc<Database>) -> Result<()> {
+        self.refresh_commands(db)?;
+
+        let port = {
+            let mut state = self.inner.lock().map_err(|_| AppError::LockError)?;
+            if state.running {
+                return Ok(());
+            }
+            state.running = true;
+            state.started_at = Some(Instant::now());
+            state.logs.push("Starting MCP server".to_string());
+            state.db = Some(Arc::clone(db));
+            state.port
+        };
+
+        let (stop_tx, _) = broadcast::channel(1);
+        {
+            let mut state = self.inner.lock().map_err(|_| AppError::LockError)?;
+            state.stop_tx = Some(stop_tx.clone());
+        }
+
+        let manager = self.clone();
+        let mut stop_rx = stop_tx.subscribe();
+        tokio::spawn(async move {
+            let app = Router::new()
+                .route("/", post(mcp_handler))
+                // Support root and any other path for flexibility
+                .fallback(post(mcp_handler))
+                .layer(CorsLayer::permissive())
+                .with_state(manager.clone());
+
+            let addr = format!("127.0.0.1:{}", port);
+            let listener = match tokio::net::TcpListener::bind(&addr).await {
+                Ok(l) => l,
+                Err(e) => {
+                    let _ = manager.log(format!("Failed to bind MCP server {}: {}", addr, e));
+                    let _ = manager.mark_stopped();
+                    return;
+                }
+            };
+
+            let _ = manager.log(format!("MCP server listening on {}", addr));
+
+            if let Err(e) = axum::serve(listener, app)
+                .with_graceful_shutdown(async move {
+                    let _ = stop_rx.recv().await;
+                })
+                .await
+            {
+                let _ = manager.log(format!("MCP server error: {}", e));
+            }
+
+            let _ = manager.log("MCP server stopped".to_string());
+            let _ = manager.mark_stopped();
+        });
+
+        Ok(())
+    }
+
+    pub fn stop(&self) -> Result<()> {
+        let tx = {
+            let mut state = self.inner.lock().map_err(|_| AppError::LockError)?;
+            if !state.running {
+                return Ok(());
+            }
+            state.stop_tx.take()
+        };
+
+        if let Some(tx) = tx {
+            let _ = tx.send(());
+        }
+
+        Ok(())
+    }
+
+    pub fn status(&self) -> Result<McpStatus> {
+        let state = self.inner.lock().map_err(|_| AppError::LockError)?;
+        let uptime_seconds = state.started_at.map(|t| t.elapsed().as_secs()).unwrap_or(0);
+        Ok(McpStatus {
+            running: state.running,
+            port: state.port,
+            uptime_seconds,
+        })
+    }
+
+    pub fn logs(&self, limit: usize) -> Result<Vec<String>> {
+        let state = self.inner.lock().map_err(|_| AppError::LockError)?;
+        let len = state.logs.len();
+        let start = len.saturating_sub(limit);
+        Ok(state.logs[start..].to_vec())
+    }
+
+    pub fn instructions(&self) -> Result<McpConnectionInstructions> {
+        let status = self.status()?;
+        let port = status.port;
+
+        let claude_code_json = serde_json::to_string_pretty(&json!({
+            "mcpServers": {
+                "ruleweaver": {
+                    "url": format!("http://127.0.0.1:{}", port)
+                }
+            }
+        }))
+        .map_err(AppError::Serialization)?;
+
+        let opencode_json = serde_json::to_string_pretty(&json!({
+            "mcp": {
+                "servers": [
+                    {
+                        "name": "ruleweaver",
+                        "url": format!("http://127.0.0.1:{}", port)
+                    }
+                ]
+            }
+        }))
+        .map_err(AppError::Serialization)?;
+
+        Ok(McpConnectionInstructions {
+            claude_code_json,
+            opencode_json,
+            standalone_command: format!("ruleweaver-mcp --port {}", port),
+        })
+    }
+
+    fn log(&self, message: String) -> Result<()> {
+        let mut state = self.inner.lock().map_err(|_| AppError::LockError)?;
+        state.logs.push(message);
+        if state.logs.len() > 500 {
+            let drain_to = state.logs.len() - 500;
+            state.logs.drain(0..drain_to);
+        }
+        Ok(())
+    }
+
+    fn mark_stopped(&self) -> Result<()> {
+        let mut state = self.inner.lock().map_err(|_| AppError::LockError)?;
+        state.running = false;
+        state.stop_tx = None;
+        state.started_at = None;
+        Ok(())
+    }
+
+    fn allow_invocation(&self) -> Result<bool> {
+        let mut state = self.inner.lock().map_err(|_| AppError::LockError)?;
+        let cutoff = Instant::now() - Duration::from_secs(MCP_RATE_LIMIT_WINDOW_SECS);
+        state.invocation_timestamps.retain(|t| *t >= cutoff);
+
+        if state.invocation_timestamps.len() >= MCP_RATE_LIMIT_MAX_CALLS {
+            return Ok(false);
+        }
+
+        state.invocation_timestamps.push(Instant::now());
+        Ok(true)
+    }
+}
+
+#[derive(Debug, Deserialize)]
+struct JsonRpcRequest {
+    id: serde_json::Value,
+    method: String,
+    params: Option<serde_json::Value>,
+}
+
+async fn mcp_handler(
+    State(manager): State<McpManager>,
+    Json(request): Json<JsonRpcRequest>,
+) -> Json<serde_json::Value> {
+    let McpSnapshot {
+        commands,
+        skills,
+        db: shared_db,
+    } = match manager.snapshot() {
+        Ok(s) => s,
+        Err(e) => {
+            return Json(json!({
+                "jsonrpc": "2.0",
+                "id": request.id,
+                "error": {
+                    "code": -32603,
+                    "message": format!("Internal server error: {}", e)
+                }
+            }));
+        }
+    };
+
+    let response = match request.method.as_str() {
+        "initialize" => json!({
+            "jsonrpc": "2.0",
+            "id": request.id,
+            "result": {
+                "serverInfo": {
+                    "name": "RuleWeaver MCP",
+                    "version": "0.1.0"
+                }
+            }
+        }),
+        "tools/list" => {
+            let tools: Vec<serde_json::Value> = commands
+                .iter()
+                .filter(|c| c.expose_via_mcp)
+                .map(|c| {
+                    let mut props = serde_json::Map::new();
+                    let mut required: Vec<String> = Vec::new();
+
+                    for arg in &c.arguments {
+                        props.insert(
+                            arg.name.clone(),
+                            json!({
+                                "type": "string",
+                                "description": arg.description,
+                            }),
+                        );
+                        if arg.required {
+                            required.push(arg.name.clone());
+                        }
+                    }
+
+                    json!({
+                        "name": c.name,
+                        "description": c.description,
+                        "inputSchema": {
+                            "type": "object",
+                            "properties": props,
+                            "required": required,
+                        }
+                    })
+                })
+                .collect();
+
+            let skill_tools: Vec<serde_json::Value> = skills
+                .iter()
+                .filter(|s| s.enabled)
+                .map(|s| {
+                    json!({
+                        "name": format!("skill_{}", slugify(&s.name)),
+                        "description": s.description,
+                        "inputSchema": {
+                            "type": "object",
+                            "properties": {
+                                "input": {
+                                    "type": "string",
+                                    "description": "Optional free-form input for the skill"
+                                }
+                            },
+                            "required": []
+                        }
+                    })
+                })
+                .collect();
+
+            let mut all_tools = tools;
+            all_tools.extend(skill_tools);
+
+            json!({
+                "jsonrpc": "2.0",
+                "id": request.id,
+                "result": { "tools": all_tools }
+            })
+        }
+        "tools/call" => {
+            let allow = match manager.allow_invocation() {
+                Ok(a) => a,
+                Err(e) => {
+                    return Json(json!({
+                        "jsonrpc": "2.0",
+                        "id": request.id,
+                        "error": {
+                            "code": -32603,
+                            "message": format!("Internal server error: {}", e)
+                        }
+                    }));
+                }
+            };
+
+            if !allow {
+                json!({
+                    "jsonrpc": "2.0",
+                    "id": request.id,
+                    "error": {
+                        "code": -32029,
+                        "message": "Rate limit exceeded. Please retry shortly."
+                    }
+                })
+            } else {
+                let params = request.params.unwrap_or_else(|| json!({}));
+                let name = params
+                    .get("name")
+                    .and_then(|v| v.as_str())
+                    .unwrap_or_default()
+                    .to_string();
+
+                let args_map = params
+                    .get("arguments")
+                    .and_then(|v| v.as_object())
+                    .cloned()
+                    .unwrap_or_default();
+
+                if let Some(cmd) = commands.iter().find(|c| c.name == name && c.expose_via_mcp) {
+                    let missing_required: Vec<String> = cmd
+                        .arguments
+                        .iter()
+                        .filter(|arg| {
+                            arg.required
+                                && !args_map.contains_key(&arg.name)
+                                && arg
+                                    .default_value
+                                    .as_ref()
+                                    .map(|v| v.is_empty())
+                                    .unwrap_or(true)
+                        })
+                        .map(|arg| arg.name.clone())
+                        .collect();
+
+                    if !missing_required.is_empty() {
+                        json!({
+                            "jsonrpc": "2.0",
+                            "id": request.id,
+                            "error": {
+                                "code": -32602,
+                                "message": format!("Missing required arguments: {}", missing_required.join(", "))
+                            }
+                        })
+                    } else {
+                        let mut rendered = cmd.script.clone();
+                        let mut envs: Vec<(String, String)> = Vec::new();
+                        let mut invalid_arg_message: Option<String> = None;
+
+                        for arg in &cmd.arguments {
+                            rendered = replace_template_with_env_ref(&rendered, &arg.name);
+
+                            let raw_value = args_map
+                                .get(&arg.name)
+                                .map(|v| {
+                                    if let Some(s) = v.as_str() {
+                                        s.to_string()
+                                    } else {
+                                        v.to_string()
+                                    }
+                                })
+                                .or_else(|| arg.default_value.clone())
+                                .unwrap_or_default();
+
+                            match sanitize_argument_value(&raw_value) {
+                                Ok(safe_value) => {
+                                    envs.push((argument_env_var_name(&arg.name), safe_value));
+                                }
+                                Err(e) => {
+                                    invalid_arg_message = Some(e.to_string());
+                                    break;
+                                }
+                            }
+                        }
+
+                        if let Some(message) = invalid_arg_message {
+                            json!({
+                                "jsonrpc": "2.0",
+                                "id": request.id,
+                                "error": {
+                                    "code": -32602,
+                                    "message": format!("Invalid argument value: {}", message)
+                                }
+                            })
+                        } else {
+                            match execute_shell_with_timeout_env(
+                                &rendered,
+                                Duration::from_secs(CMD_EXEC_TIMEOUT_SECS),
+                                &envs,
+                            )
+                            .await
+                            {
+                                Ok((exit_code, stdout, stderr)) => {
+                                    let _ = manager.log(format!(
+                                        "MCP tools/call '{}' exit code {}",
+                                        cmd.name, exit_code
+                                    ));
+                                    if let Some(db) = &shared_db {
+                                        let args_json =
+                                            serde_json::to_string(&args_map).unwrap_or_default();
+                                        let _ = db.add_execution_log(&ExecutionLogInput {
+                                            command_id: &cmd.id,
+                                            command_name: &cmd.name,
+                                            arguments_json: &args_json,
+                                            stdout: &stdout,
+                                            stderr: &stderr,
+                                            exit_code,
+                                            duration_ms: 0,
+                                            triggered_by: "mcp",
+                                        });
+                                    }
+                                    json!({
+                                        "jsonrpc": "2.0",
+                                        "id": request.id,
+                                        "result": {
+                                            "content": [{
+                                                "type": "text",
+                                                "text": format!("exit_code: {}\n\nstdout:\n{}\n\nstderr:\n{}", exit_code, stdout, stderr)
+                                            }],
+                                            "is_error": exit_code != 0
+                                        }
+                                    })
+                                }
+                                Err(e) => json!({
+                                    "jsonrpc": "2.0",
+                                    "id": request.id,
+                                    "error": {
+                                        "code": -32000,
+                                        "message": format!("Failed to execute command: {}", e)
+                                    }
+                                }),
+                            }
+                        }
+                    }
+                } else if let Some(skill) = skills
+                    .iter()
+                    .find(|s| s.enabled && format!("skill_{}", slugify(&s.name)) == name)
+                {
+                    let input = args_map
+                        .get("input")
+                        .and_then(|v| v.as_str())
+                        .unwrap_or_default()
+                        .to_string();
+
+                    let rendered = skill.instructions.replace("{{input}}", &input);
+                    let steps = extract_skill_steps(&rendered);
+
+                    if steps.is_empty() {
+                        json!({
+                            "jsonrpc": "2.0",
+                            "id": request.id,
+                            "result": {
+                                "content": [{
+                                    "type": "text",
+                                    "text": rendered
+                                }],
+                                "is_error": false
+                            }
+                        })
+                    } else {
+                        let mut output = String::new();
+                        let mut is_error = false;
+
+                        for (idx, step) in steps.iter().take(MAX_SKILL_STEPS).enumerate() {
+                            if step.len() > MAX_STEP_LENGTH {
+                                is_error = true;
+                                output.push_str(&format!("Step {} rejected: too long\n", idx + 1));
+                                break;
+                            }
+
+                            if let Some(pattern) = contains_disallowed_pattern(step) {
+                                is_error = true;
+                                output.push_str(&format!(
+                                    "Step {} rejected due to unsafe pattern: {}\n",
+                                    idx + 1,
+                                    pattern
+                                ));
+                                break;
+                            }
+
+                            match execute_shell_with_timeout(
+                                step,
+                                Duration::from_secs(SKILL_EXEC_TIMEOUT_SECS),
+                            )
+                            .await
+                            {
+                                Ok((exit_code, stdout, stderr)) => {
+                                    output.push_str(&format!(
+                                        "[step {}] exit_code: {}\nstdout:\n{}\nstderr:\n{}\n\n",
+                                        idx + 1,
+                                        exit_code,
+                                        stdout,
+                                        stderr
+                                    ));
+                                    if exit_code != 0 {
+                                        is_error = true;
+                                        break;
+                                    }
+                                }
+                                Err(e) => {
+                                    is_error = true;
+                                    output.push_str(&format!(
+                                        "[step {}] execution error: {}\n",
+                                        idx + 1,
+                                        e
+                                    ));
+                                    break;
+                                }
+                            }
+                        }
+
+                        let _ = manager.log(format!(
+                            "MCP tools/call '{}' skill execution {}",
+                            skill.name,
+                            if is_error { "failed" } else { "succeeded" }
+                        ));
+
+                        if let Some(db) = &shared_db {
+                            let args_json = serde_json::to_string(&args_map).unwrap_or_default();
+                            let skill_name = format!("skill:{}", skill.name);
+                            let _ = db.add_execution_log(&ExecutionLogInput {
+                                command_id: &skill.id,
+                                command_name: &skill_name,
+                                arguments_json: &args_json,
+                                stdout: &output,
+                                stderr: "",
+                                exit_code: if is_error { 1 } else { 0 },
+                                duration_ms: 0,
+                                triggered_by: "mcp-skill",
+                            });
+                        }
+
+                        json!({
+                            "jsonrpc": "2.0",
+                            "id": request.id,
+                            "result": {
+                                "content": [{
+                                    "type": "text",
+                                    "text": output
+                                }],
+                                "is_error": is_error
+                            }
+                        })
+                    }
+                } else {
+                    json!({
+                        "jsonrpc": "2.0",
+                        "id": request.id,
+                        "error": {
+                            "code": -32602,
+                            "message": format!("Unknown or disabled tool: {}", name)
+                        }
+                    })
+                }
+            }
+        }
+        _ => json!({
+            "jsonrpc": "2.0",
+            "id": request.id,
+            "error": {
+                "code": -32601,
+                "message": format!("Method not found: {}", request.method)
+            }
+        }),
+    };
+
+    Json(response)
+}
+
+fn extract_skill_steps(instructions: &str) -> Vec<String> {
+    static RE: std::sync::OnceLock<Regex> = std::sync::OnceLock::new();
+    let re = RE.get_or_init(|| {
+        Regex::new(r"(?s)```(?:bash|sh|shell|powershell|pwsh|cmd)?\n(.*?)```")
+            .expect("Invalid skill steps regex")
+    });
+
+    re.captures_iter(instructions)
+        .filter_map(|caps| caps.get(1).map(|m| m.as_str().trim().to_string()))
+        .filter(|s| !s.is_empty())
+        .collect()
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn test_slugify() {
+        assert_eq!(slugify("My Skill"), "my-skill");
+        assert_eq!(slugify("Skill__Name"), "skill-name");
+    }
+
+    #[test]
+    fn test_extract_skill_steps() {
+        let text = "before\n```bash\necho one\n```\nmid\n```sh\necho two\n```";
+        let steps = extract_skill_steps(text);
+        assert_eq!(steps.len(), 2);
+        assert!(steps[0].contains("echo one"));
+    }
+
+    #[test]
+    fn test_disallowed_patterns() {
+        assert!(contains_disallowed_pattern("rm -rf /").is_some());
+        assert!(contains_disallowed_pattern("echo hi").is_none());
+    }
+}
diff --git a/src-tauri/src/models/command.rs b/src-tauri/src/models/command.rs
new file mode 100644
index 0000000..2d6dc1a
--- /dev/null
+++ b/src-tauri/src/models/command.rs
@@ -0,0 +1,152 @@
+use chrono::{DateTime, Utc};
+use serde::{Deserialize, Serialize};
+use uuid::Uuid;
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct Command {
+    pub id: String,
+    pub name: String,
+    pub description: String,
+    pub script: String,
+    pub arguments: Vec<CommandArgument>,
+    pub expose_via_mcp: bool,
+    #[serde(with = "ts_seconds")]
+    pub created_at: DateTime<Utc>,
+    #[serde(with = "ts_seconds")]
+    pub updated_at: DateTime<Utc>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct CommandArgument {
+    pub name: String,
+    pub description: String,
+    pub required: bool,
+    pub default_value: Option<String>,
+}
+
+mod ts_seconds {
+    use chrono::{DateTime, TimeZone, Utc};
+    use serde::{self, Deserialize, Deserializer, Serialize, Serializer};
+
+    pub fn serialize<S>(date: &DateTime<Utc>, serializer: S) -> Result<S::Ok, S::Error>
+    where
+        S: Serializer,
+    {
+        date.timestamp().serialize(serializer)
+    }
+
+    pub fn deserialize<'de, D>(deserializer: D) -> Result<DateTime<Utc>, D::Error>
+    where
+        D: Deserializer<'de>,
+    {
+        let ts = i64::deserialize(deserializer)?;
+        Utc.timestamp_opt(ts, 0)
+            .single()
+            .ok_or_else(|| serde::de::Error::custom(format!("Invalid timestamp: {}", ts)))
+    }
+}
+
+impl Command {
+    #[allow(dead_code)]
+    pub fn new(name: String, description: String, script: String) -> Self {
+        let now = Utc::now();
+        Self {
+            id: Uuid::new_v4().to_string(),
+            name,
+            description,
+            script,
+            arguments: Vec::new(),
+            expose_via_mcp: true,
+            created_at: now,
+            updated_at: now,
+        }
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct CreateCommandInput {
+    pub name: String,
+    pub description: String,
+    pub script: String,
+    #[serde(default)]
+    pub arguments: Vec<CommandArgument>,
+    #[serde(default = "default_true")]
+    pub expose_via_mcp: bool,
+}
+
+fn default_true() -> bool {
+    true
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, Default)]
+pub struct UpdateCommandInput {
+    pub name: Option<String>,
+    pub description: Option<String>,
+    pub script: Option<String>,
+    pub arguments: Option<Vec<CommandArgument>>,
+    pub expose_via_mcp: Option<bool>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct TestCommandResult {
+    pub success: bool,
+    pub stdout: String,
+    pub stderr: String,
+    pub exit_code: i32,
+    pub duration_ms: u64,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct ExecutionLog {
+    pub id: String,
+    pub command_id: String,
+    pub command_name: String,
+    pub arguments: String,
+    pub stdout: String,
+    pub stderr: String,
+    pub exit_code: i32,
+    pub duration_ms: u64,
+    #[serde(with = "ts_seconds")]
+    pub executed_at: DateTime<Utc>,
+    pub triggered_by: String,
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+
+    #[test]
+    fn test_new_command_defaults() {
+        let command = Command::new(
+            "Fmt".to_string(),
+            "Format".to_string(),
+            "npm run fmt".to_string(),
+        );
+        assert_eq!(command.name, "Fmt");
+        assert!(command.expose_via_mcp);
+        assert!(command.arguments.is_empty());
+        assert!(!command.id.is_empty());
+    }
+
+    #[test]
+    fn test_command_roundtrip() {
+        let input = CreateCommandInput {
+            name: "Run Tests".to_string(),
+            description: "Run unit tests".to_string(),
+            script: "npm test".to_string(),
+            arguments: vec![CommandArgument {
+                name: "path".to_string(),
+                description: "Test path".to_string(),
+                required: false,
+                default_value: None,
+            }],
+            expose_via_mcp: true,
+        };
+
+        let json = serde_json::to_string(&input).expect("serialize create input");
+        let parsed: CreateCommandInput =
+            serde_json::from_str(&json).expect("deserialize create input");
+        assert_eq!(parsed.name, input.name);
+        assert_eq!(parsed.arguments.len(), 1);
+    }
+}
diff --git a/src-tauri/src/models/mod.rs b/src-tauri/src/models/mod.rs
index 1cb21b7..e20831e 100644
--- a/src-tauri/src/models/mod.rs
+++ b/src-tauri/src/models/mod.rs
@@ -1,3 +1,7 @@
+mod command;
 mod rule;
+mod skill;
 
+pub use command::*;
 pub use rule::*;
+pub use skill::*;
diff --git a/src-tauri/src/models/skill.rs b/src-tauri/src/models/skill.rs
new file mode 100644
index 0000000..6da9f1f
--- /dev/null
+++ b/src-tauri/src/models/skill.rs
@@ -0,0 +1,87 @@
+use chrono::{DateTime, Utc};
+use serde::{Deserialize, Serialize};
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct Skill {
+    pub id: String,
+    pub name: String,
+    pub description: String,
+    pub instructions: String,
+    #[serde(default)]
+    pub input_schema: Vec<SkillParameter>,
+    pub enabled: bool,
+    #[serde(with = "ts_seconds")]
+    pub created_at: DateTime<Utc>,
+    #[serde(with = "ts_seconds")]
+    pub updated_at: DateTime<Utc>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct SkillParameter {
+    pub name: String,
+    pub description: String,
+    #[serde(default = "default_skill_param_type")]
+    pub param_type: SkillParameterType,
+    #[serde(default)]
+    pub required: bool,
+    #[serde(default)]
+    pub default_value: Option<String>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
+#[serde(rename_all = "lowercase")]
+pub enum SkillParameterType {
+    String,
+    Number,
+    Boolean,
+}
+
+fn default_skill_param_type() -> SkillParameterType {
+    SkillParameterType::String
+}
+
+mod ts_seconds {
+    use chrono::{DateTime, TimeZone, Utc};
+    use serde::{self, Deserialize, Deserializer, Serialize, Serializer};
+
+    pub fn serialize<S>(date: &DateTime<Utc>, serializer: S) -> Result<S::Ok, S::Error>
+    where
+        S: Serializer,
+    {
+        date.timestamp().serialize(serializer)
+    }
+
+    pub fn deserialize<'de, D>(deserializer: D) -> Result<DateTime<Utc>, D::Error>
+    where
+        D: Deserializer<'de>,
+    {
+        let ts = i64::deserialize(deserializer)?;
+        Utc.timestamp_opt(ts, 0)
+            .single()
+            .ok_or_else(|| serde::de::Error::custom(format!("Invalid timestamp: {}", ts)))
+    }
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct CreateSkillInput {
+    pub name: String,
+    pub description: String,
+    pub instructions: String,
+    #[serde(default)]
+    pub input_schema: Vec<SkillParameter>,
+    #[serde(default = "default_true")]
+    pub enabled: bool,
+}
+
+fn default_true() -> bool {
+    true
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize, Default)]
+pub struct UpdateSkillInput {
+    pub name: Option<String>,
+    pub description: Option<String>,
+    pub instructions: Option<String>,
+    pub input_schema: Option<Vec<SkillParameter>>,
+    pub enabled: Option<bool>,
+}
diff --git a/src/App.tsx b/src/App.tsx
index 5320c86..645714c 100644
--- a/src/App.tsx
+++ b/src/App.tsx
@@ -2,6 +2,8 @@ import { useState } from "react";
 import { MainLayout } from "./components/layout/MainLayout";
 import { Dashboard } from "./components/pages/Dashboard";
 import { RulesPage } from "./components/pages/RulesPage";
+import { Commands } from "./components/pages/Commands";
+import { Skills } from "./components/pages/Skills";
 import { Settings } from "./components/pages/Settings";
 import { ToastProvider } from "./components/ui/toast";
 import { ErrorBoundary } from "./components/ui/error-boundary";
@@ -23,6 +25,26 @@ function App() {
         ...SHORTCUTS.SETTINGS,
         action: () => setActiveView("settings"),
       },
+      {
+        ...SHORTCUTS.NEW_COMMAND,
+        action: () => setActiveView("commands"),
+      },
+      {
+        ...SHORTCUTS.DASHBOARD,
+        action: () => setActiveView("dashboard"),
+      },
+      {
+        ...SHORTCUTS.RULES,
+        action: () => setActiveView("rules"),
+      },
+      {
+        ...SHORTCUTS.COMMANDS,
+        action: () => setActiveView("commands"),
+      },
+      {
+        ...SHORTCUTS.SKILLS,
+        action: () => setActiveView("skills"),
+      },
       {
         ...SHORTCUTS.HELP,
         action: () => setShortcutsDialogOpen(true),
@@ -36,6 +58,10 @@ function App() {
         return <Dashboard onNavigate={setActiveView} />;
       case "rules":
         return <RulesPage />;
+      case "commands":
+        return <Commands />;
+      case "skills":
+        return <Skills />;
       case "settings":
         return <Settings />;
       default:
diff --git a/src/components/layout/Sidebar.tsx b/src/components/layout/Sidebar.tsx
index bf87278..6d862c5 100644
--- a/src/components/layout/Sidebar.tsx
+++ b/src/components/layout/Sidebar.tsx
@@ -1,5 +1,13 @@
 import { cn } from "@/lib/utils";
-import { LayoutDashboard, FileText, Settings, ChevronLeft, ChevronRight } from "lucide-react";
+import {
+  LayoutDashboard,
+  FileText,
+  Settings,
+  ChevronLeft,
+  ChevronRight,
+  Terminal,
+  Brain,
+} from "lucide-react";
 
 interface SidebarProps {
   collapsed: boolean;
@@ -11,6 +19,8 @@ interface SidebarProps {
 const navItems = [
   { id: "dashboard", label: "Dashboard", icon: LayoutDashboard },
   { id: "rules", label: "Rules", icon: FileText },
+  { id: "commands", label: "Commands", icon: Terminal },
+  { id: "skills", label: "Skills", icon: Brain },
   { id: "settings", label: "Settings", icon: Settings },
 ];
 
diff --git a/src/components/pages/Commands.tsx b/src/components/pages/Commands.tsx
new file mode 100644
index 0000000..5cd723c
--- /dev/null
+++ b/src/components/pages/Commands.tsx
@@ -0,0 +1,389 @@
+import { useEffect, useMemo, useState } from "react";
+import { Plus, Play, Trash2 } from "lucide-react";
+import { Button } from "@/components/ui/button";
+import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
+import { Input } from "@/components/ui/input";
+import { Switch } from "@/components/ui/switch";
+import { Badge } from "@/components/ui/badge";
+import { api } from "@/lib/tauri";
+import { useToast } from "@/components/ui/toast";
+import type { CommandModel, ExecutionLog } from "@/types/command";
+
+export function Commands() {
+  const [commands, setCommands] = useState<CommandModel[]>([]);
+  const [selectedId, setSelectedId] = useState<string>("");
+  const [name, setName] = useState("");
+  const [description, setDescription] = useState("");
+  const [script, setScript] = useState("");
+  const [exposeViaMcp, setExposeViaMcp] = useState(true);
+  const [isSaving, setIsSaving] = useState(false);
+  const [isTesting, setIsTesting] = useState(false);
+  const [testArgs, setTestArgs] = useState<Record<string, string>>({});
+  const [testOutput, setTestOutput] = useState<{
+    stdout: string;
+    stderr: string;
+    exitCode: number;
+  } | null>(null);
+  const [query, setQuery] = useState("");
+  const [history, setHistory] = useState<ExecutionLog[]>([]);
+  const [isSyncing, setIsSyncing] = useState(false);
+  const { addToast } = useToast();
+
+  const selected = useMemo(
+    () => commands.find((cmd) => cmd.id === selectedId) ?? null,
+    [commands, selectedId]
+  );
+
+  const filtered = useMemo(
+    () =>
+      commands.filter((cmd) => {
+        const q = query.toLowerCase().trim();
+        if (!q) return true;
+        return cmd.name.toLowerCase().includes(q) || cmd.description.toLowerCase().includes(q);
+      }),
+    [commands, query]
+  );
+
+  const loadCommands = async () => {
+    const result = await api.commands.getAll();
+    setCommands(result);
+  };
+
+  const loadHistory = async () => {
+    const logs = await api.execution.getHistory(50);
+    setHistory(logs);
+  };
+
+  useEffect(() => {
+    Promise.all([loadCommands(), loadHistory()]).catch((error) => {
+      addToast({
+        title: "Failed to Load Commands",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    });
+  }, [addToast]);
+
+  useEffect(() => {
+    if (!selected) {
+      setName("");
+      setDescription("");
+      setScript("");
+      setExposeViaMcp(true);
+      return;
+    }
+
+    setName(selected.name);
+    setDescription(selected.description);
+    setScript(selected.script);
+    setExposeViaMcp(Boolean(selected.expose_via_mcp));
+    const nextArgs: Record<string, string> = {};
+    for (const arg of selected.arguments) {
+      nextArgs[arg.name] = arg.default_value ?? "";
+    }
+    setTestArgs(nextArgs);
+  }, [selected]);
+
+  const handleCreate = async () => {
+    setIsSaving(true);
+    try {
+      const created = await api.commands.create({
+        name: "New Command",
+        description: "Describe what this command does",
+        script: "echo hello",
+        arguments: [],
+        expose_via_mcp: true,
+      });
+      await loadCommands();
+      setSelectedId(created.id);
+      addToast({ title: "Command Created", description: created.name, variant: "success" });
+    } catch (error) {
+      addToast({
+        title: "Create Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    } finally {
+      setIsSaving(false);
+    }
+  };
+
+  const handleSave = async () => {
+    if (!selected) return;
+    setIsSaving(true);
+    try {
+      const updated = await api.commands.update(selected.id, {
+        name,
+        description,
+        script,
+        expose_via_mcp: exposeViaMcp,
+      });
+      setCommands((prev) => prev.map((c) => (c.id === updated.id ? updated : c)));
+      addToast({ title: "Command Saved", description: updated.name, variant: "success" });
+    } catch (error) {
+      addToast({
+        title: "Save Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    } finally {
+      setIsSaving(false);
+    }
+  };
+
+  const handleDelete = async () => {
+    if (!selected) return;
+    setIsSaving(true);
+    try {
+      await api.commands.delete(selected.id);
+      setCommands((prev) => prev.filter((c) => c.id !== selected.id));
+      setSelectedId("");
+      addToast({ title: "Command Deleted", description: selected.name, variant: "success" });
+    } catch (error) {
+      addToast({
+        title: "Delete Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    } finally {
+      setIsSaving(false);
+    }
+  };
+
+  const handleTest = async () => {
+    if (!selected) return;
+    setIsTesting(true);
+    try {
+      const payload: Record<string, string> = {};
+      for (const arg of selected.arguments) {
+        payload[arg.name] = testArgs[arg.name] ?? "";
+      }
+
+      const result = await api.commands.test(selected.id, payload);
+      setTestOutput({
+        stdout: result.stdout,
+        stderr: result.stderr,
+        exitCode: result.exit_code,
+      });
+      await loadHistory();
+      addToast({
+        title: "Test Completed",
+        description: result.success ? "Command succeeded" : "Command failed",
+        variant: result.success ? "success" : "error",
+      });
+    } catch (error) {
+      addToast({
+        title: "Test Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    } finally {
+      setIsTesting(false);
+    }
+  };
+
+  const handleSyncCommands = async () => {
+    setIsSyncing(true);
+    try {
+      const result = await api.commands.sync();
+      if (!result.success) {
+        throw new Error(result.errors[0]?.message ?? "Failed to sync commands");
+      }
+      addToast({
+        title: "Commands Synced",
+        description: `Wrote ${result.filesWritten.length} command files`,
+        variant: "success",
+      });
+    } catch (error) {
+      addToast({
+        title: "Sync Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    } finally {
+      setIsSyncing(false);
+    }
+  };
+
+  return (
+    <div className="grid gap-6 lg:grid-cols-[320px,1fr]">
+      <Card>
+        <CardHeader className="space-y-3">
+          <div className="flex items-center justify-between">
+            <CardTitle>Commands</CardTitle>
+            <Button size="sm" onClick={handleCreate} disabled={isSaving}>
+              <Plus className="mr-2 h-4 w-4" />
+              New
+            </Button>
+          </div>
+          <Button variant="outline" size="sm" onClick={handleSyncCommands} disabled={isSyncing}>
+            {isSyncing ? "Syncing..." : "Sync Command Files"}
+          </Button>
+          <Input
+            value={query}
+            onChange={(e) => setQuery(e.target.value)}
+            placeholder="Search commands"
+          />
+        </CardHeader>
+        <CardContent className="space-y-2">
+          {filtered.map((cmd) => (
+            <button
+              key={cmd.id}
+              className={`w-full rounded-md border px-3 py-2 text-left transition ${
+                selectedId === cmd.id ? "border-primary bg-accent" : "hover:bg-accent"
+              }`}
+              onClick={() => setSelectedId(cmd.id)}
+            >
+              <div className="flex items-center justify-between gap-2">
+                <div className="truncate font-medium">{cmd.name}</div>
+                {cmd.expose_via_mcp ? <Badge>MCP</Badge> : <Badge variant="outline">Local</Badge>}
+              </div>
+              <div className="mt-1 truncate text-xs text-muted-foreground">{cmd.description}</div>
+            </button>
+          ))}
+          {filtered.length === 0 && (
+            <p className="text-sm text-muted-foreground">No commands found.</p>
+          )}
+        </CardContent>
+      </Card>
+
+      <Card>
+        <CardHeader>
+          <CardTitle>{selected ? "Edit Command" : "Select a Command"}</CardTitle>
+          <CardDescription>
+            Define script-based commands and expose them to MCP clients.
+          </CardDescription>
+        </CardHeader>
+        <CardContent className="space-y-4">
+          {!selected ? (
+            <p className="text-sm text-muted-foreground">
+              Choose a command from the list or create a new one.
+            </p>
+          ) : (
+            <>
+              <div className="grid gap-2">
+                <label className="text-sm font-medium">Name</label>
+                <Input
+                  value={name}
+                  onChange={(e) => setName(e.target.value)}
+                  placeholder="Command name"
+                />
+              </div>
+
+              <div className="grid gap-2">
+                <label className="text-sm font-medium">Description</label>
+                <Input
+                  value={description}
+                  onChange={(e) => setDescription(e.target.value)}
+                  placeholder="What this command does"
+                />
+              </div>
+
+              <div className="grid gap-2">
+                <label className="text-sm font-medium">Script</label>
+                <textarea
+                  value={script}
+                  onChange={(e) => setScript(e.target.value)}
+                  className="min-h-36 rounded-md border bg-background p-3 text-sm"
+                  placeholder="echo hello"
+                />
+              </div>
+
+              <div className="flex items-center justify-between rounded-md border p-3">
+                <div>
+                  <div className="font-medium">Expose via MCP</div>
+                  <div className="text-xs text-muted-foreground">
+                    Enable this command in tools/list responses.
+                  </div>
+                </div>
+                <Switch checked={exposeViaMcp} onCheckedChange={setExposeViaMcp} />
+              </div>
+
+              {selected.arguments.length > 0 && (
+                <div className="rounded-md border p-3 space-y-2">
+                  <div className="text-sm font-medium">Test Arguments</div>
+                  {selected.arguments.map((arg) => (
+                    <div key={arg.name} className="grid gap-1">
+                      <label className="text-xs text-muted-foreground">
+                        {arg.name} {arg.required ? "(required)" : "(optional)"}
+                      </label>
+                      <Input
+                        value={testArgs[arg.name] ?? ""}
+                        onChange={(e) =>
+                          setTestArgs((prev) => ({
+                            ...prev,
+                            [arg.name]: e.target.value,
+                          }))
+                        }
+                        placeholder={arg.description || arg.name}
+                      />
+                    </div>
+                  ))}
+                </div>
+              )}
+
+              <div className="flex flex-wrap gap-2">
+                <Button onClick={handleSave} disabled={isSaving}>
+                  {isSaving ? "Saving..." : "Save"}
+                </Button>
+                <Button variant="outline" onClick={handleTest} disabled={isTesting}>
+                  <Play className="mr-2 h-4 w-4" />
+                  {isTesting ? "Running..." : "Test Run"}
+                </Button>
+                <Button variant="outline" onClick={handleDelete} disabled={isSaving}>
+                  <Trash2 className="mr-2 h-4 w-4" />
+                  Delete
+                </Button>
+              </div>
+
+              {testOutput && (
+                <div className="rounded-md border p-3 text-sm">
+                  <div className="mb-2 font-medium">
+                    Test Output (exit code: {testOutput.exitCode})
+                  </div>
+                  <div className="grid gap-2 md:grid-cols-2">
+                    <div>
+                      <div className="mb-1 text-xs text-muted-foreground">stdout</div>
+                      <pre className="max-h-48 overflow-auto rounded bg-muted p-2 text-xs whitespace-pre-wrap">
+                        {testOutput.stdout || "(empty)"}
+                      </pre>
+                    </div>
+                    <div>
+                      <div className="mb-1 text-xs text-muted-foreground">stderr</div>
+                      <pre className="max-h-48 overflow-auto rounded bg-muted p-2 text-xs whitespace-pre-wrap">
+                        {testOutput.stderr || "(empty)"}
+                      </pre>
+                    </div>
+                  </div>
+                </div>
+              )}
+
+              <div className="rounded-md border p-3 text-sm">
+                <div className="mb-2 font-medium">Recent Execution History</div>
+                <div className="space-y-2 max-h-56 overflow-auto">
+                  {history
+                    .filter((h) => h.command_id === selected.id)
+                    .slice(0, 10)
+                    .map((h) => (
+                      <div key={h.id} className="rounded border p-2">
+                        <div className="flex items-center justify-between text-xs">
+                          <span className="font-medium">exit {h.exit_code}</span>
+                          <span className="text-muted-foreground">{h.duration_ms}ms</span>
+                        </div>
+                        <div className="mt-1 truncate text-xs text-muted-foreground">
+                          {h.stdout || h.stderr || "(no output)"}
+                        </div>
+                      </div>
+                    ))}
+                  {history.filter((h) => h.command_id === selected.id).length === 0 && (
+                    <p className="text-xs text-muted-foreground">No executions yet.</p>
+                  )}
+                </div>
+              </div>
+            </>
+          )}
+        </CardContent>
+      </Card>
+    </div>
+  );
+}
diff --git a/src/components/pages/Settings.tsx b/src/components/pages/Settings.tsx
index f3870b5..37b1e0f 100644
--- a/src/components/pages/Settings.tsx
+++ b/src/components/pages/Settings.tsx
@@ -1,5 +1,14 @@
 import { useEffect, useState, useCallback } from "react";
-import { FolderOpen, ExternalLink, Info, Save } from "lucide-react";
+import {
+  FolderOpen,
+  ExternalLink,
+  Info,
+  RotateCcw,
+  Save,
+  ShieldCheck,
+  Server,
+  RefreshCw,
+} from "lucide-react";
 import { Button } from "@/components/ui/button";
 import { Card, CardContent, CardHeader, CardTitle, CardDescription } from "@/components/ui/card";
 import { Switch } from "@/components/ui/switch";
@@ -27,19 +36,73 @@ export function Settings() {
   const [hasChanges, setHasChanges] = useState(false);
   const [isSaving, setIsSaving] = useState(false);
   const [isLoading, setIsLoading] = useState(true);
+  const [storageMode, setStorageMode] = useState<"sqlite" | "file">("sqlite");
+  const [storageInfo, setStorageInfo] = useState<Record<string, string> | null>(null);
+  const [isMigratingStorage, setIsMigratingStorage] = useState(false);
+  const [backupPath, setBackupPath] = useState<string>("");
+  const [migrationProgress, setMigrationProgress] = useState<{
+    total: number;
+    migrated: number;
+    current_rule?: string;
+    status: "NotStarted" | "InProgress" | "Completed" | "Failed" | "RolledBack";
+  } | null>(null);
+  const [isRollingBack, setIsRollingBack] = useState(false);
+  const [isVerifyingMigration, setIsVerifyingMigration] = useState(false);
+  const [mcpStatus, setMcpStatus] = useState<{
+    running: boolean;
+    port: number;
+    uptime_seconds: number;
+  } | null>(null);
+  const [mcpInstructions, setMcpInstructions] = useState<{
+    claude_code_json: string;
+    opencode_json: string;
+    standalone_command: string;
+  } | null>(null);
+  const [isMcpLoading, setIsMcpLoading] = useState(false);
+  const [mcpAutoStart, setMcpAutoStart] = useState(false);
+  const [minimizeToTray, setMinimizeToTray] = useState(true);
+  const [mcpLogs, setMcpLogs] = useState<string[]>([]);
   const { addToast } = useToast();
 
   useEffect(() => {
     const loadData = async () => {
       setIsLoading(true);
       try {
-        const [path, version, settingsJson] = await Promise.all([
+        const [
+          path,
+          version,
+          settingsJson,
+          mode,
+          info,
+          savedBackupPath,
+          progress,
+          mcpStatusRes,
+          mcpAutoStartSetting,
+          minimizeToTraySetting,
+          mcpLogsInitial,
+        ] = await Promise.all([
           api.app.getAppDataPath(),
           api.app.getVersion(),
           api.settings.get(ADAPTER_SETTINGS_KEY),
+          api.storage.getMode(),
+          api.storage.getInfo(),
+          api.settings.get("file_storage_backup_path"),
+          api.storage.getMigrationProgress(),
+          api.mcp.getStatus(),
+          api.settings.get("mcp_auto_start"),
+          api.settings.get("minimize_to_tray"),
+          api.mcp.getLogs(20),
         ]);
         setAppDataPath(path);
         setAppVersion(version);
+        setStorageMode(mode === "file" ? "file" : "sqlite");
+        setStorageInfo(info);
+        setBackupPath(savedBackupPath ?? "");
+        setMigrationProgress(progress);
+        setMcpStatus(mcpStatusRes);
+        setMcpAutoStart(mcpAutoStartSetting === "true");
+        setMinimizeToTray(minimizeToTraySetting !== "false");
+        setMcpLogs(mcpLogsInitial);
 
         if (settingsJson) {
           try {
@@ -102,6 +165,216 @@ export function Settings() {
     }
   };
 
+  const migrateToFileStorage = async () => {
+    setIsMigratingStorage(true);
+    let poll: ReturnType<typeof setInterval> | null = null;
+    try {
+      poll = setInterval(async () => {
+        try {
+          const progress = await api.storage.getMigrationProgress();
+          setMigrationProgress(progress);
+        } catch {
+          // no-op during migration polling
+        }
+      }, 500);
+
+      const result = await api.storage.migrateToFileStorage();
+      clearInterval(poll);
+      poll = null;
+
+      if (!result.success) {
+        throw new Error(
+          result.errors[0]?.error ?? "Migration completed with errors. Check logs for details."
+        );
+      }
+
+      setBackupPath(result.backup_path ?? "");
+
+      const [mode, info] = await Promise.all([api.storage.getMode(), api.storage.getInfo()]);
+      setStorageMode(mode === "file" ? "file" : "sqlite");
+      setStorageInfo(info);
+      setMigrationProgress(await api.storage.getMigrationProgress());
+
+      addToast({
+        title: "Migration Complete",
+        description: `Migrated ${result.rules_migrated} rules to file storage.`,
+        variant: "success",
+      });
+    } catch (error) {
+      addToast({
+        title: "Migration Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    } finally {
+      if (poll) {
+        clearInterval(poll);
+      }
+      setIsMigratingStorage(false);
+    }
+  };
+
+  const rollbackMigration = async () => {
+    if (!backupPath) {
+      addToast({
+        title: "Rollback Unavailable",
+        description: "No backup path available for rollback.",
+        variant: "error",
+      });
+      return;
+    }
+
+    setIsRollingBack(true);
+    try {
+      await api.storage.rollbackMigration(backupPath);
+      setStorageMode("sqlite");
+      setMigrationProgress(await api.storage.getMigrationProgress());
+      addToast({
+        title: "Rollback Complete",
+        description: "Database backup restored and file storage disabled.",
+        variant: "success",
+      });
+    } catch (error) {
+      addToast({
+        title: "Rollback Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    } finally {
+      setIsRollingBack(false);
+    }
+  };
+
+  const verifyMigration = async () => {
+    setIsVerifyingMigration(true);
+    try {
+      const result = await api.storage.verifyMigration();
+      if (result.is_valid) {
+        addToast({
+          title: "Migration Verified",
+          description: `Verified ${result.file_rule_count} file rules match ${result.db_rule_count} database rules.`,
+          variant: "success",
+        });
+      } else {
+        addToast({
+          title: "Verification Failed",
+          description: `${result.missing_rules.length} missing, ${result.mismatched_rules.length} mismatched, ${result.load_errors} load errors.`,
+          variant: "error",
+        });
+      }
+    } catch (error) {
+      addToast({
+        title: "Verification Error",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    } finally {
+      setIsVerifyingMigration(false);
+    }
+  };
+
+  const refreshMcpStatus = async () => {
+    try {
+      const [status, logs] = await Promise.all([api.mcp.getStatus(), api.mcp.getLogs(20)]);
+      setMcpStatus(status);
+      setMcpLogs(logs);
+    } catch (error) {
+      addToast({
+        title: "MCP Status Error",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    }
+  };
+
+  const startMcp = async () => {
+    setIsMcpLoading(true);
+    try {
+      await api.mcp.start();
+      const [status, instructions] = await Promise.all([
+        api.mcp.getStatus(),
+        api.mcp.getInstructions(),
+      ]);
+      setMcpStatus(status);
+      setMcpInstructions(instructions);
+      setMcpLogs(await api.mcp.getLogs(20));
+      addToast({
+        title: "MCP Started",
+        description: `Server running on port ${status.port}`,
+        variant: "success",
+      });
+    } catch (error) {
+      addToast({
+        title: "MCP Start Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    } finally {
+      setIsMcpLoading(false);
+    }
+  };
+
+  const stopMcp = async () => {
+    setIsMcpLoading(true);
+    try {
+      await api.mcp.stop();
+      await refreshMcpStatus();
+      addToast({
+        title: "MCP Stopped",
+        description: "Server has been stopped",
+        variant: "success",
+      });
+    } catch (error) {
+      addToast({
+        title: "MCP Stop Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    } finally {
+      setIsMcpLoading(false);
+    }
+  };
+
+  const toggleMcpAutoStart = async (enabled: boolean) => {
+    setMcpAutoStart(enabled);
+    try {
+      await api.settings.set("mcp_auto_start", enabled ? "true" : "false");
+      addToast({
+        title: "MCP Setting Saved",
+        description: enabled ? "MCP will auto-start on app launch" : "MCP auto-start disabled",
+        variant: "success",
+      });
+    } catch (error) {
+      setMcpAutoStart(!enabled);
+      addToast({
+        title: "Setting Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    }
+  };
+
+  const toggleMinimizeToTray = async (enabled: boolean) => {
+    setMinimizeToTray(enabled);
+    try {
+      await api.settings.set("minimize_to_tray", enabled ? "true" : "false");
+      addToast({
+        title: "Window Behavior Updated",
+        description: enabled
+          ? "Closing the window will hide RuleWeaver to tray"
+          : "Closing the window will exit RuleWeaver",
+        variant: "success",
+      });
+    } catch (error) {
+      setMinimizeToTray(!enabled);
+      addToast({
+        title: "Setting Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    }
+  };
+
   return (
     <div className="space-y-6 max-w-3xl">
       <div className="flex items-center justify-between">
@@ -136,6 +409,174 @@ export function Settings() {
         </CardContent>
       </Card>
 
+      <Card>
+        <CardHeader>
+          <CardTitle>MCP Server</CardTitle>
+          <CardDescription>
+            Start and manage the local MCP server for tool integration
+          </CardDescription>
+        </CardHeader>
+        <CardContent className="space-y-4">
+          <div className="flex items-center justify-between rounded-md border p-3">
+            <div className="flex items-center gap-2">
+              <Server className="h-4 w-4" />
+              <div>
+                <div className="font-medium">Status</div>
+                <div className="text-sm text-muted-foreground">
+                  {mcpStatus?.running ? `Running on port ${mcpStatus.port}` : "Stopped"}
+                </div>
+              </div>
+            </div>
+            <Badge variant={mcpStatus?.running ? "default" : "outline"}>
+              {mcpStatus?.running ? "Running" : "Stopped"}
+            </Badge>
+          </div>
+
+          {mcpStatus?.running && (
+            <p className="text-xs text-muted-foreground">Uptime: {mcpStatus.uptime_seconds}s</p>
+          )}
+
+          <div className="flex flex-wrap gap-2">
+            <Button onClick={startMcp} disabled={isMcpLoading || !!mcpStatus?.running}>
+              Start
+            </Button>
+            <Button
+              variant="outline"
+              onClick={stopMcp}
+              disabled={isMcpLoading || !mcpStatus?.running}
+            >
+              Stop
+            </Button>
+            <Button variant="outline" onClick={refreshMcpStatus} disabled={isMcpLoading}>
+              <RefreshCw className="mr-2 h-4 w-4" />
+              Refresh
+            </Button>
+          </div>
+
+          <div className="flex items-center justify-between rounded-md border p-3">
+            <div>
+              <div className="font-medium">Auto-start MCP</div>
+              <div className="text-xs text-muted-foreground">
+                Start MCP automatically when RuleWeaver launches
+              </div>
+            </div>
+            <Switch checked={mcpAutoStart} onCheckedChange={toggleMcpAutoStart} />
+          </div>
+
+          <div className="flex items-center justify-between rounded-md border p-3">
+            <div>
+              <div className="font-medium">Minimize to tray on close</div>
+              <div className="text-xs text-muted-foreground">
+                Keep app and MCP running when closing the main window
+              </div>
+            </div>
+            <Switch checked={minimizeToTray} onCheckedChange={toggleMinimizeToTray} />
+          </div>
+
+          {mcpInstructions && (
+            <div className="space-y-2">
+              <code className="block rounded-md bg-muted p-2 text-xs overflow-auto">
+                {mcpInstructions.standalone_command}
+              </code>
+              <div className="grid gap-2 md:grid-cols-2">
+                <code className="rounded-md bg-muted p-2 text-xs overflow-auto">
+                  {mcpInstructions.claude_code_json}
+                </code>
+                <code className="rounded-md bg-muted p-2 text-xs overflow-auto">
+                  {mcpInstructions.opencode_json}
+                </code>
+              </div>
+            </div>
+          )}
+
+          <div className="rounded-md border p-3">
+            <div className="mb-2 text-sm font-medium">Recent MCP Logs</div>
+            <div className="max-h-40 space-y-1 overflow-auto text-xs text-muted-foreground">
+              {mcpLogs.length === 0 && <div>No logs yet.</div>}
+              {mcpLogs.map((log, idx) => (
+                <div key={`${idx}-${log.slice(0, 20)}`}>{log}</div>
+              ))}
+            </div>
+          </div>
+        </CardContent>
+      </Card>
+
+      <Card>
+        <CardHeader>
+          <CardTitle>Storage</CardTitle>
+          <CardDescription>
+            Manage where rules are stored: legacy SQLite or file-based markdown storage
+          </CardDescription>
+        </CardHeader>
+        <CardContent className="space-y-4">
+          <div className="flex items-center justify-between rounded-md border p-3">
+            <div>
+              <div className="font-medium">Current Mode</div>
+              <div className="text-sm text-muted-foreground">
+                {storageMode === "file"
+                  ? "File storage (.ruleweaver/rules/*.md)"
+                  : "SQLite database (legacy)"}
+              </div>
+            </div>
+            <Badge variant={storageMode === "file" ? "default" : "outline"}>
+              {storageMode === "file" ? "File" : "SQLite"}
+            </Badge>
+          </div>
+
+          {storageInfo && (
+            <div className="grid grid-cols-1 gap-2 text-sm text-muted-foreground md:grid-cols-3">
+              <div>Rules: {storageInfo.rule_count ?? "0"}</div>
+              <div>Size: {storageInfo.total_size_bytes ?? "0"} bytes</div>
+              <div>Storage Exists: {storageInfo.exists ?? "false"}</div>
+            </div>
+          )}
+
+          {storageMode !== "file" && (
+            <Button onClick={migrateToFileStorage} disabled={isMigratingStorage || isLoading}>
+              {isMigratingStorage ? "Migrating..." : "Migrate to File Storage"}
+            </Button>
+          )}
+
+          {migrationProgress && (
+            <div className="rounded-md border p-3 space-y-2">
+              <div className="flex items-center justify-between text-sm">
+                <span className="text-muted-foreground">Migration Status</span>
+                <Badge variant="outline">{migrationProgress.status}</Badge>
+              </div>
+              <div className="text-sm">
+                {migrationProgress.migrated} / {migrationProgress.total || 0} rules migrated
+              </div>
+              {migrationProgress.current_rule && (
+                <div className="text-xs text-muted-foreground truncate">
+                  Current: {migrationProgress.current_rule}
+                </div>
+              )}
+            </div>
+          )}
+
+          {storageMode === "file" && (
+            <div className="flex flex-wrap gap-2">
+              <Button variant="outline" onClick={verifyMigration} disabled={isVerifyingMigration}>
+                <ShieldCheck className="mr-2 h-4 w-4" />
+                {isVerifyingMigration ? "Verifying..." : "Verify Migration"}
+              </Button>
+              <Button
+                variant="outline"
+                onClick={rollbackMigration}
+                disabled={isRollingBack || !backupPath}
+              >
+                <RotateCcw className="mr-2 h-4 w-4" />
+                {isRollingBack ? "Rolling Back..." : "Rollback"}
+              </Button>
+            </div>
+          )}
+
+          {backupPath && (
+            <p className="text-xs text-muted-foreground break-all">Backup: {backupPath}</p>
+          )}
+        </CardContent>
+      </Card>
+
       <Card>
         <CardHeader>
           <CardTitle>Adapters</CardTitle>
diff --git a/src/components/pages/Skills.tsx b/src/components/pages/Skills.tsx
new file mode 100644
index 0000000..e06b71b
--- /dev/null
+++ b/src/components/pages/Skills.tsx
@@ -0,0 +1,198 @@
+import { useEffect, useMemo, useState } from "react";
+import { Plus, Trash2 } from "lucide-react";
+import { Button } from "@/components/ui/button";
+import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
+import { Input } from "@/components/ui/input";
+import { Switch } from "@/components/ui/switch";
+import { api } from "@/lib/tauri";
+import { useToast } from "@/components/ui/toast";
+import type { Skill } from "@/types/skill";
+
+export function Skills() {
+  const [skills, setSkills] = useState<Skill[]>([]);
+  const [selectedId, setSelectedId] = useState("");
+  const [name, setName] = useState("");
+  const [description, setDescription] = useState("");
+  const [instructions, setInstructions] = useState("");
+  const [enabled, setEnabled] = useState(true);
+  const [isSaving, setIsSaving] = useState(false);
+  const { addToast } = useToast();
+
+  const selected = useMemo(
+    () => skills.find((s) => s.id === selectedId) ?? null,
+    [skills, selectedId]
+  );
+
+  const loadSkills = async () => {
+    const data = await api.skills.getAll();
+    setSkills(data);
+  };
+
+  useEffect(() => {
+    loadSkills().catch((error) => {
+      addToast({
+        title: "Failed to Load Skills",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    });
+  }, [addToast]);
+
+  useEffect(() => {
+    if (!selected) {
+      setName("");
+      setDescription("");
+      setInstructions("");
+      setEnabled(true);
+      return;
+    }
+    setName(selected.name);
+    setDescription(selected.description);
+    setInstructions(selected.instructions);
+    setEnabled(selected.enabled);
+  }, [selected]);
+
+  const createSkill = async () => {
+    setIsSaving(true);
+    try {
+      const created = await api.skills.create({
+        name: "New Skill",
+        description: "Describe this workflow",
+        instructions: "Step 1\nStep 2",
+        enabled: true,
+      });
+      await loadSkills();
+      setSelectedId(created.id);
+      addToast({ title: "Skill Created", description: created.name, variant: "success" });
+    } catch (error) {
+      addToast({
+        title: "Create Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    } finally {
+      setIsSaving(false);
+    }
+  };
+
+  const saveSkill = async () => {
+    if (!selected) return;
+    setIsSaving(true);
+    try {
+      const updated = await api.skills.update(selected.id, {
+        name,
+        description,
+        instructions,
+        enabled,
+      });
+      setSkills((prev) => prev.map((s) => (s.id === updated.id ? updated : s)));
+      addToast({ title: "Skill Saved", description: updated.name, variant: "success" });
+    } catch (error) {
+      addToast({
+        title: "Save Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    } finally {
+      setIsSaving(false);
+    }
+  };
+
+  const deleteSkill = async () => {
+    if (!selected) return;
+    setIsSaving(true);
+    try {
+      await api.skills.delete(selected.id);
+      setSkills((prev) => prev.filter((s) => s.id !== selected.id));
+      setSelectedId("");
+      addToast({ title: "Skill Deleted", description: selected.name, variant: "success" });
+    } catch (error) {
+      addToast({
+        title: "Delete Failed",
+        description: error instanceof Error ? error.message : "Unknown error",
+        variant: "error",
+      });
+    } finally {
+      setIsSaving(false);
+    }
+  };
+
+  return (
+    <div className="grid gap-6 lg:grid-cols-[320px,1fr]">
+      <Card>
+        <CardHeader>
+          <div className="flex items-center justify-between">
+            <CardTitle>Skills</CardTitle>
+            <Button size="sm" onClick={createSkill} disabled={isSaving}>
+              <Plus className="mr-2 h-4 w-4" />
+              New
+            </Button>
+          </div>
+          <CardDescription>Complex multi-step workflows</CardDescription>
+        </CardHeader>
+        <CardContent className="space-y-2">
+          {skills.map((skill) => (
+            <button
+              key={skill.id}
+              className={`w-full rounded-md border px-3 py-2 text-left transition ${
+                selectedId === skill.id ? "border-primary bg-accent" : "hover:bg-accent"
+              }`}
+              onClick={() => setSelectedId(skill.id)}
+            >
+              <div className="font-medium truncate">{skill.name}</div>
+              <div className="text-xs text-muted-foreground truncate">{skill.description}</div>
+            </button>
+          ))}
+        </CardContent>
+      </Card>
+
+      <Card>
+        <CardHeader>
+          <CardTitle>{selected ? "Edit Skill" : "Select a Skill"}</CardTitle>
+          <CardDescription>Define reusable instructions and workflow context.</CardDescription>
+        </CardHeader>
+        <CardContent className="space-y-4">
+          <div className="rounded-md border border-amber-300 bg-amber-50 p-3 text-xs text-amber-900">
+            Security warning: Skills execute shell commands with your current user privileges. Treat
+            imported or shared skills as trusted code only.
+          </div>
+          {!selected ? (
+            <p className="text-sm text-muted-foreground">Select a skill or create a new one.</p>
+          ) : (
+            <>
+              <Input
+                value={name}
+                onChange={(e) => setName(e.target.value)}
+                placeholder="Skill name"
+              />
+              <Input
+                value={description}
+                onChange={(e) => setDescription(e.target.value)}
+                placeholder="Description"
+              />
+              <textarea
+                value={instructions}
+                onChange={(e) => setInstructions(e.target.value)}
+                className="min-h-48 rounded-md border bg-background p-3 text-sm"
+                placeholder="Write workflow instructions..."
+              />
+              <div className="flex items-center justify-between rounded-md border p-3">
+                <span className="text-sm">Enabled</span>
+                <Switch checked={enabled} onCheckedChange={setEnabled} />
+              </div>
+              <div className="flex gap-2">
+                <Button onClick={saveSkill} disabled={isSaving}>
+                  {isSaving ? "Saving..." : "Save"}
+                </Button>
+                <Button variant="outline" onClick={deleteSkill} disabled={isSaving}>
+                  <Trash2 className="mr-2 h-4 w-4" />
+                  Delete
+                </Button>
+              </div>
+            </>
+          )}
+        </CardContent>
+      </Card>
+    </div>
+  );
+}
diff --git a/src/components/ui/keyboard-shortcuts-dialog.tsx b/src/components/ui/keyboard-shortcuts-dialog.tsx
index fd2c5bb..08ebc6b 100644
--- a/src/components/ui/keyboard-shortcuts-dialog.tsx
+++ b/src/components/ui/keyboard-shortcuts-dialog.tsx
@@ -15,9 +15,14 @@ interface ShortcutItem {
 
 const shortcutList: ShortcutItem[] = [
   { key: "n", ctrl: true, label: "New Rule" },
+  { key: "n", ctrl: true, shift: true, label: "New Command" },
   { key: "s", ctrl: true, label: "Save" },
   { key: "s", ctrl: true, shift: true, label: "Sync All" },
   { key: "f", ctrl: true, label: "Search" },
+  { key: "1", ctrl: true, label: "Dashboard" },
+  { key: "2", ctrl: true, label: "Rules" },
+  { key: "3", ctrl: true, label: "Commands" },
+  { key: "4", ctrl: true, label: "Skills" },
   { key: ",", ctrl: true, label: "Settings" },
   { key: "Escape", label: "Close/Cancel" },
 ];
diff --git a/src/hooks/useKeyboardShortcuts.ts b/src/hooks/useKeyboardShortcuts.ts
index 748f8e7..70a9066 100644
--- a/src/hooks/useKeyboardShortcuts.ts
+++ b/src/hooks/useKeyboardShortcuts.ts
@@ -50,10 +50,15 @@ export function useKeyboardShortcuts({ shortcuts, enabled = true }: UseKeyboardS
 
 export const SHORTCUTS = {
   NEW_RULE: { key: "n", ctrl: true, description: "Create new rule" },
+  NEW_COMMAND: { key: "n", ctrl: true, shift: true, description: "Create new command" },
   SAVE: { key: "s", ctrl: true, description: "Save current rule" },
   SYNC: { key: "s", ctrl: true, shift: true, description: "Sync all rules" },
   SEARCH: { key: "f", ctrl: true, description: "Focus search" },
   SETTINGS: { key: ",", ctrl: true, description: "Open settings" },
+  DASHBOARD: { key: "1", ctrl: true, description: "Go to dashboard" },
+  RULES: { key: "2", ctrl: true, description: "Go to rules" },
+  COMMANDS: { key: "3", ctrl: true, description: "Go to commands" },
+  SKILLS: { key: "4", ctrl: true, description: "Go to skills" },
   HELP: { key: "?", shift: true, description: "Show keyboard shortcuts" },
   ESCAPE: { key: "Escape", description: "Close dialog/cancel" },
 } as const;
diff --git a/src/lib/tauri.ts b/src/lib/tauri.ts
index 476552c..435b999 100644
--- a/src/lib/tauri.ts
+++ b/src/lib/tauri.ts
@@ -7,6 +7,16 @@ import type {
   SyncHistoryEntry,
   Conflict,
 } from "@/types/rule";
+import type {
+  CommandModel,
+  CreateCommandInput,
+  UpdateCommandInput,
+  TestCommandResult,
+  McpStatus,
+  McpConnectionInstructions,
+  ExecutionLog,
+} from "@/types/command";
+import type { CreateSkillInput, Skill, UpdateSkillInput } from "@/types/skill";
 
 export const api = {
   rules: {
@@ -37,6 +47,73 @@ export const api = {
     getAll: () => invoke<Record<string, string>>("get_all_settings"),
   },
 
+  storage: {
+    getMode: () => invoke<string>("get_storage_mode"),
+    getInfo: () => invoke<Record<string, string>>("get_storage_info"),
+    migrateToFileStorage: () =>
+      invoke<{
+        success: boolean;
+        rules_migrated: number;
+        rules_skipped: number;
+        errors: Array<{ rule_id: string; rule_name: string; error: string }>;
+        backup_path?: string;
+        storage_dir: string;
+      }>("migrate_to_file_storage"),
+    rollbackMigration: (backupPath: string) =>
+      invoke<void>("rollback_file_migration", { backupPath }),
+    verifyMigration: () =>
+      invoke<{
+        is_valid: boolean;
+        db_rule_count: number;
+        file_rule_count: number;
+        missing_rules: string[];
+        extra_rules: string[];
+        mismatched_rules: string[];
+        load_errors: number;
+      }>("verify_file_migration"),
+    getMigrationProgress: () =>
+      invoke<{
+        total: number;
+        migrated: number;
+        current_rule?: string;
+        status: "NotStarted" | "InProgress" | "Completed" | "Failed" | "RolledBack";
+      }>("get_file_migration_progress"),
+  },
+
+  commands: {
+    getAll: () => invoke<CommandModel[]>("get_all_commands"),
+    getById: (id: string) => invoke<CommandModel>("get_command_by_id", { id }),
+    create: (input: CreateCommandInput) => invoke<CommandModel>("create_command", { input }),
+    update: (id: string, input: UpdateCommandInput) =>
+      invoke<CommandModel>("update_command", { id, input }),
+    delete: (id: string) => invoke<void>("delete_command", { id }),
+    test: (id: string, args: Record<string, string>) =>
+      invoke<TestCommandResult>("test_command", { id, args }),
+    sync: () => invoke<SyncResult>("sync_commands"),
+  },
+
+  skills: {
+    getAll: () => invoke<Skill[]>("get_all_skills"),
+    getById: (id: string) => invoke<Skill>("get_skill_by_id", { id }),
+    create: (input: CreateSkillInput) => invoke<Skill>("create_skill", { input }),
+    update: (id: string, input: UpdateSkillInput) => invoke<Skill>("update_skill", { id, input }),
+    delete: (id: string) => invoke<void>("delete_skill", { id }),
+  },
+
+  mcp: {
+    getStatus: () => invoke<McpStatus>("get_mcp_status"),
+    start: () => invoke<void>("start_mcp_server"),
+    stop: () => invoke<void>("stop_mcp_server"),
+    restart: () => invoke<void>("restart_mcp_server"),
+    getInstructions: () => invoke<McpConnectionInstructions>("get_mcp_connection_instructions"),
+    getLogs: (limit?: number) => invoke<string[]>("get_mcp_logs", { limit: limit ?? 50 }),
+  },
+
+  execution: {
+    getHistory: (limit?: number) =>
+      invoke<ExecutionLog[]>("get_execution_history", { limit: limit ?? 100 }),
+  },
+
   app: {
     getAppDataPath: () => invoke<string>("get_app_data_path_cmd"),
     openInExplorer: (path: string) => invoke<void>("open_in_explorer", { path }),
diff --git a/src/types/command.ts b/src/types/command.ts
new file mode 100644
index 0000000..09bf4db
--- /dev/null
+++ b/src/types/command.ts
@@ -0,0 +1,66 @@
+export interface CommandArgument {
+  name: string;
+  description: string;
+  required: boolean;
+  default_value?: string;
+}
+
+export interface CommandModel {
+  id: string;
+  name: string;
+  description: string;
+  script: string;
+  arguments: CommandArgument[];
+  expose_via_mcp: boolean;
+  created_at: number;
+  updated_at: number;
+}
+
+export interface CreateCommandInput {
+  name: string;
+  description: string;
+  script: string;
+  arguments?: CommandArgument[];
+  expose_via_mcp?: boolean;
+}
+
+export interface UpdateCommandInput {
+  name?: string;
+  description?: string;
+  script?: string;
+  arguments?: CommandArgument[];
+  expose_via_mcp?: boolean;
+}
+
+export interface TestCommandResult {
+  success: boolean;
+  stdout: string;
+  stderr: string;
+  exit_code: number;
+  duration_ms: number;
+}
+
+export interface McpStatus {
+  running: boolean;
+  port: number;
+  uptime_seconds: number;
+}
+
+export interface McpConnectionInstructions {
+  claude_code_json: string;
+  opencode_json: string;
+  standalone_command: string;
+}
+
+export interface ExecutionLog {
+  id: string;
+  command_id: string;
+  command_name: string;
+  arguments: string;
+  stdout: string;
+  stderr: string;
+  exit_code: number;
+  duration_ms: number;
+  executed_at: number;
+  triggered_by: string;
+}
diff --git a/src/types/skill.ts b/src/types/skill.ts
new file mode 100644
index 0000000..5f15612
--- /dev/null
+++ b/src/types/skill.ts
@@ -0,0 +1,23 @@
+export interface Skill {
+  id: string;
+  name: string;
+  description: string;
+  instructions: string;
+  enabled: boolean;
+  created_at: number;
+  updated_at: number;
+}
+
+export interface CreateSkillInput {
+  name: string;
+  description: string;
+  instructions: string;
+  enabled?: boolean;
+}
+
+export interface UpdateSkillInput {
+  name?: string;
+  description?: string;
+  instructions?: string;
+  enabled?: boolean;
+}
